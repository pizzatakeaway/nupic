{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# parameters generated using getScalar()_ HTM Univariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# from tqdm import tqdm_notebook\n",
    "# import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "Load Data and Groundtruth labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_relative = 'realKnownCause/machine_temperature_system_failure.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/NAB/' + PATH_relative) #parse_dates=True\n",
    "with open('../labels/NAB/combined_windows.json') as f:\n",
    "    labels = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-12-02 21:15:00</td>\n",
       "      <td>73.967322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-12-02 21:20:00</td>\n",
       "      <td>74.935882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-12-02 21:25:00</td>\n",
       "      <td>76.124162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-12-02 21:30:00</td>\n",
       "      <td>78.140707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-12-02 21:35:00</td>\n",
       "      <td>79.329836</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp      value\n",
       "0  2013-12-02 21:15:00  73.967322\n",
       "1  2013-12-02 21:20:00  74.935882\n",
       "2  2013-12-02 21:25:00  76.124162\n",
       "3  2013-12-02 21:30:00  78.140707\n",
       "4  2013-12-02 21:35:00  79.329836"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([0,1], inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df['value'] = pd.to_numeric(df['value'])\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'], format=\"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Groundtruth labels for anomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[u'2013-12-10 06:25:00.000000', u'2013-12-12 05:35:00.000000'],\n",
       " [u'2013-12-15 17:50:00.000000', u'2013-12-17 17:00:00.000000'],\n",
       " [u'2014-01-27 14:20:00.000000', u'2014-01-29 13:30:00.000000'],\n",
       " [u'2014-02-07 14:55:00.000000', u'2014-02-09 14:05:00.000000']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[PATH_relative]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['labels'] = np.zeros_like(df.value)\n",
    "\n",
    "# set values within the range = 1\n",
    "for i in range(len(labels[PATH_relative])):\n",
    "    df.loc[(df['timestamp'] >= labels[PATH_relative][i][0]) & \n",
    "           (df['timestamp'] <= labels[PATH_relative][i][1]), 'labels'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>value</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-12-02 21:25:00</td>\n",
       "      <td>76.124162</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-12-02 21:30:00</td>\n",
       "      <td>78.140707</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-12-02 21:35:00</td>\n",
       "      <td>79.329836</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-12-02 21:40:00</td>\n",
       "      <td>78.710418</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-12-02 21:45:00</td>\n",
       "      <td>80.269784</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            timestamp      value  labels\n",
       "0 2013-12-02 21:25:00  76.124162     0.0\n",
       "1 2013-12-02 21:30:00  78.140707     0.0\n",
       "2 2013-12-02 21:35:00  79.329836     0.0\n",
       "3 2013-12-02 21:40:00  78.710418     0.0\n",
       "4 2013-12-02 21:45:00  80.269784     0.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suggested Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **load** `.json` parameters from `src/nupic/frameworks/opf/common_models/anomaly_params_random_encoder/best_single_metric_anomaly_params_tm_cpp.json`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HTM Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load** MODEL_PARAMS:\n",
    "\n",
    "Best Parameters.\n",
    "The fnc `getScalarMetricWithTimeOfDayAnomalyParams` should return the best parameters.\n",
    "[link](http://nupic.docs.numenta.org/1.0.3/api/opf/utils.html?highlight=getscalarmetricwithtimeofdayanomalyparams)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nupic.frameworks.opf.common_models.cluster_params import getScalarMetricWithTimeOfDayAnomalyParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelParams = getScalarMetricWithTimeOfDayAnomalyParams(df['value'],\n",
    "                                                        minVal=df['value'].min(), \n",
    "                                                        maxVal=df['value'].max()\n",
    "                                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'inferenceArgs': {u'inputPredictedField': u'auto',\n",
       "  u'predictedField': u'c1',\n",
       "  u'predictionSteps': [1]},\n",
       " u'modelConfig': {u'aggregationInfo': {u'days': 0,\n",
       "   u'fields': [],\n",
       "   u'hours': 0,\n",
       "   u'microseconds': 0,\n",
       "   u'milliseconds': 0,\n",
       "   u'minutes': 0,\n",
       "   u'months': 0,\n",
       "   u'seconds': 0,\n",
       "   u'weeks': 0,\n",
       "   u'years': 0},\n",
       "  u'model': u'HTMPrediction',\n",
       "  u'modelParams': {u'anomalyParams': {u'anomalyCacheRecords': None,\n",
       "    u'autoDetectThreshold': None,\n",
       "    u'autoDetectWaitRecords': 5030},\n",
       "   u'clEnable': False,\n",
       "   u'clParams': {u'alpha': 0.035828933612158,\n",
       "    u'regionName': u'SDRClassifierRegion',\n",
       "    u'steps': u'1',\n",
       "    u'verbosity': 0},\n",
       "   u'inferenceType': u'TemporalAnomaly',\n",
       "   u'sensorParams': {u'encoders': {u'c0_dayOfWeek': None,\n",
       "     u'c0_timeOfDay': {u'fieldname': u'c0',\n",
       "      u'name': u'c0',\n",
       "      u'timeOfDay': [21, 9.49],\n",
       "      u'type': u'DateEncoder'},\n",
       "     u'c0_weekend': None,\n",
       "     u'c1': {u'fieldname': u'c1',\n",
       "      u'name': u'c1',\n",
       "      'resolution': 0.81866016610769232,\n",
       "      u'seed': 42,\n",
       "      u'type': u'RandomDistributedScalarEncoder'}},\n",
       "    u'sensorAutoReset': None,\n",
       "    u'verbosity': 0},\n",
       "   u'spEnable': True,\n",
       "   u'spParams': {u'boostStrength': 0.0,\n",
       "    u'columnCount': 2048,\n",
       "    u'globalInhibition': 1,\n",
       "    u'inputWidth': 0,\n",
       "    u'numActiveColumnsPerInhArea': 40,\n",
       "    u'potentialPct': 0.8,\n",
       "    u'seed': 1956,\n",
       "    u'spVerbosity': 0,\n",
       "    u'spatialImp': u'cpp',\n",
       "    u'synPermActiveInc': 0.003,\n",
       "    u'synPermConnected': 0.2,\n",
       "    u'synPermInactiveDec': 0.0005},\n",
       "   u'tmEnable': True,\n",
       "   u'tmParams': {u'activationThreshold': 13,\n",
       "    u'cellsPerColumn': 32,\n",
       "    u'columnCount': 2048,\n",
       "    u'globalDecay': 0.0,\n",
       "    u'initialPerm': 0.21,\n",
       "    u'inputWidth': 2048,\n",
       "    u'maxAge': 0,\n",
       "    u'maxSegmentsPerCell': 128,\n",
       "    u'maxSynapsesPerSegment': 32,\n",
       "    u'minThreshold': 10,\n",
       "    u'newSynapseCount': 20,\n",
       "    u'outputType': u'normal',\n",
       "    u'pamLength': 3,\n",
       "    u'permanenceDec': 0.1,\n",
       "    u'permanenceInc': 0.1,\n",
       "    u'seed': 1960,\n",
       "    u'temporalImp': u'cpp',\n",
       "    u'verbosity': 0},\n",
       "   u'trainSPNetOnlyIfRequested': False},\n",
       "  u'predictAheadTime': None,\n",
       "  u'version': 1}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelParams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'encoders': {u'c0_dayOfWeek': None,\n",
       "  u'c0_timeOfDay': {u'fieldname': u'c0',\n",
       "   u'name': u'c0',\n",
       "   u'timeOfDay': [21, 9.49],\n",
       "   u'type': u'DateEncoder'},\n",
       "  u'c0_weekend': None,\n",
       "  u'c1': {u'fieldname': u'c1',\n",
       "   u'name': u'c1',\n",
       "   'resolution': 0.81866016610769232,\n",
       "   u'seed': 42,\n",
       "   u'type': u'RandomDistributedScalarEncoder'}},\n",
       " u'sensorAutoReset': None,\n",
       " u'verbosity': 0}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelParams['modelConfig']['modelParams']['sensorParams']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'labels': 0.0,\n",
       "  'timestamp': Timestamp('2013-12-02 21:25:00'),\n",
       "  'value': 76.12416182},\n",
       " {'labels': 0.0,\n",
       "  'timestamp': Timestamp('2013-12-02 21:30:00'),\n",
       "  'value': 78.14070732},\n",
       " {'labels': 0.0,\n",
       "  'timestamp': Timestamp('2013-12-02 21:35:00'),\n",
       "  'value': 79.32983574},\n",
       " {'labels': 0.0,\n",
       "  'timestamp': Timestamp('2013-12-02 21:40:00'),\n",
       "  'value': 78.71041827},\n",
       " {'labels': 0.0,\n",
       "  'timestamp': Timestamp('2013-12-02 21:45:00'),\n",
       "  'value': 80.26978421}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df.to_dict(orient='records')\n",
    "data[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \n",
      "\n",
      "c0_timeOfDay {u'fieldname': u'c0', u'timeOfDay': [21, 9.49], u'type': u'DateEncoder', u'name': u'c0'} \n",
      "\n",
      "c1 {u'name': u'c1', 'resolution': 0.81866016610769232, u'seed': 42, u'fieldname': u'c1', u'type': u'RandomDistributedScalarEncoder'} \n",
      "\n",
      "0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k,v in modelParams['modelConfig']['modelParams']['sensorParams']['encoders'].items():\n",
    "    if v != None:\n",
    "        print k, v, \"\\n\"\n",
    "    else: \n",
    "        print str(0), \"\\n\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to build: \n",
    "- 1x 'DateEncoder' which encodes the field `timestamp`\n",
    "- 1x 'ScalarEncoder' which encodes the field `value`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_dict_key(d, keys):\n",
    "    \"\"\"\n",
    "    Remove 'keys' in dict.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    d: dict\n",
    "    keys: list\n",
    "        List containing key(s) to delete.\n",
    "        \n",
    "    Outputp\n",
    "    -------\n",
    "    new_d: dict\n",
    "        A new dict object.\n",
    "    \n",
    "    \"\"\"\n",
    "    new_d = dict(d)\n",
    "    for i in keys: \n",
    "        del new_d[i]\n",
    "    return new_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from nupic.encoders.random_distributed_scalar import RandomDistributedScalarEncoder\n",
    "from nupic.encoders.scalar import ScalarEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76.12416182 =  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0]\n",
      "78.14070732 =  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "vEnc = ScalarEncoder(w=21, minval=df['value'].min(), maxval=df['value'].max(),\n",
    "                     resolution=modelParams['modelConfig']['modelParams']['sensorParams']['encoders']['c1']['resolution'])\n",
    "\n",
    "print str(data[0]['value']) + \" = \", vEnc.encode(data[0]['value'])\n",
    "print str(data[1]['value']) + \" = \", vEnc.encode(data[1]['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'[2.084721206:108.5105428]': ([[74.945475989584608, 74.945475989584608]],\n",
       "   '74.95')},\n",
       " ['[2.084721206:108.5105428]'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = vEnc.encode(75.123)\n",
    "#print(enc)\n",
    "vEnc.decode(enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scalar encoder proposed seems to be very precise for our data.  \n",
    "`[2.084721206:108.5105428]` this is the *range* of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from nupic.encoders.date import DateEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dEnc = DateEncoder(modelParams['modelConfig']['modelParams']['sensorParams']['encoders']['c0_timeOfDay']['timeOfDay']) \n",
    "\n",
    "# tsObs1 = datetime.datetime.strptime(data[0]['timestamp'], \"%Y-%m-%d %H:%M:%S\")\n",
    "# print \"TimeStamp-obs0 = \", dEnc.encode(data[0]['timestamp'])\n",
    "# print \"TimeStamp-obs1 = \", dEnc.encode(data[1]['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = []\n",
    "inputVal = []\n",
    "inputTs = []\n",
    "label = []\n",
    "inputSDRval = []\n",
    "inputSDRts = []\n",
    "inputSDR = []  # main\n",
    "inputTsIdx = [0, len(dEnc.encode(data[0]['timestamp'])) - 1]\n",
    "inputValIdx = [len(dEnc.encode(data[0]['timestamp'])), \n",
    "               len(dEnc.encode(data[0]['timestamp'])) + len(vEnc.encode(data[1]['value'])) - 1]\n",
    "\n",
    "for i in xrange(len(data)):\n",
    "    obs.append(i)\n",
    "    inputTs.append(data[i]['timestamp'])  \n",
    "    inputVal.append(data[i]['value'])   \n",
    "    label.append(data[i]['labels'])\n",
    "    inputSDRts.append(dEnc.encode(data[i]['timestamp']))\n",
    "    inputSDRval.append(vEnc.encode(data[i]['value']))\n",
    "    inputSDR.append(np.hstack((inputSDRts[i], inputSDRval[i])))  # combine the 2 ancoders in 1 enoder \n",
    "    \n",
    "# send everything to dict    \n",
    "data = pd.DataFrame({'inputVal':inputVal, 'inputTs':inputTs, 'label': label,\n",
    "                      'inputSDR':inputSDR, 'inputSDRval':inputSDRval, 'inputSDRts':inputSDRts, \n",
    "                      #'inputValIdx1':inputValIdx1, 'inputVaIdx2':inputValIdx2\n",
    "                     }, index=obs).to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(inputSDR):  961\n",
      "{'inputSDR': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=uint8), 'label': 0.0, 'inputVal': 76.12416182, 'inputTs': Timestamp('2013-12-02 21:25:00'), 'inputSDRts': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0], dtype=uint8), 'inputSDRval': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=uint8)}\n",
      "22693\n"
     ]
    }
   ],
   "source": [
    "print \"len(inputSDR): \", len(data[0]['inputSDR'])\n",
    "print data[0]\n",
    "print len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spatial Pooler\n",
    "[link to wiki](http://nupic.docs.numenta.org/1.0.3/api/algorithms/spatial-pooling.html#nupic.algorithms.spatial_pooler.SpatialPooler)\n",
    "\n",
    "Load `modelParams` fors SP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nupic.algorithms.spatial_pooler import SpatialPooler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'inferenceArgs': {u'inputPredictedField': u'auto',\n",
       "  u'predictedField': u'c1',\n",
       "  u'predictionSteps': [1]},\n",
       " u'modelConfig': {u'aggregationInfo': {u'days': 0,\n",
       "   u'fields': [],\n",
       "   u'hours': 0,\n",
       "   u'microseconds': 0,\n",
       "   u'milliseconds': 0,\n",
       "   u'minutes': 0,\n",
       "   u'months': 0,\n",
       "   u'seconds': 0,\n",
       "   u'weeks': 0,\n",
       "   u'years': 0},\n",
       "  u'model': u'HTMPrediction',\n",
       "  u'modelParams': {u'anomalyParams': {u'anomalyCacheRecords': None,\n",
       "    u'autoDetectThreshold': None,\n",
       "    u'autoDetectWaitRecords': 5030},\n",
       "   u'clEnable': False,\n",
       "   u'clParams': {u'alpha': 0.035828933612158,\n",
       "    u'regionName': u'SDRClassifierRegion',\n",
       "    u'steps': u'1',\n",
       "    u'verbosity': 0},\n",
       "   u'inferenceType': u'TemporalAnomaly',\n",
       "   u'sensorParams': {u'encoders': {u'c0_dayOfWeek': None,\n",
       "     u'c0_timeOfDay': {u'fieldname': u'c0',\n",
       "      u'name': u'c0',\n",
       "      u'timeOfDay': [21, 9.49],\n",
       "      u'type': u'DateEncoder'},\n",
       "     u'c0_weekend': None,\n",
       "     u'c1': {u'fieldname': u'c1',\n",
       "      u'name': u'c1',\n",
       "      'resolution': 0.81866016610769232,\n",
       "      u'seed': 42,\n",
       "      u'type': u'RandomDistributedScalarEncoder'}},\n",
       "    u'sensorAutoReset': None,\n",
       "    u'verbosity': 0},\n",
       "   u'spEnable': True,\n",
       "   u'spParams': {u'boostStrength': 0.0,\n",
       "    u'columnCount': 2048,\n",
       "    u'globalInhibition': 1,\n",
       "    u'inputWidth': 0,\n",
       "    u'numActiveColumnsPerInhArea': 40,\n",
       "    u'potentialPct': 0.8,\n",
       "    u'seed': 1956,\n",
       "    u'spVerbosity': 0,\n",
       "    u'spatialImp': u'cpp',\n",
       "    u'synPermActiveInc': 0.003,\n",
       "    u'synPermConnected': 0.2,\n",
       "    u'synPermInactiveDec': 0.0005},\n",
       "   u'tmEnable': True,\n",
       "   u'tmParams': {u'activationThreshold': 13,\n",
       "    u'cellsPerColumn': 32,\n",
       "    u'columnCount': 2048,\n",
       "    u'globalDecay': 0.0,\n",
       "    u'initialPerm': 0.21,\n",
       "    u'inputWidth': 2048,\n",
       "    u'maxAge': 0,\n",
       "    u'maxSegmentsPerCell': 128,\n",
       "    u'maxSynapsesPerSegment': 32,\n",
       "    u'minThreshold': 10,\n",
       "    u'newSynapseCount': 20,\n",
       "    u'outputType': u'normal',\n",
       "    u'pamLength': 3,\n",
       "    u'permanenceDec': 0.1,\n",
       "    u'permanenceInc': 0.1,\n",
       "    u'seed': 1960,\n",
       "    u'temporalImp': u'cpp',\n",
       "    u'verbosity': 0},\n",
       "   u'trainSPNetOnlyIfRequested': False},\n",
       "  u'predictAheadTime': None,\n",
       "  u'version': 1}}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'boostStrength': 0.0,\n",
       " u'columnCount': 2048,\n",
       " u'globalInhibition': 1,\n",
       " u'inputWidth': 0,\n",
       " u'numActiveColumnsPerInhArea': 40,\n",
       " u'potentialPct': 0.8,\n",
       " u'seed': 1956,\n",
       " u'spVerbosity': 0,\n",
       " u'spatialImp': u'cpp',\n",
       " u'synPermActiveInc': 0.003,\n",
       " u'synPermConnected': 0.2,\n",
       " u'synPermInactiveDec': 0.0005}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelParams['modelConfig']['modelParams']['spParams']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "selectedSPparams = {\n",
    "    u'boostStrength': 0.0,\n",
    "#     u'columnCount': 2048,\n",
    "    u'globalInhibition': 1,\n",
    "#     u'inputWidth': 0,\n",
    "    u'numActiveColumnsPerInhArea': 40,\n",
    "    u'potentialPct': 0.8,\n",
    "    u'seed': 1956,\n",
    "    u'spVerbosity': 0,\n",
    "#     u'spatialImp': u'cpp',\n",
    "    u'synPermActiveInc': 0.003,\n",
    "    u'synPermConnected': 0.2,\n",
    "    u'synPermInactiveDec': 0.0005,\n",
    "   ### Changes\n",
    "    u'inputDimensions': (len(data[0]['inputSDR']), ),\n",
    "    u'columnDimensions': modelParams['modelConfig']['modelParams']['spParams']['columnCount'], \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init SP\n",
    "sp = SpatialPooler(**selectedSPparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print SP\n",
    "\n",
    "cols = []\n",
    "connections = []\n",
    "\n",
    "for col in xrange(sp.getColumnDimensions()):\n",
    "    connected = np.zeros(len(data[0]['inputSDR']), dtype=\"int\")\n",
    "    sp.getConnectedSynapses(col, connected)\n",
    "    cols.append(col)\n",
    "    connections.append(connected)\n",
    "\n",
    "spSDR = dict(zip(cols, connections))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SP Shape:2048; 961\n"
     ]
    }
   ],
   "source": [
    "print \"SP Shape:\" + str(len(spSDR)) + \"; \" + str(len(spSDR[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The active bits (min-columns) are set by calculating the *overlapping score* with the input vector.  \n",
    "*Overalpping score* = `inputSDR` * `spSDR\\[column]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idx_active_cols(inputArr):\n",
    "    \"\"\"\n",
    "    This function takes an 1d or nd-array and returns a 1d-array with the index for ACTIVE bits/columns: \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    inputArr:   np.array (1d or nD)\n",
    "            \n",
    "    Output\n",
    "    ------\n",
    "    tmActiveColsIdx: 1d np.arraz\n",
    "        Array with index of active cols.\n",
    "        \n",
    "    \"\"\"\n",
    "    #tmObject.reshape(tmObject.numberOfCols, tm.cellsPerColumn)\n",
    "    activeColsVec = []  # initialize vector\n",
    "\n",
    "    for i in range(inputArr.shape[0]):\n",
    "        # assign 1 if any 1 (active cell) in the column,\n",
    "        # 0 otherwise\n",
    "        if np.any(inputArr[i]>0):\n",
    "        # if np.any(tm.compute(spSDR[track[3]['sp_active']], enableLearn=True, enableInference=True).reshape(256, 3)[i]>0):\n",
    "            activeColsVec.append(1)\n",
    "        else:\n",
    "            activeColsVec.append(0)\n",
    "    # return index of active Columns        \n",
    "    tmActiveColsIdx = np.flatnonzero(np.array(activeColsVec))\n",
    "    return tmActiveColsIdx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Compute` returns the to 40 active cols, as defined in:  \n",
    "`MODEL_PARAMS['modelParams']['spParams']['numActiveColumnsPerInhArea']=40`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all the SP-columns active for every input\n",
    "\n",
    "for i in xrange(len(data)):\n",
    "    output = np.zeros(sp.getColumnDimensions(), dtype=\"int\")\n",
    "    sp.compute(data[i]['inputSDR'], learn=False, activeArray=output)\n",
    "    data[i]['sp_active'] = idx_active_cols(output) #save to dict\n",
    "    \n",
    "#     print \"obs\" + str(i) + \", Active col: \", str(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1557, 1567, 1569, 1578, 1581, 1583, 1584, 1587, 1589, 1591, 1592,\n",
       "       1593, 1594, 1596, 1603, 1912, 1919, 1923, 1929, 1930, 1931, 1933,\n",
       "       1934, 1937, 1938, 1939, 1940, 1942, 1946, 1948, 1951, 1954, 1956,\n",
       "       1958, 1959, 1961, 1962, 1963, 1965, 1966])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]['sp_active']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['inputSDR',\n",
       " 'label',\n",
       " 'inputVal',\n",
       " 'sp_active',\n",
       " 'inputTs',\n",
       " 'inputSDRts',\n",
       " 'inputSDRval']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0, 809], [810, 960])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputTsIdx, inputValIdx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obs22692\n",
      "Active col:  [ 209  221  222  223  226  227  231  236  240  243  244  253  257  258 1975\n",
      " 1977 1978 1981 1982 1983 1986 1987 1988 1989 1991 1995 1999 2000 2002 2003\n",
      " 2005 2006 2007 2008 2012 2013 2016 2017 2018 2019]\n",
      "obs22692\n",
      "Active col:  [ 209  221  222  223  226  227  231  236  240  243  244  253  257  258 1975\n",
      " 1977 1978 1981 1982 1983 1986 1987 1988 1989 1991 1995 1999 2000 2002 2003\n",
      " 2005 2006 2007 2008 2012 2013 2016 2017 2018 2019]\n",
      "obs22692\n",
      "Active col:  [ 209  221  222  223  226  227  231  236  240  243  244  253  257  258 1975\n",
      " 1977 1978 1981 1982 1983 1986 1987 1988 1989 1991 1995 1999 2000 2002 2003\n",
      " 2005 2006 2007 2008 2012 2013 2016 2017 2018 2019]\n",
      "obs22692\n",
      "Active col:  [ 209  221  222  223  226  227  231  236  240  243  244  253  257  258 1975\n",
      " 1977 1978 1981 1982 1983 1986 1987 1988 1989 1991 1995 1999 2000 2002 2003\n",
      " 2005 2006 2007 2008 2012 2013 2016 2017 2018 2019]\n",
      "obs22692\n",
      "Active col:  [ 209  221  222  223  226  227  231  236  240  243  244  253  257  258 1975\n",
      " 1977 1978 1981 1982 1983 1986 1987 1988 1989 1991 1995 1999 2000 2002 2003\n",
      " 2005 2006 2007 2008 2012 2013 2016 2017 2018 2019]\n"
     ]
    }
   ],
   "source": [
    "for _ in xrange(5):\n",
    "    print \"obs\" + str(i)\n",
    "    print \"Active col: \", data[i]['sp_active']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Permanence\n",
    "# permanence = []\n",
    "\n",
    "# for i in xrange(sp.getColumnDimensions()):\n",
    "#     p = []\n",
    "#     sp.getPermanence(i, p)\n",
    "#     permanence.append(np.array(p))\n",
    "\n",
    "# permanence[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For `Permanence > Threshold` we have a connection to the *inputSDR*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarizing SP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputSDR:  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "SDR active bits [731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748\n",
      " 749 750 751 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914\n",
      " 915 916 917 918 919 920]\n",
      "SP active col:  [1557 1567 1569 1578 1581 1583 1584 1587 1589 1591 1592 1593 1594 1596 1603\n",
      " 1912 1919 1923 1929 1930 1931 1933 1934 1937 1938 1939 1940 1942 1946 1948\n",
      " 1951 1954 1956 1958 1959 1961 1962 1963 1965 1966]\n",
      "\n",
      "------------\n",
      "SP active col: 1557; \tOverlappin bits: 10\n",
      "SP active col: 1567; \tOverlappin bits: 10\n",
      "SP active col: 1569; \tOverlappin bits: 9\n",
      "SP active col: 1578; \tOverlappin bits: 12\n",
      "SP active col: 1581; \tOverlappin bits: 9\n",
      "SP active col: 1583; \tOverlappin bits: 10\n",
      "SP active col: 1584; \tOverlappin bits: 10\n",
      "SP active col: 1587; \tOverlappin bits: 11\n",
      "SP active col: 1589; \tOverlappin bits: 10\n",
      "SP active col: 1591; \tOverlappin bits: 11\n",
      "SP active col: 1592; \tOverlappin bits: 9\n",
      "SP active col: 1593; \tOverlappin bits: 9\n",
      "SP active col: 1594; \tOverlappin bits: 9\n",
      "SP active col: 1596; \tOverlappin bits: 11\n",
      "SP active col: 1603; \tOverlappin bits: 10\n",
      "SP active col: 1912; \tOverlappin bits: 9\n",
      "SP active col: 1919; \tOverlappin bits: 11\n",
      "SP active col: 1923; \tOverlappin bits: 9\n",
      "SP active col: 1929; \tOverlappin bits: 10\n",
      "SP active col: 1930; \tOverlappin bits: 9\n",
      "SP active col: 1931; \tOverlappin bits: 9\n",
      "SP active col: 1933; \tOverlappin bits: 10\n",
      "SP active col: 1934; \tOverlappin bits: 10\n",
      "SP active col: 1937; \tOverlappin bits: 15\n",
      "SP active col: 1938; \tOverlappin bits: 9\n",
      "SP active col: 1939; \tOverlappin bits: 10\n",
      "SP active col: 1940; \tOverlappin bits: 9\n",
      "SP active col: 1942; \tOverlappin bits: 13\n",
      "SP active col: 1946; \tOverlappin bits: 10\n",
      "SP active col: 1948; \tOverlappin bits: 10\n",
      "SP active col: 1951; \tOverlappin bits: 9\n",
      "SP active col: 1954; \tOverlappin bits: 8\n",
      "SP active col: 1956; \tOverlappin bits: 8\n",
      "SP active col: 1958; \tOverlappin bits: 12\n",
      "SP active col: 1959; \tOverlappin bits: 9\n",
      "SP active col: 1961; \tOverlappin bits: 8\n",
      "SP active col: 1962; \tOverlappin bits: 8\n",
      "SP active col: 1963; \tOverlappin bits: 8\n",
      "SP active col: 1965; \tOverlappin bits: 8\n",
      "SP active col: 1966; \tOverlappin bits: 8\n"
     ]
    }
   ],
   "source": [
    "entry = 0\n",
    "\n",
    "print \"inputSDR: \", data[entry]['inputSDR']\n",
    "print \"SDR active bits\", idx_active_cols(data[entry]['inputSDR'])\n",
    "print \"SP active col: \", data[entry]['sp_active']\n",
    "print \"\\n\", \"------------\"\n",
    "\n",
    "for i in data[entry]['sp_active']:\n",
    "    print \"SP active col: \" + str(i) + \"; \\tOverlappin bits: \" + str(sum(spSDR[i] * data[entry]['inputSDR']))\n",
    "\n",
    "#print \"Pemanence winning col: \", permanence[track[0]['sp_active']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temporal Pooler\n",
    "\n",
    "[link to wiki](http://nupic.docs.numenta.org/1.0.3/api/algorithms/sequence-memory.html#nupic.algorithms.backtracking_tm_cpp.BacktrackingTMCPP)\n",
    "\n",
    "Load `MODEL_PARAMS` fors TM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'activationThreshold': 13,\n",
       " u'cellsPerColumn': 32,\n",
       " u'columnCount': 2048,\n",
       " u'globalDecay': 0.0,\n",
       " u'initialPerm': 0.21,\n",
       " u'inputWidth': 2048,\n",
       " u'maxAge': 0,\n",
       " u'maxSegmentsPerCell': 128,\n",
       " u'maxSynapsesPerSegment': 32,\n",
       " u'minThreshold': 10,\n",
       " u'newSynapseCount': 20,\n",
       " u'outputType': u'normal',\n",
       " u'pamLength': 3,\n",
       " u'permanenceDec': 0.1,\n",
       " u'permanenceInc': 0.1,\n",
       " u'seed': 1960,\n",
       " u'temporalImp': u'cpp',\n",
       " u'verbosity': 0}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelParams['modelConfig']['modelParams']['tmParams']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "selectedTMparams = { \n",
    "    'activationThreshold': 20,\n",
    "    'cellsPerColumn': 32,\n",
    "#     'columnCount': 2048,\n",
    "    'globalDecay': 0.0,\n",
    "    'initialPerm': 0.24,\n",
    "#     'inputWidth': 2048,\n",
    "    'maxAge': 0,\n",
    "    'maxSegmentsPerCell': 128,\n",
    "    'maxSynapsesPerSegment': 128,\n",
    "    'minThreshold': 13,\n",
    "    'newSynapseCount': 31,\n",
    "    'outputType': 'normal',\n",
    "    'permanenceDec': 0.008,\n",
    "    'permanenceInc': 0.04,\n",
    "#     'predictedSegmentDecrement': 0.001,\n",
    "    'seed': 1960,\n",
    "#     'temporalImp': 'tm_cpp',\n",
    "    'verbosity': 0,\n",
    "    ### Changes\n",
    "    'numberOfCols': modelParams['modelConfig']['modelParams']['tmParams']['columnCount'],\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To better understand the example we suggest to set `verbosity=5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nupic.algorithms.backtracking_tm import BacktrackingTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init TM\n",
    "tm = BacktrackingTM(**selectedTMparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For every input, send the ACTIVE_sp_columns to TM as 0/1 vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in xrange(len(data)): #len(data)\n",
    "    # for every input, select the 'sp_active' col and get active bit in very col  \n",
    "     sp4tm = [spSDR.get(sp) for sp in data[i]['sp_active']]\n",
    "    # stack all the arrays in matrix and sum to see overlap \n",
    "     sp4tm = sum(np.array(sp4tm))\n",
    "    # if overlap 1 send active cols aove \n",
    "     sp4tm[sp4tm>0] = 1\n",
    "    \n",
    "    # send the vector with the SP active cols to TM\n",
    "     data[i]['sp4tm'] = sp4tm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: send the  input to the temporal memory for learning\n",
    "\n",
    "# # Send each input in the sequence in order\n",
    "# for i in xrange(len(data[:1000])):\n",
    "\n",
    "#     # The compute method performs one step of learning and/or inference. Note:\n",
    "#     # here we just perform learning but you can perform prediction/inference and\n",
    "#     # learning in the same step if you want (online learning).\n",
    "#     tm_output = tm.compute(data[i]['sp4tm'], enableLearn=True, enableInference=True)\n",
    "#     # This function prints the segments associated with every cell.$$$$\n",
    "#     # If you really want to understand the TP, uncomment this line. By following\n",
    "#     # every step you can get an excellent understanding for exactly how the TP\n",
    "#     # learns.\n",
    "#     #tm.printCells()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the first 3000 entries to learn, test on the rest:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anomaly Score\n",
    "\n",
    "[link](http://nupic.docs.numenta.org/stable/guides/anomaly-detection.html)\n",
    "\n",
    "The algorithm for the anomaly score is as follows:  \n",
    "\n",
    "AS = |A_(t) - (P_(t-1) cross A_(t))|  / |A_(t)|  \n",
    "\n",
    "A_(t):   Predicted columns at time t  \n",
    "P_(t-1): Active columns at time t\n",
    "\n",
    "**Note**: Here, a predicted column is a column with a non-zero confidence value. This is not exactly the same as having a cell in the predicted state. For more information, refer the predicted cells vs. confidences section below.  \n",
    "\n",
    "...to compute the confidences for a cell, the Temporal Pooler uses the soft match count (the number of active synapses, regardless of the permanence values). Therefore, the set of columns with non-zero confidences will always be a superset of the columns containing predicted cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeRawAnomalyScore(activeColumns, prevPredictedColumns):\n",
    "  \"\"\"Computes the raw anomaly score.\n",
    "\n",
    "  The raw anomaly score is the fraction of active columns not predicted.\n",
    "\n",
    "  :param activeColumns: array of active column indices\n",
    "  :param prevPredictedColumns: array of columns indices predicted in prev step\n",
    "  :returns: anomcaly score 0..1 (float)\n",
    "  \"\"\"\n",
    "  nActiveColumns = len(activeColumns)\n",
    "  if nActiveColumns > 0:\n",
    "    # Test whether each element of a 1-D array is also present in a second\n",
    "    # array. Sum to get the total # of columns that are active and were\n",
    "    # predicted.\n",
    "    score = np.in1d(activeColumns, prevPredictedColumns).sum()\n",
    "    # Get the percent of active columns that were NOT predicted, that is\n",
    "    # our anomaly score.\n",
    "    score = (nActiveColumns - score) / float(nActiveColumns)\n",
    "  else:\n",
    "    # There are no active columns.\n",
    "    score = 0.0\n",
    "\n",
    "  return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility routine for printing the input vector\n",
    "def formatRow(x):\n",
    "    s = ''\n",
    "    for c in range(len(x)):\n",
    "        if c > 0 and c % 10 == 0:\n",
    "            s += ' '\n",
    "        s += str(x[c])\n",
    "    s += ' '\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anomaly Likelihood\n",
    "\n",
    "``` \n",
    "from nupic.algorithms.anomaly_likelihood import AnomalyLikelihood\n",
    "\n",
    "class AnomalyLikelihood(claLearningPeriod=None,\n",
    "                       learningPeriod=288,\n",
    "                       estimationSamples=100,\n",
    "                       historicWindowSize=8640,\n",
    "                       reestimationPeriod=100)):\n",
    "\n",
    "    NOTE: Anomaly likelihood scores are reported at a flat 0.5 for\n",
    "    learningPeriod + estimationSamples iterations.\n",
    "\n",
    "    claLearningPeriod and learningPeriod are specifying the same variable,\n",
    "    although claLearningPeriod is a deprecated name for it.\n",
    "\n",
    "    :param learningPeriod: (claLearningPeriod: deprecated) - (int) the number of\n",
    "      iterations required for the algorithm to learn the basic patterns in the\n",
    "      dataset and for the anomaly score to 'settle down'. The default is based\n",
    "      on empirical observations but in reality this could be larger for more\n",
    "      complex domains. The downside if this is too large is that real anomalies\n",
    "      might get ignored and not flagged.\n",
    "\n",
    "    :param estimationSamples: (int) the number of reasonable anomaly scores\n",
    "      required for the initial estimate of the Gaussian. The default of 100\n",
    "      records is reasonable - we just need sufficient samples to get a decent\n",
    "      estimate for the Gaussian. It's unlikely you will need to tune this since\n",
    "      the Gaussian is re-estimated every 10 iterations by default.\n",
    "\n",
    "    :param historicWindowSize: (int) size of sliding window of historical\n",
    "      data points to maintain for periodic reestimation of the Gaussian. Note:\n",
    "      the default of 8640 is based on a month's worth of history at 5-minute\n",
    "      intervals.\n",
    "\n",
    "    :param reestimationPeriod: (int) how often we re-estimate the Gaussian\n",
    "      distribution. The ideal is to re-estimate every iteration but this is a\n",
    "      performance hit. In general the system is not very sensitive to this\n",
    "      number as long as it is small relative to the total number of records\n",
    "      processed.\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nupic.algorithms.anomaly_likelihood import AnomalyLikelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalyLikelihood = AnomalyLikelihood()\n",
    "\n",
    "# for i in xrange(100):  # len(data)\n",
    "#     # Compute the Anomaly Likelihood\n",
    "#     likelihood = anomalyLikelihood.anomalyProbability(data[i]['inputVal'], data[i]['AnomalyScore'], data[i]['inputTs'])\n",
    "#     #likelihood = anomalyLikelihood.anomalyProbability(inputData[\"value\"], anomalyScore, inputData[\"dttm\"])\n",
    "#     logLikelihood = anomalyLikelihood.computeLogLikelihood(likelihood)\n",
    "#     data[i]['lh'] = likelihood    \n",
    "#     data[i]['logLH'] = likelihood\n",
    "#     #if likelihood > 0.9999:\n",
    "#         #print \"Anomaly detected:\", track[i]['inputVal'], track[i]['inputTs'], likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-2d85d72c4ec7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;31m#data[i]['TMpredictedCells_2'] = tm.infPredictedState['t-1']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TMactiveCells'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfActiveState\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m't'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'AnomalyScore'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomputeRawAnomalyScore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx_active_cols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfActiveState\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m't'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx_active_cols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcellConfidence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m't-1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0;31m#data[i]['AnomalyScore2'] = computeRawAnomalyScore(idx_active_cols(tm.infActiveState['t']), idx_active_cols(tm.infPredictedState['t-1']))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mlikelihood\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manomalyLikelihood\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manomalyProbability\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'inputVal'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'AnomalyScore'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'inputTs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-34-75a9e2f03859>\u001b[0m in \u001b[0;36midx_active_cols\u001b[0;34m(inputArr)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# assign 1 if any 1 (active cell) in the column,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# 0 otherwise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputArr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0;31m# if np.any(tm.compute(spSDR[track[3]['sp_active']], enableLearn=True, enableInference=True).reshape(256, 3)[i]>0):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mactiveColsVec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/alessandro/.local/share/virtualenvs/nupic-yn_sXeWq/local/lib/python2.7/site-packages/numpy/core/fromnumeric.pyc\u001b[0m in \u001b[0;36many\u001b[0;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[1;32m   1948\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkeepdims\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NoValue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1949\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'keepdims'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/alessandro/.local/share/virtualenvs/nupic-yn_sXeWq/local/lib/python2.7/site-packages/numpy/core/_methods.pyc\u001b[0m in \u001b[0;36m_any\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_prod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0m_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Step 4: send the same sequence of vectors and look at predictions made by\n",
    "# temporal memory\n",
    "\n",
    "\n",
    "for i in xrange(len(data)):  # len(data) \n",
    "#     print \"\\n\\n--------\" + str(i) + \"-----------\"\n",
    "#     print \"Raw input vector\\n\",formatRow(track[i]['sp4tm'])\n",
    "\n",
    "    # Send each vector to the TP, with learning turned off\n",
    "    tm.compute(data[i]['sp4tm'], enableLearn=True, enableInference=True)\n",
    "\n",
    "    # This method prints out the active state of each cell followed by the\n",
    "    # predicted state of each cell. For convenience the cells are grouped\n",
    "    # 10 at a time. When there are multiple cells per column the printout\n",
    "    # is arranged so the cells in a column are stacked together\n",
    "    #\n",
    "    # What you should notice is that the columns where active state is 1\n",
    "    # represent the SDR for the current input pattern and the columns where\n",
    "    # predicted state is 1 represent the SDR for the next expected pattern\n",
    "#     print \"\\nAll the active and predicted cells:\"\n",
    "#     tm.printStates(printPrevious=False, printLearnState=False)\n",
    "\n",
    "    # tm.getPredictedState() gets the predicted cells.\n",
    "    # predictedCells[c][i] represents the state of the i'th cell in the c'th\n",
    "    # column. To see if a column is predicted, we can simply take the OR\n",
    "    # across all the cells in that column. In numpy we can do this by taking\n",
    "    # the max along axis 1.\n",
    "#     print \"\\n\\nThe following columns are predicted by the temporal memory. This\"\n",
    "#     print \"should correspond to columns in the *next* item in the sequence.\"\n",
    "#     predictedCells = tm.getPredictedState()\n",
    "#     print formatRow(predictedCells.max(axis=1).nonzero())\n",
    "    \n",
    "    ## ANOMALY SCORE\n",
    "    data[i]['TMpredictedCells'] = tm.cellConfidence['t-1']\n",
    "    #data[i]['TMpredictedCells_2'] = tm.infPredictedState['t-1']\n",
    "    data[i]['TMactiveCells'] = tm.infActiveState['t']           \n",
    "    data[i]['AnomalyScore'] = computeRawAnomalyScore(idx_active_cols(tm.infActiveState['t']), idx_active_cols(tm.cellConfidence['t-1']))\n",
    "    #data[i]['AnomalyScore2'] = computeRawAnomalyScore(idx_active_cols(tm.infActiveState['t']), idx_active_cols(tm.infPredictedState['t-1']))\n",
    "    likelihood = anomalyLikelihood.anomalyProbability(data[i]['inputVal'], data[i]['AnomalyScore'], data[i]['inputTs'])\n",
    "    #likelihood = anomalyLikelihood.anomalyProbability(inputData[\"value\"], anomalyScore, inputData[\"dttm\"])\n",
    "    logLikelihood = anomalyLikelihood.computeLogLikelihood(likelihood)\n",
    "    data[i]['lh'] = likelihood    \n",
    "    data[i]['logLH'] = logLikelihood\n",
    "    \n",
    "    if likelihood > 0.9999:\n",
    "        data[i]['flag'] = 1\n",
    "    else:\n",
    "        data[i]['flag'] = 0\n",
    "    \n",
    "    ## Anomaly Attribution\n",
    "    # check overlapping columns\n",
    "    idxOverlap = np.in1d(idx_active_cols(tm.infActiveState['t']), idx_active_cols(tm.cellConfidence['t-1']))\n",
    "    # shows actual active column that do not overalp with prediction\n",
    "    data[i]['idxAS'] = idx_active_cols(tm.infActiveState['t'])[idxOverlap == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vAnomalyScore = []\n",
    "# #vAnomalyScore2 = []\n",
    "# vLH = []\n",
    "# vLogLH = []\n",
    "# vFlag = []\n",
    "\n",
    "# for i in xrange(len(data)):\n",
    "#     vAnomalyScore.append(data[i].get('AnomalyScore'))    \n",
    "#  #   vAnomalyScore2.append(track[i].get('AnomalyScore'))    \n",
    "#     vLH.append(data[i].get('lh'))\n",
    "#     vLogLH.append(data[i].get('logLH'))\n",
    "#     vFlag.append(data[i].get('flag'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-4ac22417ede5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvAnomalyScore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvLH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvLogLH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvFlag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# pd.Series(vAnomalyScore).plot()\n",
    "# pd.Series(vLH).plot()\n",
    "# pd.Series(vLogLH).plot()\n",
    "# pd.Series(vFlag).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_records(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.dates as mdates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idcs = df.label[df.label==1].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1000\n",
    "b = 2000\n",
    "\n",
    "fig, ax = plt.subplots(2, sharex=True, figsize=(15,7))\n",
    "ax[0].plot(df.inputVal[a:b], color='b')\n",
    "ax[0].set(ylabel='temperature_C', title=PATH_relative)\n",
    "#ax[0].vlines(idcs[a:b], 0, 1, transform=ax[0].get_xaxis_transform(), colors='y')\n",
    "#ax[0].vlines(anomalies_gt, 0, 1, transform=ax[0].get_xaxis_transform(), colors='b', linestyles={'dashed'})\n",
    "ax[0].plot(df.label[a:b], color='y', label='groundtruth')\n",
    "\n",
    "ax[1].plot(df.AnomalyScore[a:b], label='anomaly_score')\n",
    "ax[1].set(ylabel='Anomaly Score and LH')\n",
    "ax[1].plot(df.lh[a:b], color='r', alpha=0.5, label='anomaly_LH')\n",
    "ax[1].plot(df.logLH[a:b], color='c', alpha=0.5, label='logLH')\n",
    "ax[1].axhline(y=0.5, \n",
    "              color='r', linestyle='--', linewidth=0.4)\n",
    "              #xmin=data.anomaly_likelihood.index[a], xmax=data.anomaly_likelihood.index[b])\n",
    "#ax[1].vlines(idcs[a:b], 0, 1, transform=ax[1].get_xaxis_transform(), alpha=0.9, colors='y', label='groundtruth')\n",
    "ax[1].plot(df.label[a:b], color='y', label='groundtruth')\n",
    "ax[1].plot(df.flag[a:b], color='k', label='flag')\n",
    "ax[1].set(xlabel='time (5min)')\n",
    "ax[1].legend(loc=1)\n",
    "\n",
    "#set ticks every week\n",
    "ax[1].xaxis.set_major_locator(mdates.WeekdayLocator())\n",
    "#set major ticks format\n",
    "ax[1].xaxis.set_major_formatter(mdates.DateFormatter('%b %d'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save & Load Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import copy\n",
    "# dataOut = copy.deepcopy(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # to dump to .json we need to change array to lists and datetime to str\n",
    "\n",
    "# for i in xrange(len(dataOut)):\n",
    "#     for k,v in dataOut[i].items():\n",
    "#         if isinstance(v, np.ndarray):\n",
    "#             #print dataOut[i][k].tolist\n",
    "#             dataOut[i][k] = dataOut[i][k].tolist()\n",
    "#         if isinstance(v, datetime.datetime):\n",
    "#             dataOut[i][k] = str(dataOut[i][k])\n",
    "#         else:\n",
    "#             pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = 'univ_getScalar_spLearnFalse_tmLearnAll.json'\n",
    "# with open(filename, 'w') as f:\n",
    "#     json.dump(dataOut, f, indent=4, sort_keys=True, separators=(',', ': '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redirecting Anomaly Score\n",
    "\n",
    "Once an AS has been outputed, we want to know which are the cells the where unpredicted and causes the error to raise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------- 4 -----------  \n",
    "Raw input vector  \n",
    "0000010000 0010010000 0   \n",
    "\n",
    "==== PY Iteration: 56 =====  \n",
    "Previous learned pattern: array([ 0,  2,  4,  5, 19])  \n",
    "  \n",
    "Active cols: [ 5 12 15]  \n",
    "Inference Active state  \n",
    "0000000000 0000000000 0  \n",
    "0000010000 0000010000 0  \n",
    "0000000000 0010000000 0  \n",
    "  \n",
    "Inference Predicted state: [1, 7, 8, 14, 20]  \n",
    "0000000000 0000000000 0  \n",
    "0100000110 0000000000 1  \n",
    "0000000000 0000100000 0  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'backup': array([[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]], dtype=int8), 'candidate': array([[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]], dtype=int8), 't': array([[0, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 1, 0]], dtype=int8), 't-1': array([[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]], dtype=int8)}"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tm.infPredictedState # [t] predicted to be active next, [t-1] predicted before, for current input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  7  8 14 20] \n"
     ]
    }
   ],
   "source": [
    "predictedCells = tm.getPredictedState()\n",
    "print formatRow(predictedCells.max(axis=1).nonzero())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 1, 0]], dtype=int8)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tm.getPredictedState()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 0 Cell 1 : 2 segment(s)\n",
      "   Seg #0   ID:10    True 0.1785714 (  10/10  )    3 [1,1]1.00 [1,2]0.50 [7,1]1.00 [8,1]1.00 [8,2]0.50 [14,1]0.50 [14,2]1.00 [20,1]1.00\n",
      "   Seg #1   ID:36    True 0.0178571 (   1/1   )   23 [1,0]0.50 [7,0]0.50 [8,0]0.50 [14,0]0.50 [20,0]0.50\n",
      "Column 0 Cell 2 : 1 segment(s)\n",
      "   Seg #0   ID:23    True 0.1964286 (  11/11  )    1 [2,1]1.00 [10,1]1.00 [12,1]1.00 [16,2]1.00 [17,2]1.00 [20,1]1.00\n",
      "Column 1 Cell 1 : 2 segment(s)\n",
      "   Seg #0   ID:0     True 0.0178571 (   1/1   )   55\n",
      "  *Seg #1   ID:31    True 0.1785714 (  10/11  )    4 [5,1]1.00 [12,2]1.00 [15,1]1.00\n",
      "Column 1 Cell 2 : 1 segment(s)\n",
      "   Seg #0   ID:5     True 0.0178571 (   1/10  )   54 [1,1]0.50 [7,2]0.50 [8,1]0.50 [14,1]0.50 [20,2]0.50\n",
      "Column 2 Cell 1 : 3 segment(s)\n",
      "   Seg #0   ID:11    True 0.1785714 (  10/10  )    3 [1,1]1.00 [1,2]0.50 [7,1]1.00 [8,1]1.00 [8,2]0.50 [14,1]0.50 [14,2]1.00 [20,1]1.00\n",
      "   Seg #1   ID:17    True 0.1964286 (  11/11  )    2 [0,1]1.00 [2,1]1.00 [6,1]1.00 [11,1]0.50 [11,2]1.00 [13,2]1.00 [14,1]0.50 [14,2]1.00 [15,1]0.50 [15,2]1.00\n",
      "   Seg #2   ID:37    True 0.0178571 (   1/1   )   23 [1,0]0.50 [7,0]0.50 [8,0]0.50 [14,0]0.50 [20,0]0.50\n",
      "Column 2 Cell 2 : 1 segment(s)\n",
      "   Seg #0   ID:24    True 0.1964286 (  11/11  )    1 [2,1]1.00 [10,1]1.00 [12,1]1.00 [16,2]1.00 [17,2]1.00 [20,1]1.00\n",
      "Column 4 Cell 2 : 1 segment(s)\n",
      "   Seg #0   ID:25    True 0.1964286 (  11/11  )    1 [2,1]1.00 [10,1]1.00 [12,1]1.00 [16,2]1.00 [17,2]1.00 [20,1]1.00\n",
      "Column 5 Cell 1 : 2 segment(s)\n",
      "   Seg #0   ID:26    True 0.1964286 (  11/11  )    1 [2,1]1.00 [10,1]1.00 [12,1]1.00 [16,2]1.00 [17,2]1.00 [20,1]1.00\n",
      "   Seg #1   ID:28    True 0.1964286 (  11/11  )    0 [0,2]1.00 [2,2]1.00 [4,2]1.00 [5,1]1.00 [19,2]1.00\n",
      "Column 6 Cell 1 : 2 segment(s)\n",
      "   Seg #0   ID:12    True 0.1785714 (  10/10  )    3 [1,1]1.00 [1,2]0.50 [7,1]1.00 [8,1]1.00 [8,2]0.50 [14,1]0.50 [14,2]1.00 [20,1]1.00\n",
      "   Seg #1   ID:38    True 0.0178571 (   1/1   )   23 [1,0]0.50 [7,0]0.50 [8,0]0.50 [14,0]0.50 [20,0]0.50\n",
      "Column 7 Cell 1 : 2 segment(s)\n",
      "   Seg #0   ID:6     True 0.0178571 (   1/10  )   54 [1,1]0.50 [7,2]0.50 [8,1]0.50 [14,1]0.50 [20,2]0.50\n",
      "  *Seg #1   ID:32    True 0.1785714 (  10/11  )    4 [5,1]1.00 [12,2]1.00 [15,1]1.00\n",
      "Column 7 Cell 2 : 1 segment(s)\n",
      "   Seg #0   ID:1     True 0.0178571 (   1/1   )   55\n",
      "Column 8 Cell 1 : 2 segment(s)\n",
      "   Seg #0   ID:2     True 0.0178571 (   1/1   )   55\n",
      "  *Seg #1   ID:33    True 0.1785714 (  10/11  )    4 [5,1]1.00 [12,2]1.00 [15,1]1.00\n",
      "Column 8 Cell 2 : 1 segment(s)\n",
      "   Seg #0   ID:7     True 0.0178571 (   1/10  )   54 [1,1]0.50 [7,2]0.50 [8,1]0.50 [14,1]0.50 [20,2]0.50\n",
      "Column 10 Cell 1 : 1 segment(s)\n",
      "   Seg #0   ID:18    True 0.1964286 (  11/11  )    2 [0,1]1.00 [2,1]1.00 [6,1]1.00 [11,1]0.50 [11,2]1.00 [13,2]1.00 [14,1]0.50 [14,2]1.00 [15,1]0.50 [15,2]1.00\n",
      "Column 11 Cell 1 : 1 segment(s)\n",
      "   Seg #0   ID:39    True 0.0178571 (   1/1   )   23 [1,0]0.50 [7,0]0.50 [8,0]0.50 [14,0]0.50 [20,0]0.50\n",
      "Column 11 Cell 2 : 1 segment(s)\n",
      "   Seg #0   ID:13    True 0.1785714 (  10/10  )    3 [1,1]1.00 [1,2]0.50 [7,1]1.00 [8,1]1.00 [8,2]0.50 [14,1]0.50 [14,2]1.00 [20,1]1.00\n",
      "Column 12 Cell 1 : 1 segment(s)\n",
      "   Seg #0   ID:19    True 0.1964286 (  11/11  )    2 [0,1]1.00 [2,1]1.00 [6,1]1.00 [11,1]0.50 [11,2]1.00 [13,2]1.00 [14,1]0.50 [14,2]1.00 [15,1]0.50 [15,2]1.00\n",
      "Column 12 Cell 2 : 1 segment(s)\n",
      "   Seg #0   ID:29    True 0.1964286 (  11/11  )    0 [0,2]1.00 [2,2]1.00 [4,2]1.00 [5,1]1.00 [19,2]1.00\n",
      "Column 13 Cell 2 : 2 segment(s)\n",
      "   Seg #0   ID:14    True 0.1785714 (  10/10  )    3 [1,1]1.00 [1,2]0.50 [7,1]1.00 [8,1]1.00 [8,2]0.50 [14,1]0.50 [14,2]1.00 [20,1]1.00\n",
      "   Seg #1   ID:40    True 0.0178571 (   1/1   )   23 [1,0]0.50 [7,0]0.50 [8,0]0.50 [14,0]0.50 [20,0]0.50\n",
      "Column 14 Cell 1 : 3 segment(s)\n",
      "   Seg #0   ID:3     True 0.0178571 (   1/1   )   55\n",
      "   Seg #1   ID:8     True 0.0178571 (   1/1   )   54 [1,1]0.50 [7,2]0.50 [8,1]0.50 [14,1]0.50 [20,2]0.50\n",
      "   Seg #2   ID:41    True 0.0178571 (   1/1   )   23 [1,0]0.50 [7,0]0.50 [8,0]0.50 [14,0]0.50 [20,0]0.50\n",
      "Column 14 Cell 2 : 2 segment(s)\n",
      "   Seg #0   ID:15    True 0.1785714 (  10/10  )    3 [1,1]1.00 [1,2]0.50 [7,1]1.00 [8,1]1.00 [8,2]0.50 [14,1]0.50 [14,2]1.00 [20,1]1.00\n",
      "  *Seg #1   ID:34    True 0.1785714 (  10/11  )    4 [5,1]1.00 [12,2]1.00 [15,1]1.00\n",
      "Column 15 Cell 1 : 2 segment(s)\n",
      "   Seg #0   ID:30    True 0.1964286 (  11/11  )    0 [0,2]1.00 [2,2]1.00 [4,2]1.00 [5,1]1.00 [19,2]1.00\n",
      "   Seg #1   ID:42    True 0.0178571 (   1/1   )   23 [1,0]0.50 [7,0]0.50 [8,0]0.50 [14,0]0.50 [20,0]0.50\n",
      "Column 15 Cell 2 : 1 segment(s)\n",
      "   Seg #0   ID:16    True 0.1785714 (  10/10  )    3 [1,1]1.00 [1,2]0.50 [7,1]1.00 [8,1]1.00 [8,2]0.50 [14,1]0.50 [14,2]1.00 [20,1]1.00\n",
      "Column 16 Cell 2 : 1 segment(s)\n",
      "   Seg #0   ID:20    True 0.1964286 (  11/11  )    2 [0,1]1.00 [2,1]1.00 [6,1]1.00 [11,1]0.50 [11,2]1.00 [13,2]1.00 [14,1]0.50 [14,2]1.00 [15,1]0.50 [15,2]1.00\n",
      "Column 17 Cell 2 : 1 segment(s)\n",
      "   Seg #0   ID:21    True 0.1964286 (  11/11  )    2 [0,1]1.00 [2,1]1.00 [6,1]1.00 [11,1]0.50 [11,2]1.00 [13,2]1.00 [14,1]0.50 [14,2]1.00 [15,1]0.50 [15,2]1.00\n",
      "Column 19 Cell 2 : 1 segment(s)\n",
      "   Seg #0   ID:27    True 0.1964286 (  11/11  )    1 [2,1]1.00 [10,1]1.00 [12,1]1.00 [16,2]1.00 [17,2]1.00 [20,1]1.00\n",
      "Column 20 Cell 1 : 3 segment(s)\n",
      "   Seg #0   ID:9     True 0.0178571 (   1/10  )   54 [1,1]0.50 [7,2]0.50 [8,1]0.50 [14,1]0.50 [20,2]0.50\n",
      "   Seg #1   ID:22    True 0.1964286 (  11/11  )    2 [0,1]1.00 [2,1]1.00 [6,1]1.00 [11,1]0.50 [11,2]1.00 [13,2]1.00 [14,1]0.50 [14,2]1.00 [15,1]0.50 [15,2]1.00\n",
      "  *Seg #2   ID:35    True 0.1785714 (  10/11  )    4 [5,1]1.00 [12,2]1.00 [15,1]1.00\n",
      "Column 20 Cell 2 : 1 segment(s)\n",
      "   Seg #0   ID:4     True 0.0178571 (   1/1   )   55\n"
     ]
    }
   ],
   "source": [
    "for c in xrange(tm.numberOfCols):\n",
    "    for i in xrange(tm.cellsPerColumn):\n",
    "        if not False or tm.infPredictedState['t'][c, i]:\n",
    "            tm.printCell(c, i, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trackability - Feedforward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'inputSDR': array([0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=uint8),\n",
       "  'inputVal': 73.96732207,\n",
       "  'sp_active': 0},\n",
       " {'inputSDR': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=uint8),\n",
       "  'inputVal': 74.93588199999998,\n",
       "  'sp_active': 2},\n",
       " {'inputSDR': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0], dtype=uint8),\n",
       "  'inputVal': 76.12416182,\n",
       "  'sp_active': 1},\n",
       " {'inputSDR': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0], dtype=uint8),\n",
       "  'inputVal': 78.14070732,\n",
       "  'sp_active': 2},\n",
       " {'inputSDR': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0], dtype=uint8),\n",
       "  'inputVal': 79.32983574,\n",
       "  'sp_active': 3}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "track"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input SDR can be Decoded up to a certain granularity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73.96732207"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "track[0]['inputVal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'[70:80]': ([[73.888888888888886, 73.888888888888886]], '73.89')},\n",
       " ['[70:80]'])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vEnc.decode(track[0]['inputSDR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feed SP with `sp.compute(track[i]['inputSDR'], learn=True, activeArray=output)`,  \n",
    "and then the *Temporal Pooler* `inputSDR[track[i]['sp_active']]` = active columns in TM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trackability - Backwards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate *TM output* by feeding in the active columns of the *SP*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spSDR[track[0]['sp_active']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  1.,  0.,  1.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  1.,  0.,  1.,  0.,  0.,  0.,  1.,  0.,  1.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  1.,  0.,\n",
       "        0.,  0.,  1.,  0.,  0.,  1.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tm.compute(spSDR[track[0]['sp_active']], enableLearn=True, enableInference=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return index for ACTIVE columns in TM: \n",
    "tmActive = []\n",
    "\n",
    "for i in range(tm.infActiveState['t'].shape[0]):\n",
    "    # assign 1 if any 1 (active cell) in the column,\n",
    "    # 0 otherwise\n",
    "    if np.any(tm.infActiveState['t'][i]>0):\n",
    "        tmActive.append(1)\n",
    "    else:\n",
    "        tmActive.append(0)\n",
    "# return index of active Columns        \n",
    "tm_active = np.flatnonzero(np.array(tmActive))\n",
    "del(tmActive) # delete list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  7,  8, 14, 20])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tm_active"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build `spSDR[track[0]['sp_active']]` back:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp_active = np.zeros_like(spSDR[0])\n",
    "sp_active[tm_active] = 1\n",
    "sp_active"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the corresponding column in spSDR:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matching spSDR: [1]\n"
     ]
    }
   ],
   "source": [
    "idx = []\n",
    "for _ in spSDR:\n",
    "    i =+ 1\n",
    "    if np.array_equal(sp_active, spSDR[_]) == True:\n",
    "        idx.append(i)\n",
    "print \"matching spSDR:\", idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overlap:  [0, 1, 2, 1, 0]\n",
      "InputSDR[idx]:  2\n",
      "inputSDR:  [0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# calculate with which inputSDR, the active SP col has the higher overlap: \n",
    "\n",
    "\n",
    "for j in idx:\n",
    "    overlap = []\n",
    "    for i in xrange(len(track)):\n",
    "        overlap.append(sum(track[i]['inputSDR'] * spSDR[j]))\n",
    "        o = last_max_index(overlap)\n",
    "        \n",
    "    print \"overlap: \", str(overlap) +  \"\\nInputSDR[idx]: \", str(o)\n",
    "    print \"inputSDR: \", str(track[o]['inputSDR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function should be useful in case we have ties in the overlap-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_back_SP_to_SDR(lista):\n",
    "    '''\n",
    "    This fnc returns the indeces of the InputSDR/s that match \n",
    "    (have the highest overalpping score) the current SP the most.\n",
    "    \n",
    "    input:  copy of a list `list[:]` with the overlap score bw. \n",
    "            the winning spSDR[i] and the inputSDR[0:]   \n",
    "    output: 'match', a list, indeces of InputSDR in `track`\n",
    "    '''\n",
    "    \n",
    "    a = max(lista)\n",
    "    b = a\n",
    "    match = []\n",
    "    count = 0\n",
    "\n",
    "    while b == a:\n",
    "        i = lista.index(b)\n",
    "        out = lista.pop(i)\n",
    "        i = i+count  # fill the indexes popped out\n",
    "        match.append(i)\n",
    "        count += 1\n",
    "        b = max(lista)    \n",
    "    \n",
    "    return match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2]"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_back_SP_to_SDR(overlap[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputVal[2]: 76.12416182\n",
      "De-Encoder: ({'[70:80]': ([[76.111111111111114, 76.111111111111114]], '76.11')}, ['[70:80]'])\n",
      "-------\n"
     ]
    }
   ],
   "source": [
    "for i in match_back_SP_to_SDR(overlap[:]):\n",
    "    print \"inputVal[\" + str(i) + \"]: \" + str(track[i]['inputVal'])\n",
    "    print \"De-Encoder: \" + str(vEnc.decode(track[i]['inputSDR']))\n",
    "    print \"-------\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mleborgne/_git/nupic/src/nupic/datafiles/extra/hotgym/hotgym.csv\n",
      "\n",
      "gym,address,timestamp,consumption\n",
      "string,string,datetime,float\n",
      "S,,T,\n",
      "Balgowlah Platinum,Shop 67 197-215 Condamine Street Balgowlah 2093,2010-07-02 00:00:00.0,5.3\n",
      "Balgowlah Platinum,Shop 67 197-215 Condamine Street Balgowlah 2093,2010-07-02 00:15:00.0,5.5\n",
      "Balgowlah Platinum,Shop 67 197-215 Condamine Street Balgowlah 2093,2010-07-02 00:30:00.0,5.1\n",
      "Balgowlah Platinum,Shop 67 197-215 Condamine Street Balgowlah 2093,2010-07-02 00:45:00.0,5.3\n",
      "Balgowlah Platinum,Shop 67 197-215 Condamine Street Balgowlah 2093,2010-07-02 01:00:00.0,5.2\n"
     ]
    }
   ],
   "source": [
    "from pkg_resources import resource_filename\n",
    "\n",
    "datasetPath = resource_filename(\"nupic.datafiles\", \"extra/hotgym/hotgym.csv\")\n",
    "print datasetPath\n",
    "\n",
    "with open(datasetPath) as inputFile:\n",
    "    print\n",
    "    for _ in xrange(8):\n",
    "        print inputFile.next().strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data\n",
    "\n",
    "`FileRecordStream` - file reader for the NuPIC file format (CSV with three header rows, understands datetimes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Balgowlah Platinum', 'Shop 67 197-215 Condamine Street Balgowlah 2093', datetime.datetime(2010, 7, 2, 0, 0), 5.3]\n",
      "['Balgowlah Platinum', 'Shop 67 197-215 Condamine Street Balgowlah 2093', datetime.datetime(2010, 7, 2, 0, 15), 5.5]\n",
      "['Balgowlah Platinum', 'Shop 67 197-215 Condamine Street Balgowlah 2093', datetime.datetime(2010, 7, 2, 0, 30), 5.1]\n",
      "['Balgowlah Platinum', 'Shop 67 197-215 Condamine Street Balgowlah 2093', datetime.datetime(2010, 7, 2, 0, 45), 5.3]\n",
      "['Balgowlah Platinum', 'Shop 67 197-215 Condamine Street Balgowlah 2093', datetime.datetime(2010, 7, 2, 1, 0), 5.2]\n"
     ]
    }
   ],
   "source": [
    "from nupic.data.file_record_stream import FileRecordStream\n",
    "\n",
    "def getData():\n",
    "    return FileRecordStream(datasetPath)\n",
    "\n",
    "data = getData()\n",
    "for _ in xrange(5):\n",
    "    print data.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nupic.frameworks.opf.model_factory import ModelFactory\n",
    "model = ModelFactory.create(MODEL_PARAMS)\n",
    "model.enableInference({'predictedField': 'consumption'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  5.3\n",
      "prediction:  5.3\n",
      "input:  5.5\n",
      "prediction:  5.5\n",
      "input:  5.1\n",
      "prediction:  5.36\n",
      "input:  5.3\n",
      "prediction:  5.1\n",
      "input:  5.2\n",
      "prediction:  5.342\n",
      "input:  5.5\n",
      "prediction:  5.2994\n",
      "input:  4.5\n",
      "prediction:  5.35958\n",
      "input:  1.2\n",
      "prediction:  4.92\n",
      "input:  1.1\n",
      "prediction:  1.2\n",
      "input:  1.2\n",
      "prediction:  1.17\n",
      "input:  1.2\n",
      "prediction:  1.179\n",
      "input:  1.2\n",
      "prediction:  1.1853\n",
      "input:  1.2\n",
      "prediction:  1.18971\n",
      "input:  1.2\n",
      "prediction:  1.192797\n",
      "input:  1.1\n",
      "prediction:  1.1949579\n",
      "input:  1.2\n",
      "prediction:  1.16647053\n",
      "input:  1.1\n",
      "prediction:  1.176529371\n",
      "input:  1.2\n",
      "prediction:  1.1535705597\n",
      "input:  1.2\n",
      "prediction:  1.16749939179\n",
      "input:  1.1\n",
      "prediction:  1.17724957425\n",
      "input:  1.2\n",
      "prediction:  1.15407470198\n",
      "input:  6.0\n",
      "prediction:  1.16785229138\n",
      "input:  7.9\n",
      "prediction:  5.551706\n",
      "input:  8.4\n",
      "prediction:  6.2561942\n",
      "input:  10.6\n",
      "prediction:  6.89933594\n",
      "input:  12.4\n",
      "prediction:  10.6\n",
      "input:  12.1\n",
      "prediction:  12.4\n",
      "input:  12.4\n",
      "prediction:  12.31\n",
      "input:  11.4\n",
      "prediction:  12.337\n",
      "input:  11.2\n",
      "prediction:  10.84\n",
      "input:  10.8\n",
      "prediction:  10.948\n",
      "input:  12.0\n",
      "prediction:  10.9036\n",
      "input:  11.8\n",
      "prediction:  11.23252\n",
      "input:  11.9\n",
      "prediction:  11.402764\n",
      "input:  11.4\n",
      "prediction:  11.5519348\n",
      "input:  11.0\n",
      "prediction:  11.50635436\n",
      "input:  9.8\n",
      "prediction:  11.354448052\n",
      "input:  9.8\n",
      "prediction:  10.8881136364\n",
      "input:  10.8\n",
      "prediction:  10.5616795455\n",
      "input:  11.1\n",
      "prediction:  10.6331756818\n",
      "input:  11.1\n",
      "prediction:  10.7732229773\n",
      "input:  11.0\n",
      "prediction:  10.8712560841\n",
      "input:  10.7\n",
      "prediction:  10.9098792589\n",
      "input:  10.6\n",
      "prediction:  10.8469154812\n",
      "input:  10.3\n",
      "prediction:  10.7728408368\n",
      "input:  10.1\n",
      "prediction:  10.6309885858\n",
      "input:  12.9\n",
      "prediction:  10.4716920101\n",
      "input:  10.5\n",
      "prediction:  10.4716920101\n",
      "input:  9.7\n",
      "prediction:  10.480184407\n",
      "input:  9.7\n",
      "prediction:  10.2461290849\n",
      "input:  9.2\n",
      "prediction:  10.0822903594\n",
      "input:  9.2\n",
      "prediction:  9.81760325161\n",
      "input:  9.2\n",
      "prediction:  9.63232227613\n",
      "input:  9.3\n",
      "prediction:  9.50262559329\n",
      "input:  9.1\n",
      "prediction:  9.4418379153\n",
      "input:  9.0\n",
      "prediction:  9.33928654071\n",
      "input:  8.9\n",
      "prediction:  9.2375005785\n",
      "input:  9.0\n",
      "prediction:  9.13625040495\n",
      "input:  8.9\n",
      "prediction:  9.09537528346\n",
      "input:  8.9\n",
      "prediction:  9.03676269843\n",
      "input:  9.0\n",
      "prediction:  8.9957338889\n",
      "input:  9.2\n",
      "prediction:  8.99701372223\n",
      "input:  10.0\n",
      "prediction:  9.05790960556\n",
      "input:  10.7\n",
      "prediction:  9.34053672389\n",
      "input:  8.9\n",
      "prediction:  9.74837570672\n",
      "input:  9.0\n",
      "prediction:  9.49386299471\n",
      "input:  9.0\n",
      "prediction:  9.34570409629\n",
      "input:  9.3\n",
      "prediction:  9.24199286741\n",
      "input:  9.3\n",
      "prediction:  9.25939500718\n",
      "input:  9.1\n",
      "prediction:  9.27157650503\n",
      "input:  9.1\n",
      "prediction:  9.22010355352\n",
      "input:  9.1\n",
      "prediction:  9.18407248746\n",
      "input:  9.2\n",
      "prediction:  9.15885074122\n",
      "input:  9.4\n",
      "prediction:  9.17119551886\n",
      "input:  9.3\n",
      "prediction:  9.2398368632\n",
      "input:  9.3\n",
      "prediction:  9.25788580424\n",
      "input:  9.1\n",
      "prediction:  9.27052006297\n",
      "input:  9.1\n",
      "prediction:  9.21936404408\n",
      "input:  11.0\n",
      "prediction:  9.18355483085\n",
      "input:  9.0\n",
      "prediction:  9.7284883816\n",
      "input:  8.6\n",
      "prediction:  9.50994186712\n",
      "input:  3.0\n",
      "prediction:  9.50994186712\n",
      "input:  1.3\n",
      "prediction:  4.344\n",
      "input:  1.2\n",
      "prediction:  1.20749660397\n",
      "input:  1.3\n",
      "prediction:  1.20524762278\n",
      "input:  1.3\n",
      "prediction:  1.23367333594\n",
      "input:  1.3\n",
      "prediction:  1.25357133516\n",
      "input:  1.2\n",
      "prediction:  1.26749993461\n",
      "input:  1.3\n",
      "prediction:  1.24724995423\n",
      "input:  1.2\n",
      "prediction:  1.26307496796\n",
      "input:  1.3\n",
      "prediction:  1.24415247757\n",
      "input:  1.2\n",
      "prediction:  1.2609067343\n",
      "input:  1.3\n",
      "prediction:  1.24263471401\n",
      "input:  1.2\n",
      "prediction:  1.25984429981\n",
      "input:  1.1\n",
      "prediction:  1.24189100987\n",
      "input:  2.3\n",
      "prediction:  1.19932370691\n",
      "input:  5.5\n",
      "prediction:  3.7308\n",
      "input:  5.5\n",
      "prediction:  6.8366746106\n",
      "input:  5.8\n",
      "prediction:  6.43567222742\n",
      "input:  5.7\n",
      "prediction:  6.24497055919\n"
     ]
    }
   ],
   "source": [
    "data = getData()\n",
    "for _ in xrange(100):\n",
    "    record = dict(zip(data.getFieldNames(), data.next()))\n",
    "    print \"input: \", record[\"consumption\"]\n",
    "    result = model.run(record)\n",
    "    print \"prediction: \", result.inferences[\"multiStepBestPredictions\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-step prediction:  1.19932370691\n"
     ]
    }
   ],
   "source": [
    "print \"5-step prediction: \", result.inferences[\"multiStepBestPredictions\"][5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Params!\n",
    "MODEL_PARAMS = {\n",
    "    # Type of model that the rest of these parameters apply to.\n",
    "    'model': \"HTMPrediction\",\n",
    "\n",
    "    # Version that specifies the format of the config.\n",
    "    'version': 1,\n",
    "\n",
    "    # Intermediate variables used to compute fields in modelParams and also\n",
    "    # referenced from the control section.\n",
    "    'aggregationInfo': {   'days': 0,\n",
    "        'fields': [('consumption', 'sum')],\n",
    "        'hours': 1,\n",
    "        'microseconds': 0,\n",
    "        'milliseconds': 0,\n",
    "        'minutes': 0,\n",
    "        'months': 0,\n",
    "        'seconds': 0,\n",
    "        'weeks': 0,\n",
    "        'years': 0},\n",
    "\n",
    "    'predictAheadTime': None,\n",
    "\n",
    "    # Model parameter dictionary.\n",
    "    'modelParams': {\n",
    "        # The type of inference that this model will perform\n",
    "        'inferenceType': 'TemporalAnomaly',\n",
    "\n",
    "        'sensorParams': {\n",
    "            # Sensor diagnostic output verbosity control;\n",
    "            # if > 0: sensor region will print out on screen what it's sensing\n",
    "            # at each step 0: silent; >=1: some info; >=2: more info;\n",
    "            # >=3: even more info (see compute() in py/regions/RecordSensor.py)\n",
    "            'verbosity' : 0,\n",
    "\n",
    "            # Include the encoders we use\n",
    "            'encoders': {\n",
    "                u'timestamp_timeOfDay': {\n",
    "                    'fieldname': u'timestamp',\n",
    "                    'name': u'timestamp_timeOfDay',\n",
    "                    'timeOfDay': (21, 0.5),\n",
    "                    'type': 'DateEncoder'},\n",
    "                u'timestamp_dayOfWeek': None,\n",
    "                u'timestamp_weekend': None,\n",
    "                u'consumption': {\n",
    "                    'clipInput': True,\n",
    "                    'fieldname': u'consumption',\n",
    "                    'maxval': 100.0,\n",
    "                    'minval': 0.0,\n",
    "                    'n': 50,\n",
    "                    'name': u'c1',\n",
    "                    'type': 'ScalarEncoder',\n",
    "                    'w': 21},},\n",
    "\n",
    "            # A dictionary specifying the period for automatically-generated\n",
    "            # resets from a RecordSensor;\n",
    "            #\n",
    "            # None = disable automatically-generated resets (also disabled if\n",
    "            # all of the specified values evaluate to 0).\n",
    "            # Valid keys is the desired combination of the following:\n",
    "            #   days, hours, minutes, seconds, milliseconds, microseconds, weeks\n",
    "            #\n",
    "            # Example for 1.5 days: sensorAutoReset = dict(days=1,hours=12),\n",
    "            #\n",
    "            # (value generated from SENSOR_AUTO_RESET)\n",
    "            'sensorAutoReset' : None,\n",
    "        },\n",
    "\n",
    "        'spEnable': True,\n",
    "\n",
    "        'spParams': {\n",
    "            # SP diagnostic output verbosity control;\n",
    "            # 0: silent; >=1: some info; >=2: more info;\n",
    "            'spVerbosity' : 0,\n",
    "\n",
    "            # Spatial Pooler implementation selector, see getSPClass\n",
    "            # in py/regions/SPRegion.py for details\n",
    "            # 'py' (default), 'cpp' (speed optimized, new)\n",
    "            'spatialImp' : 'cpp',\n",
    "\n",
    "            'globalInhibition': 1,\n",
    "\n",
    "            # Number of cell columns in the cortical region (same number for\n",
    "            # SP and TM)\n",
    "            # (see also tpNCellsPerCol)\n",
    "            'columnCount': 2048,\n",
    "\n",
    "            'inputWidth': 0,\n",
    "\n",
    "            # SP inhibition control (absolute value);\n",
    "            # Maximum number of active columns in the SP region's output (when\n",
    "            # there are more, the weaker ones are suppressed)\n",
    "            'numActiveColumnsPerInhArea': 40,\n",
    "\n",
    "            'seed': 1956,\n",
    "\n",
    "            # potentialPct\n",
    "            # What percent of the columns's receptive field is available\n",
    "            # for potential synapses. At initialization time, we will\n",
    "            # choose potentialPct * (2*potentialRadius+1)^2\n",
    "            'potentialPct': 0.5,\n",
    "\n",
    "            # The default connected threshold. Any synapse whose\n",
    "            # permanence value is above the connected threshold is\n",
    "            # a \"connected synapse\", meaning it can contribute to the\n",
    "            # cell's firing. Typical value is 0.10. Cells whose activity\n",
    "            # level before inhibition falls below minDutyCycleBeforeInh\n",
    "            # will have their own internal synPermConnectedCell\n",
    "            # threshold set below this default value.\n",
    "            # (This concept applies to both SP and TM and so 'cells'\n",
    "            # is correct here as opposed to 'columns')\n",
    "            'synPermConnected': 0.1,\n",
    "\n",
    "            'synPermActiveInc': 0.1,\n",
    "\n",
    "            'synPermInactiveDec': 0.005,\n",
    "        },\n",
    "\n",
    "        # Controls whether TM is enabled or disabled;\n",
    "        # TM is necessary for making temporal predictions, such as predicting\n",
    "        # the next inputs.  Without TP, the model is only capable of\n",
    "        # reconstructing missing sensor inputs (via SP).\n",
    "        'tmEnable' : True,\n",
    "\n",
    "        'tmParams': {\n",
    "            # TM diagnostic output verbosity control;\n",
    "            # 0: silent; [1..6]: increasing levels of verbosity\n",
    "            # (see verbosity in nupic/trunk/py/nupic/research/TP.py and BacktrackingTMCPP.py)\n",
    "            'verbosity': 0,\n",
    "\n",
    "            # Number of cell columns in the cortical region (same number for\n",
    "            # SP and TM)\n",
    "            # (see also tpNCellsPerCol)\n",
    "            'columnCount': 2048,\n",
    "\n",
    "            # The number of cells (i.e., states), allocated per column.\n",
    "            'cellsPerColumn': 32,\n",
    "\n",
    "            'inputWidth': 2048,\n",
    "\n",
    "            'seed': 1960,\n",
    "\n",
    "            # Temporal Pooler implementation selector (see _getTPClass in\n",
    "            # CLARegion.py).\n",
    "            'temporalImp': 'cpp',\n",
    "\n",
    "            # New Synapse formation count\n",
    "            # NOTE: If None, use spNumActivePerInhArea\n",
    "            #\n",
    "            # TODO: need better explanation\n",
    "            'newSynapseCount': 20,\n",
    "\n",
    "            # Maximum number of synapses per segment\n",
    "            #  > 0 for fixed-size CLA\n",
    "            # -1 for non-fixed-size CLA\n",
    "            #\n",
    "            # TODO: for Ron: once the appropriate value is placed in TP\n",
    "            # constructor, see if we should eliminate this parameter from\n",
    "            # description.py.\n",
    "            'maxSynapsesPerSegment': 32,\n",
    "\n",
    "            # Maximum number of segments per cell\n",
    "            #  > 0 for fixed-size CLA\n",
    "            # -1 for non-fixed-size CLA\n",
    "            #\n",
    "            # TODO: for Ron: once the appropriate value is placed in TP\n",
    "            # constructor, see if we should eliminate this parameter from\n",
    "            # description.py.\n",
    "            'maxSegmentsPerCell': 128,\n",
    "\n",
    "            # Initial Permanence\n",
    "            # TODO: need better explanation\n",
    "            'initialPerm': 0.21,\n",
    "\n",
    "            # Permanence Increment\n",
    "            'permanenceInc': 0.1,\n",
    "\n",
    "            # Permanence Decrement\n",
    "            # If set to None, will automatically default to tpPermanenceInc\n",
    "            # value.\n",
    "            'permanenceDec' : 0.1,\n",
    "\n",
    "            'globalDecay': 0.0,\n",
    "\n",
    "            'maxAge': 0,\n",
    "\n",
    "            # Minimum number of active synapses for a segment to be considered\n",
    "            # during search for the best-matching segments.\n",
    "            # None=use default\n",
    "            # Replaces: tpMinThreshold\n",
    "            'minThreshold': 9,\n",
    "\n",
    "            # Segment activation threshold.\n",
    "            # A segment is active if it has >= tpSegmentActivationThreshold\n",
    "            # connected synapses that are active due to infActiveState\n",
    "            # None=use default\n",
    "            # Replaces: tpActivationThreshold\n",
    "            'activationThreshold': 12,\n",
    "\n",
    "            'outputType': 'normal',\n",
    "\n",
    "            # \"Pay Attention Mode\" length. This tells the TM how many new\n",
    "            # elements to append to the end of a learned sequence at a time.\n",
    "            # Smaller values are better for datasets with short sequences,\n",
    "            # higher values are better for datasets with long sequences.\n",
    "            'pamLength': 1,\n",
    "        },\n",
    "\n",
    "        'clParams': {\n",
    "            'regionName' : 'SDRClassifierRegion',\n",
    "\n",
    "            # Classifier diagnostic output verbosity control;\n",
    "            # 0: silent; [1..6]: increasing levels of verbosity\n",
    "            'verbosity' : 0,\n",
    "\n",
    "            # This controls how fast the classifier learns/forgets. Higher values\n",
    "            # make it adapt faster and forget older patterns faster.\n",
    "            'alpha': 0.005,\n",
    "\n",
    "            # This is set after the call to updateConfigFromSubConfig and is\n",
    "            # computed from the aggregationInfo and predictAheadTime.\n",
    "            'steps': '1',\n",
    "\n",
    "            'implementation': 'cpp',\n",
    "        },\n",
    "\n",
    "        'anomalyParams': {\n",
    "            u'anomalyCacheRecords': None,\n",
    "            u'autoDetectThreshold': None,\n",
    "            u'autoDetectWaitRecords': 2184\n",
    "        },\n",
    "\n",
    "        'trainSPNetOnlyIfRequested': False,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nupic.frameworks.opf.model_factory import ModelFactory\n",
    "model = ModelFactory.create(MODEL_PARAMS)\n",
    "model.enableInference({'predictedField': 'consumption'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  5.3\n",
      "prediction:  5.3\n",
      "input:  5.5\n",
      "prediction:  5.5\n",
      "input:  5.1\n",
      "prediction:  5.36\n",
      "input:  5.3\n",
      "prediction:  5.1\n",
      "input:  5.2\n",
      "prediction:  5.342\n"
     ]
    }
   ],
   "source": [
    "data = getData()\n",
    "for _ in xrange(5):\n",
    "    record = dict(zip(data.getFieldNames(), data.next()))\n",
    "    print \"input: \", record[\"consumption\"]\n",
    "    result = model.run(record)\n",
    "    print \"prediction: \", result.inferences[\"multiStepBestPredictions\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelResult(\tpredictionNumber=4\n",
      "\trawInput={'timestamp': datetime.datetime(2010, 7, 2, 1, 0), 'gym': 'Balgowlah Platinum', 'consumption': 5.2, 'address': 'Shop 67 197-215 Condamine Street Balgowlah 2093'}\n",
      "\tsensorInput=SensorInput(\tdataRow=(5.2, 1.0)\n",
      "\tdataDict={'timestamp': datetime.datetime(2010, 7, 2, 1, 0), 'gym': 'Balgowlah Platinum', 'consumption': 5.2, 'address': 'Shop 67 197-215 Condamine Street Balgowlah 2093'}\n",
      "\tdataEncodings=[array([ 0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  0.,\n",
      "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.], dtype=float32), array([ 0.,  0.,  0., ...,  0.,  0.,  0.], dtype=float32)]\n",
      "\tsequenceReset=0.0\n",
      "\tcategory=-1\n",
      ")\n",
      "\tinferences={'multiStepPredictions': {1: {5.1: 0.0088801263517415546, 5.2: 0.010775254623541418, 5.341999999999999: 0.98034461902471692}}, 'multiStepBucketLikelihoods': {1: {1: 0.0088801263517415546, 2: 0.98034461902471692}}, 'multiStepBestPredictions': {1: 5.341999999999999}, 'anomalyLabel': '[]', 'anomalyScore': 0.40000001}\n",
      "\tmetrics=None\n",
      "\tpredictedFieldIdx=0\n",
      "\tpredictedFieldName=consumption\n",
      "\tclassifierInput=ClassifierInput(\tdataRow=5.2\n",
      "\tbucketIndex=2\n",
      ")\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anomaly score:  0.4\n"
     ]
    }
   ],
   "source": [
    "print \"anomaly score: \", result.inferences[\"anomalyScore\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__See Subutai's talk for more info on anomaly detection!__\n",
    "\n",
    "# Built-in OPF Clients\n",
    "\n",
    "`python examples/opf/bin/OpfRunExperiment.py examples/opf/experiments/multistep/hotgym/`\n",
    "\n",
    "Outputs `examples/opf/experiments/multistep/hotgym/inference/DefaultTask.TemporalMultiStep.predictionLog.csv`\n",
    "\n",
    "`python bin/run_swarm.py examples/opf/experiments/multistep/hotgym/permutations.py`\n",
    "\n",
    "Outputs `examples/opf/experiments/multistep/hotgym/model_0/description.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nupic",
   "language": "python",
   "name": "nupic"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
