{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Swarming test for HTM Univariate\n",
    "\n",
    "In this notebook we are testing:\n",
    "1. Swarm over datasets: medium, all data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# from tqdm import tqdm_notebook\n",
    "# import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "Load Data and Groundtruth labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_relative = 'realKnownCause/machine_temperature_system_failure.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/NAB/' + PATH_relative) #parse_dates=True\n",
    "with open('../labels/NAB/combined_windows.json') as f:\n",
    "    labels = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-12-02 21:15:00</td>\n",
       "      <td>73.967322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-12-02 21:20:00</td>\n",
       "      <td>74.935882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-12-02 21:25:00</td>\n",
       "      <td>76.124162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-12-02 21:30:00</td>\n",
       "      <td>78.140707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-12-02 21:35:00</td>\n",
       "      <td>79.329836</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp      value\n",
       "0  2013-12-02 21:15:00  73.967322\n",
       "1  2013-12-02 21:20:00  74.935882\n",
       "2  2013-12-02 21:25:00  76.124162\n",
       "3  2013-12-02 21:30:00  78.140707\n",
       "4  2013-12-02 21:35:00  79.329836"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([0,1], inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df['value'] = pd.to_numeric(df['value'])\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'], format=\"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Groundtruth labels for anomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[u'2013-12-10 06:25:00.000000', u'2013-12-12 05:35:00.000000'],\n",
       " [u'2013-12-15 17:50:00.000000', u'2013-12-17 17:00:00.000000'],\n",
       " [u'2014-01-27 14:20:00.000000', u'2014-01-29 13:30:00.000000'],\n",
       " [u'2014-02-07 14:55:00.000000', u'2014-02-09 14:05:00.000000']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[PATH_relative]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['labels'] = np.zeros_like(df.value)\n",
    "\n",
    "# set values within the range = 1\n",
    "for i in range(len(labels[PATH_relative])):\n",
    "    df.loc[(df['timestamp'] >= labels[PATH_relative][i][0]) & \n",
    "             (df['timestamp'] <= labels[PATH_relative][i][1]), 'labels'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>value</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-12-02 21:25:00</td>\n",
       "      <td>76.124162</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-12-02 21:30:00</td>\n",
       "      <td>78.140707</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-12-02 21:35:00</td>\n",
       "      <td>79.329836</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-12-02 21:40:00</td>\n",
       "      <td>78.710418</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-12-02 21:45:00</td>\n",
       "      <td>80.269784</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            timestamp      value  labels\n",
       "0 2013-12-02 21:25:00  76.124162     0.0\n",
       "1 2013-12-02 21:30:00  78.140707     0.0\n",
       "2 2013-12-02 21:35:00  79.329836     0.0\n",
       "3 2013-12-02 21:40:00  78.710418     0.0\n",
       "4 2013-12-02 21:45:00  80.269784     0.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SWARM\n",
    "**Hyperparameter search**\n",
    "\n",
    "Making use of the *swarm algorithm*, we will find the hyperparmeter gor our HTM model.  \n",
    "To perform the *swarm*, we need to create a `.json` file feed with informations about our data.  \n",
    "Once the hyperparameter search is completed, we need to load the best model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'realKnownCause/machine_temperature_system_failure.csv'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH_relative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_search_def(data, selectCols, source, predictCol=[], \n",
    "                      timestampCol=None, inferenceType='TemporalAnomaly', \n",
    "                      iterationCount=-1, swarmSize='medium'):\n",
    "    \"\"\"\n",
    "    Generates the `search_def` dict, to be then converted as `.json`.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data: pandas.DataFrame\n",
    "        Timestamp column if present must be named 'timestamp'.\n",
    "        Other columns are considered as `float`.\n",
    "    timestampCol: str \n",
    "        If present, name of column containing `datetime` variable.\n",
    "    selectCols: list of str\n",
    "        List of column names elegible for swarming.\n",
    "    predictCol: str\n",
    "        Name of the column --only 1!-- to be predicted.\n",
    "    source: str\n",
    "        `Path_to_file + file.csv` containing our DataFrame.\n",
    "        Must start from the root of nupic.\n",
    "    inferenceType: str, default='TemporalMultistep'\n",
    "    iterationCount: int, default=-1\n",
    "        Number of value every model iterates on. \n",
    "        `-1` iterates over all data in data frame.\n",
    "    swarmSize: str ('small', 'medium', 'large')\n",
    "        Default='medium', for debugging suggested 'small'.\n",
    "                \n",
    "    Output\n",
    "    ------\n",
    "    search_def : dict\n",
    "        Dictionary version of 'search_def.json'\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    To understand how to change the default paramaters for `inferenceType`, \n",
    "    'iterationCount' and 'swarmSize' consider reading the swarm documentation: \n",
    "    'http://nupic.docs.numenta.org/stable/guides/swarming/running.html#the-swarm-description' \n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    includedFields = []\n",
    "    \n",
    "    if timestampCol != None:\n",
    "        field = {\n",
    "            \"fieldName\": timestampCol,\n",
    "            \"fieldType\": \"datetime\",\n",
    "        }\n",
    "        includedFields.append(field)\n",
    "\n",
    "    for i in selectCols:\n",
    "        field = {\n",
    "            \"fieldName\": data[i].name,\n",
    "            \"fieldType\": \"float\",\n",
    "            \"minValue\": data[i].min(),\n",
    "            \"maxValue\": data[i].max()\n",
    "        }        \n",
    "        includedFields.append(field)\n",
    "\n",
    "    search_def = {\n",
    "        \"includedFields\": includedFields,\n",
    "        \"streamDef\" : {\n",
    "            \"info\": \"Experiment\",\n",
    "            \"version\": 1,\n",
    "            \"streams\": [\n",
    "              {\n",
    "                \"info\": \"Exp\",\n",
    "                \"source\": \"file://\" + source,\n",
    "                \"columns\": [\n",
    "                  \"*\"\n",
    "                ]\n",
    "              }\n",
    "            ]\n",
    "          },\n",
    "\n",
    "        \"inferenceArgs\" : {\n",
    "            \"predictionSteps\": [\n",
    "              1\n",
    "            ],\n",
    "            \"predictedField\": predictCol\n",
    "          },\n",
    "        \"inferenceType\" : inferenceType,\n",
    "        \"iterationCount\" : iterationCount,\n",
    "        \"swarmSize\" : swarmSize\n",
    "    }\n",
    "    \n",
    "    return search_def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_def = create_search_def(df, selectCols=['value'], timestampCol='timestamp', \n",
    "                               predictCol='value', \n",
    "                               source=\"ab_experiments/data/NAB/\"+PATH_relative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'includedFields': [{'fieldName': 'timestamp', 'fieldType': 'datetime'},\n",
       "  {'fieldName': 'value',\n",
       "   'fieldType': 'float',\n",
       "   'maxValue': 108.5105428,\n",
       "   'minValue': 2.0847212060000002}],\n",
       " 'inferenceArgs': {'predictedField': 'value', 'predictionSteps': [1]},\n",
       " 'inferenceType': 'TemporalAnomaly',\n",
       " 'iterationCount': -1,\n",
       " 'streamDef': {'info': 'Experiment',\n",
       "  'streams': [{'columns': ['*'],\n",
       "    'info': 'Exp',\n",
       "    'source': 'file://ab_experiments/data/NAB/realKnownCause/machine_temperature_system_failure.csv'}],\n",
       "  'version': 1},\n",
       " 'swarmSize': 'medium'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_search_def_to_file(search_def_dict):\n",
    "    \"\"\"\n",
    "    Write `search_def` dict to `search_def.json`.\n",
    "    The file will be written in the notebook folder.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    search_def_dict: dict\n",
    "        Dictionary as outputed by `create_search_def`\n",
    "        as indicated in: \n",
    "        'http://nupic.docs.numenta.org/stable/guides/swarming/running.html#a-simple-example'\n",
    "    \n",
    "    Output\n",
    "    ----------\n",
    "    `search_def.json`: `.json` file\n",
    "        File to perform swarm.\n",
    "        File located in notebook folder.\n",
    "    \"\"\"\n",
    "    \n",
    "    with open('search_def.json', 'w') as f:\n",
    "        json.dump(search_def_dict, f, indent=2, separators=(\", \", \": \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write_search_def_to_file(search_def)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "- **Open** original `.csv` in `ab_experiments/data/NAB/realKnownCause/machine_temperature_system_failure.csv` and  \n",
    "save it as `machine_temperature_system_failure_backup.csv` \n",
    "- **Edit header** of `machine_temperature_system_failure_backup.csv` adding lines #2 and #3:\n",
    "    ```\n",
    "    timestamp,value\n",
    "    datetime, float\n",
    "    T,\n",
    "    2013-12-02 21:15:00,73.96732207\n",
    "\n",
    "    ```\n",
    "- **Move** *search_def.json* and **execute** swarm algorithm:\n",
    "\n",
    "    ```\n",
    "    $ mv ab_experiments/notebooks/search_def.json ab_experiments/swarm/NAB/realKnownCaus/machine_temperature_failure\n",
    "\n",
    "    $ python scripts/run_swarm.py ab_experiments/swarm/NAB/realKnownCause/machine_temperature_failure/search_def.json --overwrite --maxWorkers=4\n",
    "    ```\n",
    "\n",
    "---\n",
    "\n",
    "**Swarm RESULTS**  \n",
    "The best hyperparameter are stored in `ab_experiments/swarm/NAB/realKnownCause/machine_temperature_failure/swarm_medium_allData/model_0`  \n",
    "in **model_params.py**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HTM Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load** MODEL_PARAMS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PARAMS = {'aggregationInfo': {'days': 0,\n",
    "                     'fields': [],\n",
    "                     'hours': 0,\n",
    "                     'microseconds': 0,\n",
    "                     'milliseconds': 0,\n",
    "                     'minutes': 0,\n",
    "                     'months': 0,\n",
    "                     'seconds': 0,\n",
    "                     'weeks': 0,\n",
    "                     'years': 0},\n",
    " 'model': 'HTMPrediction',\n",
    " 'modelParams': {'anomalyParams': {u'anomalyCacheRecords': None,\n",
    "                                   u'autoDetectThreshold': None,\n",
    "                                   u'autoDetectWaitRecords': None},\n",
    "                 'clParams': {'alpha': 0.03199623347319286,\n",
    "                              'regionName': 'SDRClassifierRegion',\n",
    "                              'steps': '1',\n",
    "                              'verbosity': 0},\n",
    "                 'inferenceType': 'TemporalAnomaly',\n",
    "                 'sensorParams': {'encoders': {u'timestamp_dayOfWeek': None,\n",
    "                                               u'timestamp_timeOfDay': None,\n",
    "                                               u'timestamp_weekend': {'fieldname': 'timestamp',\n",
    "                                                                      'name': 'timestamp',\n",
    "                                                                      'type': 'DateEncoder',\n",
    "                                                                      'weekend': (21,\n",
    "                                                                                  1)},\n",
    "                                               u'value': {'clipInput': True,\n",
    "                                                          'fieldname': 'value',\n",
    "                                                          'maxval': 108.5105428,\n",
    "                                                          'minval': 2.084721206,\n",
    "                                                          'n': 29,\n",
    "                                                          'name': 'value',\n",
    "                                                          'type': 'ScalarEncoder',\n",
    "                                                          'w': 21}},\n",
    "                                  'sensorAutoReset': None,\n",
    "                                  'verbosity': 0},\n",
    "                 'spEnable': True,\n",
    "                 'spParams': {'boostStrength': 0.0,\n",
    "                              'columnCount': 2048,\n",
    "                              'globalInhibition': 1,\n",
    "                              'inputWidth': 0,\n",
    "                              'numActiveColumnsPerInhArea': 40,\n",
    "                              'potentialPct': 0.8,\n",
    "                              'seed': 1956,\n",
    "                              'spVerbosity': 0,\n",
    "                              'spatialImp': 'cpp',\n",
    "                              'synPermActiveInc': 0.05,\n",
    "                              'synPermConnected': 0.1,\n",
    "                              'synPermInactiveDec': 0.06265155177806427},\n",
    "                 'tmEnable': True,\n",
    "                 'tmParams': {'activationThreshold': 12,\n",
    "                              'cellsPerColumn': 32,\n",
    "                              'columnCount': 2048,\n",
    "                              'globalDecay': 0.0,\n",
    "                              'initialPerm': 0.21,\n",
    "                              'inputWidth': 2048,\n",
    "                              'maxAge': 0,\n",
    "                              'maxSegmentsPerCell': 128,\n",
    "                              'maxSynapsesPerSegment': 32,\n",
    "                              'minThreshold': 10,\n",
    "                              'newSynapseCount': 20,\n",
    "                              'outputType': 'normal',\n",
    "                              'pamLength': 2,\n",
    "                              'permanenceDec': 0.1,\n",
    "                              'permanenceInc': 0.1,\n",
    "                              'seed': 1960,\n",
    "                              'temporalImp': 'cpp',\n",
    "                              'verbosity': 0},\n",
    "                 'trainSPNetOnlyIfRequested': False},\n",
    " 'predictAheadTime': None,\n",
    " 'version': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'labels': 0.0,\n",
       "  'timestamp': Timestamp('2013-12-02 21:25:00'),\n",
       "  'value': 76.12416182},\n",
       " {'labels': 0.0,\n",
       "  'timestamp': Timestamp('2013-12-02 21:30:00'),\n",
       "  'value': 78.14070732},\n",
       " {'labels': 0.0,\n",
       "  'timestamp': Timestamp('2013-12-02 21:35:00'),\n",
       "  'value': 79.32983574},\n",
       " {'labels': 0.0,\n",
       "  'timestamp': Timestamp('2013-12-02 21:40:00'),\n",
       "  'value': 78.71041827},\n",
       " {'labels': 0.0,\n",
       "  'timestamp': Timestamp('2013-12-02 21:45:00'),\n",
       "  'value': 80.26978421}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df.to_dict(orient='records')\n",
    "data[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder\n",
    "\n",
    "Best Parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'encoders': {u'timestamp_dayOfWeek': None,\n",
       "  u'timestamp_timeOfDay': None,\n",
       "  u'timestamp_weekend': {'fieldname': 'timestamp',\n",
       "   'name': 'timestamp',\n",
       "   'type': 'DateEncoder',\n",
       "   'weekend': (21, 1)},\n",
       "  u'value': {'clipInput': True,\n",
       "   'fieldname': 'value',\n",
       "   'maxval': 108.5105428,\n",
       "   'minval': 2.084721206,\n",
       "   'n': 29,\n",
       "   'name': 'value',\n",
       "   'type': 'ScalarEncoder',\n",
       "   'w': 21}},\n",
       " 'sensorAutoReset': None,\n",
       " 'verbosity': 0}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_PARAMS['modelParams']['sensorParams']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestamp_weekend {'type': 'DateEncoder', 'fieldname': 'timestamp', 'name': 'timestamp', 'weekend': (21, 1)} \n",
      "\n",
      "0 \n",
      "\n",
      "value {'maxval': 108.5105428, 'fieldname': 'value', 'name': 'value', 'w': 21, 'clipInput': True, 'minval': 2.084721206, 'type': 'ScalarEncoder', 'n': 29} \n",
      "\n",
      "0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k,v in MODEL_PARAMS['modelParams']['sensorParams']['encoders'].items():\n",
    "    if v != None:\n",
    "        print k, v, \"\\n\"\n",
    "    else: \n",
    "        print str(0), \"\\n\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to build: \n",
    "- 1x 'DateEncoder' which encodes the field `timestamp`\n",
    "- 1x 'ScalarEncoder' which encodes the field `value`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_dict_key(d, keys):\n",
    "    new_d = dict(d)\n",
    "    for i in keys: \n",
    "        del new_d[i]\n",
    "    return new_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp_weekend = remove_dict_key(MODEL_PARAMS['modelParams']['sensorParams']['encoders'].values()[0], \n",
    "                                    keys=['type','fieldname'])\n",
    "value = remove_dict_key(MODEL_PARAMS['modelParams']['sensorParams']['encoders'].values()[2], \n",
    "                        keys=['type','fieldname'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from nupic.encoders.random_distributed_scalar import RandomDistributedScalarEncoder\n",
    "from nupic.encoders.scalar import ScalarEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters:  {'maxval': 108.5105428, 'name': 'value', 'clipInput': True, 'minval': 2.084721206, 'n': 29, 'w': 21}\n",
      "76.12416182 =  [0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0]\n",
      "78.14070732 =  [0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "vEnc = ScalarEncoder(**value)\n",
    "#vEnc = ScalarEncoder(resolution=0.1, w=21, minval=60, maxval=100)\n",
    "print \"Parameters: \", value\n",
    "print str(data[0]['value']) + \" = \", vEnc.encode(data[0]['value'])\n",
    "print str(data[1]['value']) + \" = \", vEnc.encode(data[1]['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'value': ([[68.600859702249991, 68.600859702249991]], '68.60')}, ['value'])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = vEnc.encode(75.123)\n",
    "print(enc)\n",
    "vEnc.decode(enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scalar encoder proposed by *swarm* is extremely rough.  \n",
    "In timestamp, *swarm* suggestede **weekend** to be a relevant feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from nupic.encoders.date import DateEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters:  {'name': 'timestamp', 'weekend': (21, 1)}\n",
      "TimeStamp-obs0 =  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0]\n",
      "TimeStamp-obs1 =  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "dEnc = DateEncoder(**timestamp_weekend) \n",
    "\n",
    "print \"Parameters: \", timestamp_weekend\n",
    "\n",
    "# tsObs1 = datetime.datetime.strptime(data[0]['timestamp'], \"%Y-%m-%d %H:%M:%S\")\n",
    "print \"TimeStamp-obs0 = \", dEnc.encode(data[0]['timestamp'])\n",
    "print \"TimeStamp-obs1 = \", dEnc.encode(data[1]['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels': 0.0,\n",
       " 'timestamp': Timestamp('2013-12-02 21:25:00'),\n",
       " 'value': 76.12416182}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = []\n",
    "inputVal = []\n",
    "inputTs = []\n",
    "label = []\n",
    "inputSDRval = []\n",
    "inputSDRts = []\n",
    "inputSDR = []  # main\n",
    "inputTsIdx = [0, len(dEnc.encode(data[0]['timestamp'])) - 1]\n",
    "inputValIdx = [len(dEnc.encode(data[0]['timestamp'])), \n",
    "               len(dEnc.encode(data[0]['timestamp'])) + len(vEnc.encode(data[1]['value'])) - 1]\n",
    "\n",
    "for i in xrange(len(data)):\n",
    "    obs.append(i)\n",
    "    inputTs.append(data[i]['timestamp'])  \n",
    "    inputVal.append(data[i]['value'])   \n",
    "    label.append(data[i]['labels'])\n",
    "    inputSDRts.append(dEnc.encode(data[i]['timestamp']))\n",
    "    inputSDRval.append(vEnc.encode(data[i]['value']))\n",
    "    inputSDR.append(np.hstack((inputSDRts[i], inputSDRval[i])))  # combine the 2 ancoders in 1 enoder \n",
    "    \n",
    "# send everything to dict    \n",
    "data = pd.DataFrame({'inputVal':inputVal, 'inputTs':inputTs, 'label': label,\n",
    "                      'inputSDR':inputSDR, 'inputSDRval':inputSDRval, 'inputSDRts':inputSDRts, \n",
    "                      #'inputValIdx1':inputValIdx1, 'inputVaIdx2':inputValIdx2\n",
    "                     }, index=obs).to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(inputSDR):  71\n",
      "{'inputSDR': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       0, 0], dtype=uint8), 'label': 0.0, 'inputVal': 76.12416182, 'inputTs': Timestamp('2013-12-02 21:25:00'), 'inputSDRts': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=uint8), 'inputSDRval': array([0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 0, 0], dtype=uint8)}\n",
      "22693\n"
     ]
    }
   ],
   "source": [
    "print \"len(inputSDR): \", len(data[0]['inputSDR'])\n",
    "print data[0]\n",
    "print len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spatial Pooler\n",
    "[link to wiki](http://nupic.docs.numenta.org/1.0.3/api/algorithms/spatial-pooling.html#nupic.algorithms.spatial_pooler.SpatialPooler)\n",
    "\n",
    "Load `MODEL_PARAMS` fors SP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nupic.algorithms.spatial_pooler import SpatialPooler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boostStrength': 0.0,\n",
       " 'columnCount': 2048,\n",
       " 'globalInhibition': 1,\n",
       " 'inputWidth': 0,\n",
       " 'numActiveColumnsPerInhArea': 40,\n",
       " 'potentialPct': 0.8,\n",
       " 'seed': 1956,\n",
       " 'spVerbosity': 0,\n",
       " 'spatialImp': 'cpp',\n",
       " 'synPermActiveInc': 0.05,\n",
       " 'synPermConnected': 0.1,\n",
       " 'synPermInactiveDec': 0.06265155177806427}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_PARAMS['modelParams']['spParams']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "selectedSPparams = {\n",
    "    'boostStrength': 0.0,\n",
    "    #'columnCount': 2048,\n",
    "    'globalInhibition': 1,\n",
    "    #'inputWidth': 0,\n",
    "    'numActiveColumnsPerInhArea': 40,\n",
    "    'potentialPct': 0.8,\n",
    "    'seed': 1956,\n",
    "    'spVerbosity': 0,\n",
    "    #'spatialImp': 'cpp',\n",
    "    'synPermActiveInc': 0.05,\n",
    "    'synPermConnected': 0.1,\n",
    "    'synPermInactiveDec': 0.06265155177806427,\n",
    "    ### Changes\n",
    "    'inputDimensions': (len(data[0]['inputSDR']), ),\n",
    "    'columnDimensions': MODEL_PARAMS['modelParams']['spParams']['columnCount'], \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init SP\n",
    "sp = SpatialPooler(**selectedSPparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print SP\n",
    "\n",
    "cols = []\n",
    "connections = []\n",
    "\n",
    "for col in xrange(sp.getColumnDimensions()):\n",
    "    connected = np.zeros(len(data[0]['inputSDR']), dtype=\"int\")\n",
    "    sp.getConnectedSynapses(col, connected)\n",
    "    cols.append(col)\n",
    "    connections.append(connected)\n",
    "\n",
    "spSDR = dict(zip(cols, connections))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SP Shape:2048; 71\n"
     ]
    }
   ],
   "source": [
    "print \"SP Shape:\" + str(len(spSDR)) + \"; \" + str(len(spSDR[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The active bits (min-columns) are set by calculating the *overlapping score* with the input vector.  \n",
    "*Overalpping score* = `inputSDR` * `spSDR\\[column]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idx_active_cols(inputArr):\n",
    "    \"\"\"\n",
    "    This function takes an 1d or nd-array and returns a 1d-array with the index for ACTIVE bits/columns: \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    inputArr:   np.array (1d or nD)\n",
    "            \n",
    "    Output\n",
    "    ------\n",
    "    tmActiveColsIdx: 1d np.arraz\n",
    "        Array with index of active cols.\n",
    "        \n",
    "    \"\"\"\n",
    "    #tmObject.reshape(tmObject.numberOfCols, tm.cellsPerColumn)\n",
    "    activeColsVec = []  # initialize vector\n",
    "\n",
    "    for i in range(inputArr.shape[0]):\n",
    "        # assign 1 if any 1 (active cell) in the column,\n",
    "        # 0 otherwise\n",
    "        if np.any(inputArr[i]>0):\n",
    "        # if np.any(tm.compute(spSDR[track[3]['sp_active']], enableLearn=True, enableInference=True).reshape(256, 3)[i]>0):\n",
    "            activeColsVec.append(1)\n",
    "        else:\n",
    "            activeColsVec.append(0)\n",
    "    # return index of active Columns        \n",
    "    tmActiveColsIdx = np.flatnonzero(np.array(activeColsVec))\n",
    "    return tmActiveColsIdx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Compute` returns the to 40 active cols, as defined in:  \n",
    "`MODEL_PARAMS['modelParams']['spParams']['numActiveColumnsPerInhArea']=40`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in xrange(len(data)):\n",
    "    output = np.zeros(sp.getColumnDimensions(), dtype=\"int\")\n",
    "    sp.compute(data[i]['inputSDR'], learn=False, activeArray=output)\n",
    "    data[i]['sp_active'] = idx_active_cols(output) #save to dict\n",
    "    \n",
    "#     print \"obs\" + str(i) + \", Active col: \", str(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obs22692\n",
      "Active col:  [   7   17   31   72   77   95  145  162  164  178  185  227  231 1703 1746\n",
      " 1794 1855 1867 1868 1919 1934 1937 1942 1951 1958 1962 1975 1986 1988 1991\n",
      " 2002 2003 2005 2012 2019 2026 2032 2039 2044 2047]\n",
      "obs22692\n",
      "Active col:  [   7   17   31   72   77   95  145  162  164  178  185  227  231 1703 1746\n",
      " 1794 1855 1867 1868 1919 1934 1937 1942 1951 1958 1962 1975 1986 1988 1991\n",
      " 2002 2003 2005 2012 2019 2026 2032 2039 2044 2047]\n",
      "obs22692\n",
      "Active col:  [   7   17   31   72   77   95  145  162  164  178  185  227  231 1703 1746\n",
      " 1794 1855 1867 1868 1919 1934 1937 1942 1951 1958 1962 1975 1986 1988 1991\n",
      " 2002 2003 2005 2012 2019 2026 2032 2039 2044 2047]\n",
      "obs22692\n",
      "Active col:  [   7   17   31   72   77   95  145  162  164  178  185  227  231 1703 1746\n",
      " 1794 1855 1867 1868 1919 1934 1937 1942 1951 1958 1962 1975 1986 1988 1991\n",
      " 2002 2003 2005 2012 2019 2026 2032 2039 2044 2047]\n",
      "obs22692\n",
      "Active col:  [   7   17   31   72   77   95  145  162  164  178  185  227  231 1703 1746\n",
      " 1794 1855 1867 1868 1919 1934 1937 1942 1951 1958 1962 1975 1986 1988 1991\n",
      " 2002 2003 2005 2012 2019 2026 2032 2039 2044 2047]\n"
     ]
    }
   ],
   "source": [
    "for _ in xrange(5):\n",
    "    print \"obs\" + str(i)\n",
    "    print \"Active col: \", data[i]['sp_active']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Permanence\n",
    "# permanence = []\n",
    "\n",
    "# for i in xrange(sp.getColumnDimensions()):\n",
    "#     p = []\n",
    "#     sp.getPermanence(i, p)\n",
    "#     permanence.append(np.array(p))\n",
    "\n",
    "# permanence[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For `Permanence > Threshold` we have a connection to the *inputSDR*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarizing SP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputSDR:  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0]\n",
      "SDR active bits [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 48 49 50 51\n",
      " 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68]\n",
      "SP active col:  [   7   17   95  145  147  162  164  178  185  189  227  231 1703 1746 1753\n",
      " 1775 1794 1797 1818 1822 1855 1864 1867 1937 1942 1951 1958 1962 1975 1986\n",
      " 1988 1991 2003 2005 2012 2019 2032 2039 2044 2047]\n",
      "\n",
      "------------\n",
      "SP active col: 7; \tOverlappin bits: 17\n",
      "SP active col: 17; \tOverlappin bits: 17\n",
      "SP active col: 95; \tOverlappin bits: 17\n",
      "SP active col: 145; \tOverlappin bits: 19\n",
      "SP active col: 147; \tOverlappin bits: 16\n",
      "SP active col: 162; \tOverlappin bits: 17\n",
      "SP active col: 164; \tOverlappin bits: 17\n",
      "SP active col: 178; \tOverlappin bits: 16\n",
      "SP active col: 185; \tOverlappin bits: 17\n",
      "SP active col: 189; \tOverlappin bits: 16\n",
      "SP active col: 227; \tOverlappin bits: 17\n",
      "SP active col: 231; \tOverlappin bits: 17\n",
      "SP active col: 1703; \tOverlappin bits: 17\n",
      "SP active col: 1746; \tOverlappin bits: 18\n",
      "SP active col: 1753; \tOverlappin bits: 16\n",
      "SP active col: 1775; \tOverlappin bits: 17\n",
      "SP active col: 1794; \tOverlappin bits: 18\n",
      "SP active col: 1797; \tOverlappin bits: 17\n",
      "SP active col: 1818; \tOverlappin bits: 17\n",
      "SP active col: 1822; \tOverlappin bits: 16\n",
      "SP active col: 1855; \tOverlappin bits: 16\n",
      "SP active col: 1864; \tOverlappin bits: 16\n",
      "SP active col: 1867; \tOverlappin bits: 20\n",
      "SP active col: 1937; \tOverlappin bits: 19\n",
      "SP active col: 1942; \tOverlappin bits: 17\n",
      "SP active col: 1951; \tOverlappin bits: 17\n",
      "SP active col: 1958; \tOverlappin bits: 18\n",
      "SP active col: 1962; \tOverlappin bits: 16\n",
      "SP active col: 1975; \tOverlappin bits: 16\n",
      "SP active col: 1986; \tOverlappin bits: 16\n",
      "SP active col: 1988; \tOverlappin bits: 16\n",
      "SP active col: 1991; \tOverlappin bits: 17\n",
      "SP active col: 2003; \tOverlappin bits: 17\n",
      "SP active col: 2005; \tOverlappin bits: 17\n",
      "SP active col: 2012; \tOverlappin bits: 16\n",
      "SP active col: 2019; \tOverlappin bits: 16\n",
      "SP active col: 2032; \tOverlappin bits: 16\n",
      "SP active col: 2039; \tOverlappin bits: 16\n",
      "SP active col: 2044; \tOverlappin bits: 17\n",
      "SP active col: 2047; \tOverlappin bits: 18\n"
     ]
    }
   ],
   "source": [
    "entry = 0\n",
    "\n",
    "print \"inputSDR: \", data[entry]['inputSDR']\n",
    "print \"SDR active bits\", idx_active_cols(data[entry]['inputSDR'])\n",
    "print \"SP active col: \", data[entry]['sp_active']\n",
    "print \"\\n\", \"------------\"\n",
    "\n",
    "for i in data[entry]['sp_active']:\n",
    "    print \"SP active col: \" + str(i) + \"; \\tOverlappin bits: \" + str(sum(spSDR[i] * data[entry]['inputSDR']))\n",
    "\n",
    "#print \"Pemanence winning col: \", permanence[track[0]['sp_active']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temporal Pooler\n",
    "\n",
    "[link to wiki](http://nupic.docs.numenta.org/1.0.3/api/algorithms/sequence-memory.html#nupic.algorithms.backtracking_tm_cpp.BacktrackingTMCPP)\n",
    "\n",
    "Load `MODEL_PARAMS` fors TM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activationThreshold': 12,\n",
       " 'cellsPerColumn': 32,\n",
       " 'columnCount': 2048,\n",
       " 'globalDecay': 0.0,\n",
       " 'initialPerm': 0.21,\n",
       " 'inputWidth': 2048,\n",
       " 'maxAge': 0,\n",
       " 'maxSegmentsPerCell': 128,\n",
       " 'maxSynapsesPerSegment': 32,\n",
       " 'minThreshold': 10,\n",
       " 'newSynapseCount': 20,\n",
       " 'outputType': 'normal',\n",
       " 'pamLength': 2,\n",
       " 'permanenceDec': 0.1,\n",
       " 'permanenceInc': 0.1,\n",
       " 'seed': 1960,\n",
       " 'temporalImp': 'cpp',\n",
       " 'verbosity': 0}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_PARAMS['modelParams']['tmParams']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "selectedTMparams = { \n",
    "    'activationThreshold': 12,\n",
    "    'cellsPerColumn': 32,\n",
    "    #'columnCount': 2048,\n",
    "    'globalDecay': 0.0,\n",
    "    'initialPerm': 0.21,\n",
    "    #'inputWidth': 2048,\n",
    "    'maxAge': 0,\n",
    "    'maxSegmentsPerCell': 128,\n",
    "    'maxSynapsesPerSegment': 32,\n",
    "    'minThreshold': 10,\n",
    "    'newSynapseCount': 20,\n",
    "    'outputType': 'normal',\n",
    "    'pamLength': 2,\n",
    "    'permanenceDec': 0.1,\n",
    "    'permanenceInc': 0.1,\n",
    "    'seed': 1960,\n",
    "    #'temporalImp': 'cpp',\n",
    "    'verbosity': 0,\n",
    "    ### Changes\n",
    "    'numberOfCols': MODEL_PARAMS['modelParams']['tmParams']['columnCount'],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nupic.algorithms.backtracking_tm import BacktrackingTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To better understand the example we suggest to set `verbosity=5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init TM\n",
    "tm = BacktrackingTM(**selectedTMparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For every input, send the ACTIVE_sp_columns to TM as 0/1 vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in xrange(len(data)): #len(track)\n",
    "    # for every input, select the 'sp_active' col and get active bit in very col  \n",
    "    sp4tm = [spSDR.get(sp) for sp in data[i]['sp_active']]\n",
    "    # stack all the arrays in matrix and sum to see overlap \n",
    "    sp4tm = sum(np.array(sp4tm))\n",
    "    # if overlap 1 send active cols aove \n",
    "    sp4tm[sp4tm>0] = 1\n",
    "    \n",
    "    # send the vector with the SP active cols to TM\n",
    "    data[i]['sp4tm'] = sp4tm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 3: send the  input to the temporal memory for learning\n",
    "\n",
    "# # Send each input in the sequence in order\n",
    "# for i in xrange(len(track[:3000])):\n",
    "    \n",
    "#     # The compute method performs one step of learning and/or inference. Note:\n",
    "#     # here we just perform learning but you can perform prediction/inference and\n",
    "#     # learning in the same step if you want (online learning).\n",
    "#     tm.compute(track[i]['sp4tm'], enableLearn=True, enableInference=True)\n",
    "#     # This function prints the segments associated with every cell.$$$$\n",
    "#     # If you really want to understand the TP, uncomment this line. By following\n",
    "#     # every step you can get an excellent understanding for exactly how the TP\n",
    "#     # learns.\n",
    "#     #tm.printCells()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the first 3000 entries to learn, test on the rest:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anomaly Score\n",
    "\n",
    "[link](http://nupic.docs.numenta.org/stable/guides/anomaly-detection.html)\n",
    "\n",
    "The algorithm for the anomaly score is as follows:  \n",
    "\n",
    "AS = |A_(t) - (P_(t-1) cross A_(t))|  / |A_(t)|  \n",
    "\n",
    "A_(t):   Predicted columns at time t  \n",
    "P_(t-1): Active columns at time t\n",
    "\n",
    "**Note**: Here, a “predicted column” is a column with a non-zero confidence value. This is not exactly the same as having a cell in the predicted state. For more information, refer the “predicted cells vs. confidences” section below.  \n",
    "\n",
    "...to compute the confidences for a cell, the Temporal Pooler uses the soft match count (the number of active synapses, regardless of the permanence values). Therefore, the set of columns with non-zero confidences will always be a superset of the columns containing predicted cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeRawAnomalyScore(activeColumns, prevPredictedColumns):\n",
    "  \"\"\"Computes the raw anomaly score.\n",
    "\n",
    "  The raw anomaly score is the fraction of active columns not predicted.\n",
    "\n",
    "  :param activeColumns: array of active column indices\n",
    "  :param prevPredictedColumns: array of columns indices predicted in prev step\n",
    "  :returns: anomcaly score 0..1 (float)\n",
    "  \"\"\"\n",
    "  nActiveColumns = len(activeColumns)\n",
    "  if nActiveColumns > 0:\n",
    "    # Test whether each element of a 1-D array is also present in a second\n",
    "    # array. Sum to get the total # of columns that are active and were\n",
    "    # predicted.\n",
    "    score = np.in1d(activeColumns, prevPredictedColumns).sum()\n",
    "    # Get the percent of active columns that were NOT predicted, that is\n",
    "    # our anomaly score.\n",
    "    score = (nActiveColumns - score) / float(nActiveColumns)\n",
    "  else:\n",
    "    # There are no active columns.\n",
    "    score = 0.0\n",
    "\n",
    "  return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility routine for printing the input vector\n",
    "def formatRow(x):\n",
    "    s = ''\n",
    "    for c in range(len(x)):\n",
    "        if c > 0 and c % 10 == 0:\n",
    "            s += ' '\n",
    "        s += str(x[c])\n",
    "    s += ' '\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anomaly Likelihood\n",
    "\n",
    "``` \n",
    "from nupic.algorithms.anomaly_likelihood import AnomalyLikelihood\n",
    "\n",
    "class AnomalyLikelihood(claLearningPeriod=None,\n",
    "                       learningPeriod=288,\n",
    "                       estimationSamples=100,\n",
    "                       historicWindowSize=8640,\n",
    "                       reestimationPeriod=100)):\n",
    "\n",
    "    NOTE: Anomaly likelihood scores are reported at a flat 0.5 for\n",
    "    learningPeriod + estimationSamples iterations.\n",
    "\n",
    "    claLearningPeriod and learningPeriod are specifying the same variable,\n",
    "    although claLearningPeriod is a deprecated name for it.\n",
    "\n",
    "    :param learningPeriod: (claLearningPeriod: deprecated) - (int) the number of\n",
    "      iterations required for the algorithm to learn the basic patterns in the\n",
    "      dataset and for the anomaly score to 'settle down'. The default is based\n",
    "      on empirical observations but in reality this could be larger for more\n",
    "      complex domains. The downside if this is too large is that real anomalies\n",
    "      might get ignored and not flagged.\n",
    "\n",
    "    :param estimationSamples: (int) the number of reasonable anomaly scores\n",
    "      required for the initial estimate of the Gaussian. The default of 100\n",
    "      records is reasonable - we just need sufficient samples to get a decent\n",
    "      estimate for the Gaussian. It's unlikely you will need to tune this since\n",
    "      the Gaussian is re-estimated every 10 iterations by default.\n",
    "\n",
    "    :param historicWindowSize: (int) size of sliding window of historical\n",
    "      data points to maintain for periodic reestimation of the Gaussian. Note:\n",
    "      the default of 8640 is based on a month's worth of history at 5-minute\n",
    "      intervals.\n",
    "\n",
    "    :param reestimationPeriod: (int) how often we re-estimate the Gaussian\n",
    "      distribution. The ideal is to re-estimate every iteration but this is a\n",
    "      performance hit. In general the system is not very sensitive to this\n",
    "      number as long as it is small relative to the total number of records\n",
    "      processed.\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nupic.algorithms.anomaly_likelihood import AnomalyLikelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalyLikelihood = AnomalyLikelihood()\n",
    "\n",
    "# for i in xrange(100):  # len(data)\n",
    "#     # Compute the Anomaly Likelihood\n",
    "#     likelihood = anomalyLikelihood.anomalyProbability(data[i]['inputVal'], data[i]['AnomalyScore'], data[i]['inputTs'])\n",
    "#     #likelihood = anomalyLikelihood.anomalyProbability(inputData[\"value\"], anomalyScore, inputData[\"dttm\"])\n",
    "#     logLikelihood = anomalyLikelihood.computeLogLikelihood(likelihood)\n",
    "#     data[i]['lh'] = likelihood    \n",
    "#     data[i]['logLH'] = likelihood\n",
    "#     #if likelihood > 0.9999:\n",
    "#         #print \"Anomaly detected:\", track[i]['inputVal'], track[i]['inputTs'], likelihood\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: send the same sequence of vectors and look at predictions made by\n",
    "# temporal memory\n",
    "\n",
    "\n",
    "for i in xrange(len(data)):  # len(data) \n",
    "#     print \"\\n\\n--------\" + str(i) + \"-----------\"\n",
    "#     print \"Raw input vector\\n\",formatRow(track[i]['sp4tm'])\n",
    "\n",
    "    # Send each vector to the TP, with learning turned off\n",
    "    tm.compute(data[i]['sp4tm'], enableLearn=True, enableInference=True)\n",
    "\n",
    "    # This method prints out the active state of each cell followed by the\n",
    "    # predicted state of each cell. For convenience the cells are grouped\n",
    "    # 10 at a time. When there are multiple cells per column the printout\n",
    "    # is arranged so the cells in a column are stacked together\n",
    "    #\n",
    "    # What you should notice is that the columns where active state is 1\n",
    "    # represent the SDR for the current input pattern and the columns where\n",
    "    # predicted state is 1 represent the SDR for the next expected pattern\n",
    "#     print \"\\nAll the active and predicted cells:\"\n",
    "#     tm.printStates(printPrevious=False, printLearnState=False)\n",
    "\n",
    "    # tm.getPredictedState() gets the predicted cells.\n",
    "    # predictedCells[c][i] represents the state of the i'th cell in the c'th\n",
    "    # column. To see if a column is predicted, we can simply take the OR\n",
    "    # across all the cells in that column. In numpy we can do this by taking\n",
    "    # the max along axis 1.\n",
    "#     print \"\\n\\nThe following columns are predicted by the temporal memory. This\"\n",
    "#     print \"should correspond to columns in the *next* item in the sequence.\"\n",
    "#     predictedCells = tm.getPredictedState()\n",
    "#     print formatRow(predictedCells.max(axis=1).nonzero())\n",
    "    \n",
    "    ## ANOMALY SCORE\n",
    "    data[i]['TMpredictedCells'] = tm.cellConfidence['t-1']\n",
    "    #data[i]['TMpredictedCells_2'] = tm.infPredictedState['t-1']\n",
    "    data[i]['TMactiveCells'] = tm.infActiveState['t']           \n",
    "    data[i]['AnomalyScore'] = computeRawAnomalyScore(idx_active_cols(tm.infActiveState['t']), idx_active_cols(tm.cellConfidence['t-1']))\n",
    "    #data[i]['AnomalyScore2'] = computeRawAnomalyScore(idx_active_cols(tm.infActiveState['t']), idx_active_cols(tm.infPredictedState['t-1']))\n",
    "    likelihood = anomalyLikelihood.anomalyProbability(data[i]['inputVal'], data[i]['AnomalyScore'], data[i]['inputTs'])\n",
    "    #likelihood = anomalyLikelihood.anomalyProbability(inputData[\"value\"], anomalyScore, inputData[\"dttm\"])\n",
    "    logLikelihood = anomalyLikelihood.computeLogLikelihood(likelihood)\n",
    "    data[i]['lh'] = likelihood    \n",
    "    data[i]['logLH'] = logLikelihood\n",
    "    if likelihood > 0.9999:\n",
    "        data[i]['flag'] = 1\n",
    "    else:\n",
    "        data[i]['flag'] = 0\n",
    "        \n",
    "    ## Anomaly Attribution\n",
    "    # check overlapping columns\n",
    "    idxOverlap = np.in1d(idx_active_cols(tm.infActiveState['t']), idx_active_cols(tm.cellConfidence['t-1']))\n",
    "    # shows actual active column that do not overalp with prediction\n",
    "    data[i]['idxAS'] = idx_active_cols(tm.infActiveState['t'])[idxOverlap == False]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "vAnomalyScore = []\n",
    "#vAnomalyScore2 = []\n",
    "vLH = []\n",
    "vLogLH = []\n",
    "vFlag = []\n",
    "\n",
    "for i in xrange(len(data)):\n",
    "    vAnomalyScore.append(data[i].get('AnomalyScore'))    \n",
    " #   vAnomalyScore2.append(track[i].get('AnomalyScore'))    \n",
    "    vLH.append(data[i].get('lh'))\n",
    "    vLogLH.append(data[i].get('logLH'))\n",
    "    vFlag.append(data[i].get('flag'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7efcb2df9190>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(vAnomalyScore).plot()\n",
    "pd.Series(vLH).plot()\n",
    "pd.Series(vLogLH).plot()\n",
    "pd.Series(vFlag).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_records(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AnomalyScore</th>\n",
       "      <th>TMactiveCells</th>\n",
       "      <th>TMpredictedCells</th>\n",
       "      <th>flag</th>\n",
       "      <th>idxAS</th>\n",
       "      <th>inputSDR</th>\n",
       "      <th>inputSDRts</th>\n",
       "      <th>inputSDRval</th>\n",
       "      <th>inputTs</th>\n",
       "      <th>inputVal</th>\n",
       "      <th>label</th>\n",
       "      <th>lh</th>\n",
       "      <th>logLH</th>\n",
       "      <th>sp4tm</th>\n",
       "      <th>sp_active</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>2013-12-02 21:25:00</td>\n",
       "      <td>76.124162</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.030103</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[7, 17, 95, 145, 147, 162, 164, 178, 185, 189,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>2013-12-02 21:30:00</td>\n",
       "      <td>78.140707</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.030103</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[7, 17, 95, 145, 147, 162, 164, 178, 185, 189,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>2013-12-02 21:35:00</td>\n",
       "      <td>79.329836</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.030103</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[7, 17, 95, 145, 147, 162, 164, 178, 185, 189,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>2013-12-02 21:40:00</td>\n",
       "      <td>78.710418</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.030103</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[7, 17, 95, 145, 147, 162, 164, 178, 185, 189,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>2013-12-02 21:45:00</td>\n",
       "      <td>80.269784</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.030103</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[7, 17, 95, 145, 147, 162, 164, 178, 185, 189,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AnomalyScore                                      TMactiveCells  \\\n",
       "0           1.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "1           1.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "2           1.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "3           0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "4           0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "\n",
       "                                    TMpredictedCells  flag  \\\n",
       "0  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n",
       "1  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n",
       "2  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n",
       "3  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n",
       "4  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n",
       "\n",
       "                                               idxAS  \\\n",
       "0  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "1  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "2  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "3                                                 []   \n",
       "4                                                 []   \n",
       "\n",
       "                                            inputSDR  \\\n",
       "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "\n",
       "                                          inputSDRts  \\\n",
       "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "\n",
       "                                         inputSDRval             inputTs  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, ... 2013-12-02 21:25:00   \n",
       "1  [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, ... 2013-12-02 21:30:00   \n",
       "2  [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, ... 2013-12-02 21:35:00   \n",
       "3  [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, ... 2013-12-02 21:40:00   \n",
       "4  [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, ... 2013-12-02 21:45:00   \n",
       "\n",
       "    inputVal  label   lh     logLH  \\\n",
       "0  76.124162    0.0  0.5  0.030103   \n",
       "1  78.140707    0.0  0.5  0.030103   \n",
       "2  79.329836    0.0  0.5  0.030103   \n",
       "3  78.710418    0.0  0.5  0.030103   \n",
       "4  80.269784    0.0  0.5  0.030103   \n",
       "\n",
       "                                               sp4tm  \\\n",
       "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "\n",
       "                                           sp_active  \n",
       "0  [7, 17, 95, 145, 147, 162, 164, 178, 185, 189,...  \n",
       "1  [7, 17, 95, 145, 147, 162, 164, 178, 185, 189,...  \n",
       "2  [7, 17, 95, 145, 147, 162, 164, 178, 185, 189,...  \n",
       "3  [7, 17, 95, 145, 147, 162, 164, 178, 185, 189,...  \n",
       "4  [7, 17, 95, 145, 147, 162, 164, 178, 185, 189,...  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.dates as mdates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "idcs = df.label[df.label==1].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = 1000\n",
    "b = 2000\n",
    "\n",
    "fig, ax = plt.subplots(2, sharex=True, figsize=(15,7))\n",
    "ax[0].plot(df.inputVal[a:b], color='b')\n",
    "ax[0].set(ylabel='temperature_C', title=PATH_relative)\n",
    "#ax[0].vlines(idcs[a:b], 0, 1, transform=ax[0].get_xaxis_transform(), colors='y')\n",
    "#ax[0].vlines(anomalies_gt, 0, 1, transform=ax[0].get_xaxis_transform(), colors='b', linestyles={'dashed'})\n",
    "ax[0].plot(df.label[a:b], color='y', label='groundtruth')\n",
    "\n",
    "ax[1].plot(df.AnomalyScore[a:b], label='anomaly_score')\n",
    "ax[1].set(ylabel='Anomaly Score and LH')\n",
    "ax[1].plot(df.lh[a:b], color='r', alpha=0.5, label='anomaly_LH')\n",
    "ax[1].plot(df.logLH[a:b], color='c', alpha=0.5, label='logLH')\n",
    "ax[1].axhline(y=0.5, \n",
    "              color='r', linestyle='--', linewidth=0.4)\n",
    "              #xmin=data.anomaly_likelihood.index[a], xmax=data.anomaly_likelihood.index[b])\n",
    "#ax[1].vlines(idcs[a:b], 0, 1, transform=ax[1].get_xaxis_transform(), alpha=0.9, colors='y', label='groundtruth')\n",
    "ax[1].plot(df.label[a:b], color='y', label='groundtruth')\n",
    "ax[1].plot(df.flag[a:b], color='k', label='flag')\n",
    "ax[1].set(xlabel='time (5min)')\n",
    "ax[1].legend(loc=1)\n",
    "\n",
    "#set ticks every week\n",
    "ax[1].xaxis.set_major_locator(mdates.WeekdayLocator())\n",
    "#set major ticks format\n",
    "ax[1].xaxis.set_major_formatter(mdates.DateFormatter('%b %d'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "from nab.scorer import Scorer\n",
    "\n",
    "class Scorer(object):\n",
    "  \"\"\"Class used to score a datafile.\"\"\"\n",
    "\n",
    "  def __init__(self,\n",
    "               timestamps,\n",
    "               predictions,\n",
    "               labels,\n",
    "               windowLimits,\n",
    "               costMatrix,\n",
    "               probationaryPeriod):\n",
    "   \n",
    "    @param predictions   (pandas.Series)   Detector predictions of\n",
    "                                           whether each record is anomalous or\n",
    "                                           not. predictions[\n",
    "                                           0:probationaryPeriod] are ignored.\n",
    "\n",
    "    @param labels        (pandas.DataFrame) Ground truth for each record.\n",
    "                                           For each record there should be a 1\n",
    "                                           or a 0. A 1 implies this record is\n",
    "                                           within an anomalous window.\n",
    "\n",
    "    @param windowLimits  (list)            All the window limits in tuple\n",
    "                                           form: (timestamp start, timestamp\n",
    "                                           end).\n",
    "\n",
    "    @param costmatrix    (dict)            Dictionary containing the\n",
    "                                           cost matrix for this profile.\n",
    "                                           type:  True positive (tp)\n",
    "                                                  False positive (fp)\n",
    "                                                  True Negative (tn)\n",
    "                                                  False Negative (fn)\n",
    "\n",
    "    @param probationaryPeriod\n",
    "                         (int)             Row index after which predictions\n",
    "                                           are scored.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nab.scorer import scoreCorpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save & Load Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "dataOut = copy.deepcopy(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to dump to .json we need to change array to lists and datetime to str\n",
    "\n",
    "for i in xrange(len(dataOut)):\n",
    "    for k,v in dataOut[i].items():\n",
    "        if isinstance(v, np.ndarray):\n",
    "            #print dataOut[i][k].tolist\n",
    "            dataOut[i][k] = dataOut[i][k].tolist()\n",
    "#         if isinstance(v, datetime.datetime):\n",
    "#             dataOut[i][k] = str(dataOut[i][k])\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "       AnomalyScore                                      TMactiveCells  \\\n0               1.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n1               1.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n2               1.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n3               0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n4               0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n5               0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n6               0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n7               0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n8               0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n9               0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n10              0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n11              0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n12              0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n13              0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n14              0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n15              0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n16              0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n17              0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n18              0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n19              0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n20              0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n21              0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n22              0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n23              0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n24              0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n25              0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n26              0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n27              0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n28              0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n29              0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n...             ...                                                ...   \n22663           0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n22664           0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n22665           0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n22666           0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n22667           0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n22668           0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n22669           0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n22670           0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n22671           0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n22672           0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n22673           0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n22674           0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n22675           0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n22676           0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n22677           0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n22678           0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n22679           0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n22680           0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n22681           0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n22682           0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n22683           0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n22684           0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n22685           0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n22686           0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n22687           0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n22688           0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n22689           0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n22690           0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n22691           0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n22692           0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n\n                                        TMpredictedCells  flag  \\\n0      [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n1      [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n2      [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n3      [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n4      [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n5      [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n6      [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n7      [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n8      [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n9      [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n10     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n11     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n12     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n13     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n14     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n15     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n16     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n17     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n18     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n19     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n20     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n21     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n22     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n23     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n24     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n25     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n26     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n27     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n28     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n29     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n...                                                  ...   ...   \n22663  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n22664  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n22665  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n22666  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n22667  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n22668  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n22669  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n22670  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n22671  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n22672  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n22673  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n22674  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n22675  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n22676  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n22677  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n22678  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n22679  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n22680  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n22681  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n22682  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n22683  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n22684  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n22685  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n22686  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n22687  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n22688  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n22689  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n22690  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n22691  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n22692  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n\n                                                   idxAS  \\\n0      [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n1      [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n2      [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n3                                                     []   \n4                                                     []   \n5                                                     []   \n6                                                     []   \n7                                                     []   \n8                                                     []   \n9                                                     []   \n10                                                    []   \n11                                                    []   \n12                                                    []   \n13                                                    []   \n14                                                    []   \n15                                                    []   \n16                                                    []   \n17                                                    []   \n18                                                    []   \n19                                                    []   \n20                                                    []   \n21                                                    []   \n22                                                    []   \n23                                                    []   \n24                                                    []   \n25                                                    []   \n26                                                    []   \n27                                                    []   \n28                                                    []   \n29                                                    []   \n...                                                  ...   \n22663                                                 []   \n22664                                                 []   \n22665                                                 []   \n22666                                                 []   \n22667                                                 []   \n22668                                                 []   \n22669                                                 []   \n22670                                                 []   \n22671                                                 []   \n22672                                                 []   \n22673                                                 []   \n22674                                                 []   \n22675                                                 []   \n22676                                                 []   \n22677                                                 []   \n22678                                                 []   \n22679                                                 []   \n22680                                                 []   \n22681                                                 []   \n22682                                                 []   \n22683                                                 []   \n22684                                                 []   \n22685                                                 []   \n22686                                                 []   \n22687                                                 []   \n22688                                                 []   \n22689                                                 []   \n22690                                                 []   \n22691                                                 []   \n22692                                                 []   \n\n                                                inputSDR  \\\n0      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n1      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n2      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n3      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n4      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n5      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n6      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n7      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n8      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n9      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n10     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n11     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n12     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n13     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n14     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n15     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n16     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n17     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n18     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n19     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n20     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n21     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n23     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n24     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n25     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n26     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n27     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n28     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n29     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n...                                                  ...   \n22663  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22664  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22665  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22666  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22667  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22668  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22669  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22670  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22671  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22672  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22673  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22674  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22675  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22676  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22677  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22678  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22679  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22680  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22681  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22682  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22683  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22684  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22685  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22686  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22687  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22688  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22689  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22690  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22691  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22692  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n\n                                              inputSDRts  \\\n0      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n1      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n2      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n3      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n4      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n5      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n6      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n7      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n8      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n9      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n10     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n11     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n12     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n13     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n14     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n15     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n16     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n17     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n18     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n19     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n20     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n21     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n23     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n24     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n25     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n26     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n27     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n28     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n29     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n...                                                  ...   \n22663  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22664  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22665  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22666  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22667  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22668  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22669  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22670  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22671  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22672  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22673  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22674  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22675  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22676  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22677  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22678  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22679  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22680  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22681  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22682  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22683  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22684  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22685  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22686  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22687  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22688  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22689  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22690  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22691  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22692  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n\n                                             inputSDRval             inputTs  \\\n0      [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, ... 2013-12-02 21:25:00   \n1      [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, ... 2013-12-02 21:30:00   \n2      [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, ... 2013-12-02 21:35:00   \n3      [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, ... 2013-12-02 21:40:00   \n4      [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, ... 2013-12-02 21:45:00   \n5      [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, ... 2013-12-02 21:50:00   \n6      [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, ... 2013-12-02 21:55:00   \n7      [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, ... 2013-12-02 22:00:00   \n8      [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, ... 2013-12-02 22:05:00   \n9      [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, ... 2013-12-02 22:10:00   \n10     [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, ... 2013-12-02 22:15:00   \n11     [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, ... 2013-12-02 22:20:00   \n12     [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, ... 2013-12-02 22:25:00   \n13     [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, ... 2013-12-02 22:30:00   \n14     [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, ... 2013-12-02 22:35:00   \n15     [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, ... 2013-12-02 22:40:00   \n16     [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, ... 2013-12-02 22:45:00   \n17     [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, ... 2013-12-02 22:50:00   \n18     [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, ... 2013-12-02 22:55:00   \n19     [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, ... 2013-12-02 23:00:00   \n20     [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, ... 2013-12-02 23:05:00   \n21     [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, ... 2013-12-02 23:10:00   \n22     [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, ... 2013-12-02 23:15:00   \n23     [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, ... 2013-12-02 23:20:00   \n24     [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, ... 2013-12-02 23:25:00   \n25     [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, ... 2013-12-02 23:30:00   \n26     [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, ... 2013-12-02 23:35:00   \n27     [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, ... 2013-12-02 23:40:00   \n28     [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, ... 2013-12-02 23:45:00   \n29     [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, ... 2013-12-02 23:50:00   \n...                                                  ...                 ...   \n22663  [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, ... 2014-02-19 13:00:00   \n22664  [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, ... 2014-02-19 13:05:00   \n22665  [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, ... 2014-02-19 13:10:00   \n22666  [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, ... 2014-02-19 13:15:00   \n22667  [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, ... 2014-02-19 13:20:00   \n22668  [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, ... 2014-02-19 13:25:00   \n22669  [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, ... 2014-02-19 13:30:00   \n22670  [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, ... 2014-02-19 13:35:00   \n22671  [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, ... 2014-02-19 13:40:00   \n22672  [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, ... 2014-02-19 13:45:00   \n22673  [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, ... 2014-02-19 13:50:00   \n22674  [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, ... 2014-02-19 13:55:00   \n22675  [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, ... 2014-02-19 14:00:00   \n22676  [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, ... 2014-02-19 14:05:00   \n22677  [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, ... 2014-02-19 14:10:00   \n22678  [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, ... 2014-02-19 14:15:00   \n22679  [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, ... 2014-02-19 14:20:00   \n22680  [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, ... 2014-02-19 14:25:00   \n22681  [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, ... 2014-02-19 14:30:00   \n22682  [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, ... 2014-02-19 14:35:00   \n22683  [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, ... 2014-02-19 14:40:00   \n22684  [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, ... 2014-02-19 14:45:00   \n22685  [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, ... 2014-02-19 14:50:00   \n22686  [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, ... 2014-02-19 14:55:00   \n22687  [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, ... 2014-02-19 15:00:00   \n22688  [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, ... 2014-02-19 15:05:00   \n22689  [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, ... 2014-02-19 15:10:00   \n22690  [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, ... 2014-02-19 15:15:00   \n22691  [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, ... 2014-02-19 15:20:00   \n22692  [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, ... 2014-02-19 15:25:00   \n\n        inputVal  label        lh     logLH  \\\n0      76.124162    0.0  0.500000  0.030103   \n1      78.140707    0.0  0.500000  0.030103   \n2      79.329836    0.0  0.500000  0.030103   \n3      78.710418    0.0  0.500000  0.030103   \n4      80.269784    0.0  0.500000  0.030103   \n5      80.272828    0.0  0.500000  0.030103   \n6      80.353425    0.0  0.500000  0.030103   \n7      79.486523    0.0  0.500000  0.030103   \n8      80.783277    0.0  0.500000  0.030103   \n9      79.508159    0.0  0.500000  0.030103   \n10     79.302033    0.0  0.500000  0.030103   \n11     80.802624    0.0  0.500000  0.030103   \n12     80.377789    0.0  0.500000  0.030103   \n13     80.479237    0.0  0.500000  0.030103   \n14     81.423560    0.0  0.500000  0.030103   \n15     81.373575    0.0  0.500000  0.030103   \n16     81.690942    0.0  0.500000  0.030103   \n17     80.181250    0.0  0.500000  0.030103   \n18     81.767178    0.0  0.500000  0.030103   \n19     81.259781    0.0  0.500000  0.030103   \n20     80.302937    0.0  0.500000  0.030103   \n21     81.114590    0.0  0.500000  0.030103   \n22     81.748109    0.0  0.500000  0.030103   \n23     81.994607    0.0  0.500000  0.030103   \n24     81.258053    0.0  0.500000  0.030103   \n25     83.118039    0.0  0.500000  0.030103   \n26     81.247021    0.0  0.500000  0.030103   \n27     82.735869    0.0  0.500000  0.030103   \n28     81.723326    0.0  0.500000  0.030103   \n29     81.562356    0.0  0.500000  0.030103   \n...          ...    ...       ...       ...   \n22663  93.405691    0.0  0.958369  0.138059   \n22664  94.124466    0.0  0.958369  0.138059   \n22665  93.650855    0.0  0.958369  0.138059   \n22666  94.342091    0.0  0.958369  0.138059   \n22667  94.617205    0.0  0.958369  0.138059   \n22668  94.534074    0.0  0.958369  0.138059   \n22669  94.806127    0.0  0.958369  0.138059   \n22670  95.553183    0.0  0.958369  0.138059   \n22671  94.657280    0.0  0.958369  0.138059   \n22672  95.377308    0.0  0.958369  0.138059   \n22673  96.820556    0.0  0.958369  0.138059   \n22674  94.900900    0.0  0.958369  0.138059   \n22675  95.108901    0.0  0.958369  0.138059   \n22676  97.184352    0.0  0.958369  0.138059   \n22677  95.556043    0.0  0.958369  0.138059   \n22678  96.103572    0.0  0.958369  0.138059   \n22679  95.961107    0.0  0.958369  0.138059   \n22680  97.760870    0.0  0.958369  0.138059   \n22681  97.175704    0.0  0.958369  0.138059   \n22682  96.768563    0.0  0.958369  0.138059   \n22683  96.739868    0.0  0.958369  0.138059   \n22684  97.284578    0.0  0.958369  0.138059   \n22685  97.549774    0.0  0.958369  0.138059   \n22686  98.162952    0.0  0.958369  0.138059   \n22687  97.360905    0.0  0.958369  0.138059   \n22688  98.185415    0.0  0.958369  0.138059   \n22689  97.804168    0.0  0.958369  0.138059   \n22690  97.135468    0.0  0.958369  0.138059   \n22691  98.056852    0.0  0.958369  0.138059   \n22692  96.903861    0.0  0.958369  0.138059   \n\n                                                   sp4tm  \\\n0      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n1      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n2      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n3      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n4      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n5      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n6      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n7      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n8      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n9      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n10     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n11     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n12     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n13     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n14     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n15     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n16     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n17     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n18     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n19     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n20     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n21     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n23     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n24     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n25     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n26     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n27     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n28     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n29     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n...                                                  ...   \n22663  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22664  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22665  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22666  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22667  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22668  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22669  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22670  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22671  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22672  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22673  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22674  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22675  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22676  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22677  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22678  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22679  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22680  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22681  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22682  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22683  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22684  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22685  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22686  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22687  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22688  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22689  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22690  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22691  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22692  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n\n                                               sp_active  \n0      [7, 17, 95, 145, 147, 162, 164, 178, 185, 189,...  \n1      [7, 17, 95, 145, 147, 162, 164, 178, 185, 189,...  \n2      [7, 17, 95, 145, 147, 162, 164, 178, 185, 189,...  \n3      [7, 17, 95, 145, 147, 162, 164, 178, 185, 189,...  \n4      [7, 17, 95, 145, 147, 162, 164, 178, 185, 189,...  \n5      [7, 17, 95, 145, 147, 162, 164, 178, 185, 189,...  \n6      [7, 17, 95, 145, 147, 162, 164, 178, 185, 189,...  \n7      [7, 17, 95, 145, 147, 162, 164, 178, 185, 189,...  \n8      [7, 17, 95, 145, 147, 162, 164, 178, 185, 189,...  \n9      [7, 17, 95, 145, 147, 162, 164, 178, 185, 189,...  \n10     [7, 17, 95, 145, 147, 162, 164, 178, 185, 189,...  \n11     [7, 17, 95, 145, 147, 162, 164, 178, 185, 189,...  \n12     [7, 17, 95, 145, 147, 162, 164, 178, 185, 189,...  \n13     [7, 17, 95, 145, 147, 162, 164, 178, 185, 189,...  \n14     [7, 17, 95, 145, 147, 162, 164, 178, 185, 189,...  \n15     [7, 17, 95, 145, 147, 162, 164, 178, 185, 189,...  \n16     [7, 17, 95, 145, 147, 162, 164, 178, 185, 189,...  \n17     [7, 17, 95, 145, 147, 162, 164, 178, 185, 189,...  \n18     [7, 17, 95, 145, 147, 162, 164, 178, 185, 189,...  \n19     [7, 17, 95, 145, 147, 162, 164, 178, 185, 189,...  \n20     [7, 17, 95, 145, 147, 162, 164, 178, 185, 189,...  \n21     [7, 17, 95, 145, 147, 162, 164, 178, 185, 189,...  \n22     [7, 17, 95, 145, 147, 162, 164, 178, 185, 189,...  \n23     [7, 17, 95, 145, 147, 162, 164, 178, 185, 189,...  \n24     [7, 17, 95, 145, 147, 162, 164, 178, 185, 189,...  \n25     [7, 17, 95, 145, 147, 162, 164, 178, 185, 189,...  \n26     [7, 17, 95, 145, 147, 162, 164, 178, 185, 189,...  \n27     [7, 17, 95, 145, 147, 162, 164, 178, 185, 189,...  \n28     [7, 17, 95, 145, 147, 162, 164, 178, 185, 189,...  \n29     [7, 17, 95, 145, 147, 162, 164, 178, 185, 189,...  \n...                                                  ...  \n22663  [7, 17, 31, 72, 77, 95, 145, 162, 164, 178, 18...  \n22664  [7, 17, 31, 72, 77, 95, 145, 162, 164, 178, 18...  \n22665  [7, 17, 31, 72, 77, 95, 145, 162, 164, 178, 18...  \n22666  [7, 17, 31, 72, 77, 95, 145, 162, 164, 178, 18...  \n22667  [7, 17, 31, 72, 77, 95, 145, 162, 164, 178, 18...  \n22668  [7, 17, 31, 72, 77, 95, 145, 162, 164, 178, 18...  \n22669  [7, 17, 31, 72, 77, 95, 145, 162, 164, 178, 18...  \n22670  [7, 17, 31, 72, 77, 95, 145, 162, 164, 178, 18...  \n22671  [7, 17, 31, 72, 77, 95, 145, 162, 164, 178, 18...  \n22672  [7, 17, 31, 72, 77, 95, 145, 162, 164, 178, 18...  \n22673  [7, 17, 31, 72, 77, 95, 145, 162, 164, 178, 18...  \n22674  [7, 17, 31, 72, 77, 95, 145, 162, 164, 178, 18...  \n22675  [7, 17, 31, 72, 77, 95, 145, 162, 164, 178, 18...  \n22676  [7, 17, 31, 72, 77, 95, 145, 162, 164, 178, 18...  \n22677  [7, 17, 31, 72, 77, 95, 145, 162, 164, 178, 18...  \n22678  [7, 17, 31, 72, 77, 95, 145, 162, 164, 178, 18...  \n22679  [7, 17, 31, 72, 77, 95, 145, 162, 164, 178, 18...  \n22680  [7, 17, 31, 72, 77, 95, 145, 162, 164, 178, 18...  \n22681  [7, 17, 31, 72, 77, 95, 145, 162, 164, 178, 18...  \n22682  [7, 17, 31, 72, 77, 95, 145, 162, 164, 178, 18...  \n22683  [7, 17, 31, 72, 77, 95, 145, 162, 164, 178, 18...  \n22684  [7, 17, 31, 72, 77, 95, 145, 162, 164, 178, 18...  \n22685  [7, 17, 31, 72, 77, 95, 145, 162, 164, 178, 18...  \n22686  [7, 17, 31, 72, 77, 95, 145, 162, 164, 178, 18...  \n22687  [7, 17, 31, 72, 77, 95, 145, 162, 164, 178, 18...  \n22688  [7, 17, 31, 72, 77, 95, 145, 162, 164, 178, 18...  \n22689  [7, 17, 31, 72, 77, 95, 145, 162, 164, 178, 18...  \n22690  [7, 17, 31, 72, 77, 95, 145, 162, 164, 178, 18...  \n22691  [7, 17, 31, 72, 77, 95, 145, 162, 164, 178, 18...  \n22692  [7, 17, 31, 72, 77, 95, 145, 162, 164, 178, 18...  \n\n[22693 rows x 15 columns] is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-bc6da4f388ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'univ_swarm_spLearnFalse_tmLearnAll.json'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseparators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m': '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/python2.7/json/__init__.pyc\u001b[0m in \u001b[0;36mdump\u001b[0;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, encoding, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;31m# could accelerate with writelines in some versions of Python, at\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;31m# a debuggability cost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/json/encoder.pyc\u001b[0m in \u001b[0;36m_iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    440\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Circular reference detected\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                 \u001b[0mmarkers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmarkerid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m             \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/json/encoder.pyc\u001b[0m in \u001b[0;36mdefault\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \"\"\"\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" is not JSON serializable\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m:        AnomalyScore                                      TMactiveCells  \\\n0               1.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n1               1.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n2               1.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n3               0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n4               0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n5               0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n6               0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n7               0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n8               0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n9               0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n10              0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n11              0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n12              0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n13              0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n14              0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n15              0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n16              0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n17              0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n18              0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n19              0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n20              0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n21              0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n22              0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n23              0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n24              0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n25              0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n26              0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n27              0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n28              0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n29              0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n...             ...                                                ...   \n22663           0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n22664           0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n22665           0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n22666           0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n22667           0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n22668           0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n22669           0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n22670           0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n22671           0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n22672           0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n22673           0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n22674           0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n22675           0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n22676           0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n22677           0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n22678           0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n22679           0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n22680           0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n22681           0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n22682           0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n22683           0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n22684           0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n22685           0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n22686           0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n22687           0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n22688           0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n22689           0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n22690           0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n22691           0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n22692           0.0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n\n                                        TMpredictedCells  flag  \\\n0      [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n1      [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n2      [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n3      [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n4      [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n5      [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n6      [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n7      [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n8      [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n9      [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n10     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n11     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n12     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n13     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n14     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n15     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n16     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n17     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n18     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n19     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n20     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n21     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n22     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n23     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n24     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n25     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n26     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n27     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n28     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n29     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n...                                                  ...   ...   \n22663  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n22664  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n22665  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n22666  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n22667  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n22668  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n22669  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n22670  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n22671  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n22672  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n22673  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n22674  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n22675  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n22676  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n22677  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n22678  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n22679  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n22680  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n22681  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n22682  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n22683  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n22684  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n22685  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n22686  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n22687  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n22688  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n22689  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n22690  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n22691  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n22692  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...     0   \n\n                                                   idxAS  \\\n0      [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n1      [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n2      [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n3                                                     []   \n4                                                     []   \n5                                                     []   \n6                                                     []   \n7                                                     []   \n8                                                     []   \n9                                                     []   \n10                                                    []   \n11                                                    []   \n12                                                    []   \n13                                                    []   \n14                                                    []   \n15                                                    []   \n16                                                    []   \n17                                                    []   \n18                                                    []   \n19                                                    []   \n20                                                    []   \n21                                                    []   \n22                                                    []   \n23                                                    []   \n24                                                    []   \n25                                                    []   \n26                                                    []   \n27                                                    []   \n28                                                    []   \n29                                                    []   \n...                                                  ...   \n22663                                                 []   \n22664                                                 []   \n22665                                                 []   \n22666                                                 []   \n22667                                                 []   \n22668                                                 []   \n22669                                                 []   \n22670                                                 []   \n22671                                                 []   \n22672                                                 []   \n22673                                                 []   \n22674                                                 []   \n22675                                                 []   \n22676                                                 []   \n22677                                                 []   \n22678                                                 []   \n22679                                                 []   \n22680                                                 []   \n22681                                                 []   \n22682                                                 []   \n22683                                                 []   \n22684                                                 []   \n22685                                                 []   \n22686                                                 []   \n22687                                                 []   \n22688                                                 []   \n22689                                                 []   \n22690                                                 []   \n22691                                                 []   \n22692                                                 []   \n\n                                                inputSDR  \\\n0      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n1      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n2      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n3      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n4      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n5      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n6      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n7      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n8      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n9      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n10     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n11     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n12     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n13     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n14     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n15     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n16     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n17     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n18     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n19     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n20     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n21     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n23     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n24     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n25     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n26     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n27     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n28     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n29     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n...                                                  ...   \n22663  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22664  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22665  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22666  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22667  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22668  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22669  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22670  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22671  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22672  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22673  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22674  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22675  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22676  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22677  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22678  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22679  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22680  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22681  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22682  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22683  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22684  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22685  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22686  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22687  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22688  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22689  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22690  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22691  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22692  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n\n                                              inputSDRts  \\\n0      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n1      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n2      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n3      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n4      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n5      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n6      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n7      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n8      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n9      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n10     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n11     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n12     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n13     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n14     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n15     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n16     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n17     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n18     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n19     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n20     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n21     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n23     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n24     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n25     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n26     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n27     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n28     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n29     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n...                                                  ...   \n22663  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22664  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22665  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22666  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22667  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22668  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22669  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22670  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22671  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22672  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22673  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22674  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22675  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22676  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22677  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22678  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22679  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22680  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22681  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22682  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22683  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22684  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22685  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22686  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22687  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22688  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22689  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22690  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22691  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22692  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n\n                                             inputSDRval             inputTs  \\\n0      [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, ... 2013-12-02 21:25:00   \n1      [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, ... 2013-12-02 21:30:00   \n2      [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, ... 2013-12-02 21:35:00   \n3      [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, ... 2013-12-02 21:40:00   \n4      [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, ... 2013-12-02 21:45:00   \n5      [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, ... 2013-12-02 21:50:00   \n6      [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, ... 2013-12-02 21:55:00   \n7      [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, ... 2013-12-02 22:00:00   \n8      [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, ... 2013-12-02 22:05:00   \n9      [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, ... 2013-12-02 22:10:00   \n10     [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, ... 2013-12-02 22:15:00   \n11     [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, ... 2013-12-02 22:20:00   \n12     [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, ... 2013-12-02 22:25:00   \n13     [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, ... 2013-12-02 22:30:00   \n14     [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, ... 2013-12-02 22:35:00   \n15     [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, ... 2013-12-02 22:40:00   \n16     [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, ... 2013-12-02 22:45:00   \n17     [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, ... 2013-12-02 22:50:00   \n18     [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, ... 2013-12-02 22:55:00   \n19     [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, ... 2013-12-02 23:00:00   \n20     [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, ... 2013-12-02 23:05:00   \n21     [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, ... 2013-12-02 23:10:00   \n22     [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, ... 2013-12-02 23:15:00   \n23     [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, ... 2013-12-02 23:20:00   \n24     [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, ... 2013-12-02 23:25:00   \n25     [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, ... 2013-12-02 23:30:00   \n26     [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, ... 2013-12-02 23:35:00   \n27     [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, ... 2013-12-02 23:40:00   \n28     [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, ... 2013-12-02 23:45:00   \n29     [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, ... 2013-12-02 23:50:00   \n...                                                  ...                 ...   \n22663  [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, ... 2014-02-19 13:00:00   \n22664  [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, ... 2014-02-19 13:05:00   \n22665  [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, ... 2014-02-19 13:10:00   \n22666  [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, ... 2014-02-19 13:15:00   \n22667  [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, ... 2014-02-19 13:20:00   \n22668  [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, ... 2014-02-19 13:25:00   \n22669  [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, ... 2014-02-19 13:30:00   \n22670  [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, ... 2014-02-19 13:35:00   \n22671  [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, ... 2014-02-19 13:40:00   \n22672  [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, ... 2014-02-19 13:45:00   \n22673  [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, ... 2014-02-19 13:50:00   \n22674  [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, ... 2014-02-19 13:55:00   \n22675  [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, ... 2014-02-19 14:00:00   \n22676  [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, ... 2014-02-19 14:05:00   \n22677  [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, ... 2014-02-19 14:10:00   \n22678  [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, ... 2014-02-19 14:15:00   \n22679  [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, ... 2014-02-19 14:20:00   \n22680  [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, ... 2014-02-19 14:25:00   \n22681  [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, ... 2014-02-19 14:30:00   \n22682  [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, ... 2014-02-19 14:35:00   \n22683  [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, ... 2014-02-19 14:40:00   \n22684  [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, ... 2014-02-19 14:45:00   \n22685  [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, ... 2014-02-19 14:50:00   \n22686  [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, ... 2014-02-19 14:55:00   \n22687  [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, ... 2014-02-19 15:00:00   \n22688  [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, ... 2014-02-19 15:05:00   \n22689  [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, ... 2014-02-19 15:10:00   \n22690  [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, ... 2014-02-19 15:15:00   \n22691  [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, ... 2014-02-19 15:20:00   \n22692  [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, ... 2014-02-19 15:25:00   \n\n        inputVal  label        lh     logLH  \\\n0      76.124162    0.0  0.500000  0.030103   \n1      78.140707    0.0  0.500000  0.030103   \n2      79.329836    0.0  0.500000  0.030103   \n3      78.710418    0.0  0.500000  0.030103   \n4      80.269784    0.0  0.500000  0.030103   \n5      80.272828    0.0  0.500000  0.030103   \n6      80.353425    0.0  0.500000  0.030103   \n7      79.486523    0.0  0.500000  0.030103   \n8      80.783277    0.0  0.500000  0.030103   \n9      79.508159    0.0  0.500000  0.030103   \n10     79.302033    0.0  0.500000  0.030103   \n11     80.802624    0.0  0.500000  0.030103   \n12     80.377789    0.0  0.500000  0.030103   \n13     80.479237    0.0  0.500000  0.030103   \n14     81.423560    0.0  0.500000  0.030103   \n15     81.373575    0.0  0.500000  0.030103   \n16     81.690942    0.0  0.500000  0.030103   \n17     80.181250    0.0  0.500000  0.030103   \n18     81.767178    0.0  0.500000  0.030103   \n19     81.259781    0.0  0.500000  0.030103   \n20     80.302937    0.0  0.500000  0.030103   \n21     81.114590    0.0  0.500000  0.030103   \n22     81.748109    0.0  0.500000  0.030103   \n23     81.994607    0.0  0.500000  0.030103   \n24     81.258053    0.0  0.500000  0.030103   \n25     83.118039    0.0  0.500000  0.030103   \n26     81.247021    0.0  0.500000  0.030103   \n27     82.735869    0.0  0.500000  0.030103   \n28     81.723326    0.0  0.500000  0.030103   \n29     81.562356    0.0  0.500000  0.030103   \n...          ...    ...       ...       ...   \n22663  93.405691    0.0  0.958369  0.138059   \n22664  94.124466    0.0  0.958369  0.138059   \n22665  93.650855    0.0  0.958369  0.138059   \n22666  94.342091    0.0  0.958369  0.138059   \n22667  94.617205    0.0  0.958369  0.138059   \n22668  94.534074    0.0  0.958369  0.138059   \n22669  94.806127    0.0  0.958369  0.138059   \n22670  95.553183    0.0  0.958369  0.138059   \n22671  94.657280    0.0  0.958369  0.138059   \n22672  95.377308    0.0  0.958369  0.138059   \n22673  96.820556    0.0  0.958369  0.138059   \n22674  94.900900    0.0  0.958369  0.138059   \n22675  95.108901    0.0  0.958369  0.138059   \n22676  97.184352    0.0  0.958369  0.138059   \n22677  95.556043    0.0  0.958369  0.138059   \n22678  96.103572    0.0  0.958369  0.138059   \n22679  95.961107    0.0  0.958369  0.138059   \n22680  97.760870    0.0  0.958369  0.138059   \n22681  97.175704    0.0  0.958369  0.138059   \n22682  96.768563    0.0  0.958369  0.138059   \n22683  96.739868    0.0  0.958369  0.138059   \n22684  97.284578    0.0  0.958369  0.138059   \n22685  97.549774    0.0  0.958369  0.138059   \n22686  98.162952    0.0  0.958369  0.138059   \n22687  97.360905    0.0  0.958369  0.138059   \n22688  98.185415    0.0  0.958369  0.138059   \n22689  97.804168    0.0  0.958369  0.138059   \n22690  97.135468    0.0  0.958369  0.138059   \n22691  98.056852    0.0  0.958369  0.138059   \n22692  96.903861    0.0  0.958369  0.138059   \n\n                                                   sp4tm  \\\n0      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n1      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n2      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n3      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n4      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n5      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n6      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n7      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n8      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n9      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n10     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n11     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n12     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n13     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n14     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n15     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n16     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n17     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n18     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n19     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n20     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n21     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n23     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n24     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n25     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n26     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n27     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n28     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n29     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n...                                                  ...   \n22663  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22664  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22665  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22666  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22667  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22668  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22669  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22670  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22671  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22672  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22673  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22674  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22675  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22676  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22677  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22678  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22679  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22680  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22681  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22682  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22683  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22684  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22685  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22686  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22687  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22688  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22689  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22690  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22691  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n22692  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n\n                                               sp_active  \n0      [7, 17, 95, 145, 147, 162, 164, 178, 185, 189,...  \n1      [7, 17, 95, 145, 147, 162, 164, 178, 185, 189,...  \n2      [7, 17, 95, 145, 147, 162, 164, 178, 185, 189,...  \n3      [7, 17, 95, 145, 147, 162, 164, 178, 185, 189,...  \n4      [7, 17, 95, 145, 147, 162, 164, 178, 185, 189,...  \n5      [7, 17, 95, 145, 147, 162, 164, 178, 185, 189,...  \n6      [7, 17, 95, 145, 147, 162, 164, 178, 185, 189,...  \n7      [7, 17, 95, 145, 147, 162, 164, 178, 185, 189,...  \n8      [7, 17, 95, 145, 147, 162, 164, 178, 185, 189,...  \n9      [7, 17, 95, 145, 147, 162, 164, 178, 185, 189,...  \n10     [7, 17, 95, 145, 147, 162, 164, 178, 185, 189,...  \n11     [7, 17, 95, 145, 147, 162, 164, 178, 185, 189,...  \n12     [7, 17, 95, 145, 147, 162, 164, 178, 185, 189,...  \n13     [7, 17, 95, 145, 147, 162, 164, 178, 185, 189,...  \n14     [7, 17, 95, 145, 147, 162, 164, 178, 185, 189,...  \n15     [7, 17, 95, 145, 147, 162, 164, 178, 185, 189,...  \n16     [7, 17, 95, 145, 147, 162, 164, 178, 185, 189,...  \n17     [7, 17, 95, 145, 147, 162, 164, 178, 185, 189,...  \n18     [7, 17, 95, 145, 147, 162, 164, 178, 185, 189,...  \n19     [7, 17, 95, 145, 147, 162, 164, 178, 185, 189,...  \n20     [7, 17, 95, 145, 147, 162, 164, 178, 185, 189,...  \n21     [7, 17, 95, 145, 147, 162, 164, 178, 185, 189,...  \n22     [7, 17, 95, 145, 147, 162, 164, 178, 185, 189,...  \n23     [7, 17, 95, 145, 147, 162, 164, 178, 185, 189,...  \n24     [7, 17, 95, 145, 147, 162, 164, 178, 185, 189,...  \n25     [7, 17, 95, 145, 147, 162, 164, 178, 185, 189,...  \n26     [7, 17, 95, 145, 147, 162, 164, 178, 185, 189,...  \n27     [7, 17, 95, 145, 147, 162, 164, 178, 185, 189,...  \n28     [7, 17, 95, 145, 147, 162, 164, 178, 185, 189,...  \n29     [7, 17, 95, 145, 147, 162, 164, 178, 185, 189,...  \n...                                                  ...  \n22663  [7, 17, 31, 72, 77, 95, 145, 162, 164, 178, 18...  \n22664  [7, 17, 31, 72, 77, 95, 145, 162, 164, 178, 18...  \n22665  [7, 17, 31, 72, 77, 95, 145, 162, 164, 178, 18...  \n22666  [7, 17, 31, 72, 77, 95, 145, 162, 164, 178, 18...  \n22667  [7, 17, 31, 72, 77, 95, 145, 162, 164, 178, 18...  \n22668  [7, 17, 31, 72, 77, 95, 145, 162, 164, 178, 18...  \n22669  [7, 17, 31, 72, 77, 95, 145, 162, 164, 178, 18...  \n22670  [7, 17, 31, 72, 77, 95, 145, 162, 164, 178, 18...  \n22671  [7, 17, 31, 72, 77, 95, 145, 162, 164, 178, 18...  \n22672  [7, 17, 31, 72, 77, 95, 145, 162, 164, 178, 18...  \n22673  [7, 17, 31, 72, 77, 95, 145, 162, 164, 178, 18...  \n22674  [7, 17, 31, 72, 77, 95, 145, 162, 164, 178, 18...  \n22675  [7, 17, 31, 72, 77, 95, 145, 162, 164, 178, 18...  \n22676  [7, 17, 31, 72, 77, 95, 145, 162, 164, 178, 18...  \n22677  [7, 17, 31, 72, 77, 95, 145, 162, 164, 178, 18...  \n22678  [7, 17, 31, 72, 77, 95, 145, 162, 164, 178, 18...  \n22679  [7, 17, 31, 72, 77, 95, 145, 162, 164, 178, 18...  \n22680  [7, 17, 31, 72, 77, 95, 145, 162, 164, 178, 18...  \n22681  [7, 17, 31, 72, 77, 95, 145, 162, 164, 178, 18...  \n22682  [7, 17, 31, 72, 77, 95, 145, 162, 164, 178, 18...  \n22683  [7, 17, 31, 72, 77, 95, 145, 162, 164, 178, 18...  \n22684  [7, 17, 31, 72, 77, 95, 145, 162, 164, 178, 18...  \n22685  [7, 17, 31, 72, 77, 95, 145, 162, 164, 178, 18...  \n22686  [7, 17, 31, 72, 77, 95, 145, 162, 164, 178, 18...  \n22687  [7, 17, 31, 72, 77, 95, 145, 162, 164, 178, 18...  \n22688  [7, 17, 31, 72, 77, 95, 145, 162, 164, 178, 18...  \n22689  [7, 17, 31, 72, 77, 95, 145, 162, 164, 178, 18...  \n22690  [7, 17, 31, 72, 77, 95, 145, 162, 164, 178, 18...  \n22691  [7, 17, 31, 72, 77, 95, 145, 162, 164, 178, 18...  \n22692  [7, 17, 31, 72, 77, 95, 145, 162, 164, 178, 18...  \n\n[22693 rows x 15 columns] is not JSON serializable"
     ]
    }
   ],
   "source": [
    "filename = 'univ_swarm_spLearnFalse_tmLearnAll.json'\n",
    "with open(filename, 'w') as f:\n",
    "    json.dump(df, f, indent=4, sort_keys=True, separators=(',', ': '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(filename, 'r') as f:\n",
    "#         track = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-80a4aab09c73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redirecting Anomaly Score\n",
    "\n",
    "Once an AS has been outputed, we want to know which are the cells the where unpredicted and causes the error to raise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------- 4 -----------  \n",
    "Raw input vector  \n",
    "0000010000 0010010000 0   \n",
    "\n",
    "==== PY Iteration: 56 =====  \n",
    "Previous learned pattern: array([ 0,  2,  4,  5, 19])  \n",
    "  \n",
    "Active cols: [ 5 12 15]  \n",
    "Inference Active state  \n",
    "0000000000 0000000000 0  \n",
    "0000010000 0000010000 0  \n",
    "0000000000 0010000000 0  \n",
    "  \n",
    "Inference Predicted state: [1, 7, 8, 14, 20]  \n",
    "0000000000 0000000000 0  \n",
    "0100000110 0000000000 1  \n",
    "0000000000 0000100000 0  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'backup': array([[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]], dtype=int8), 'candidate': array([[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]], dtype=int8), 't': array([[0, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 1, 0]], dtype=int8), 't-1': array([[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]], dtype=int8)}"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tm.infPredictedState # [t] predicted to be active next, [t-1] predicted before, for current input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  7  8 14 20] \n"
     ]
    }
   ],
   "source": [
    "predictedCells = tm.getPredictedState()\n",
    "print formatRow(predictedCells.max(axis=1).nonzero())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 1, 0]], dtype=int8)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tm.getPredictedState()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 0 Cell 1 : 2 segment(s)\n",
      "   Seg #0   ID:10    True 0.1785714 (  10/10  )    3 [1,1]1.00 [1,2]0.50 [7,1]1.00 [8,1]1.00 [8,2]0.50 [14,1]0.50 [14,2]1.00 [20,1]1.00\n",
      "   Seg #1   ID:36    True 0.0178571 (   1/1   )   23 [1,0]0.50 [7,0]0.50 [8,0]0.50 [14,0]0.50 [20,0]0.50\n",
      "Column 0 Cell 2 : 1 segment(s)\n",
      "   Seg #0   ID:23    True 0.1964286 (  11/11  )    1 [2,1]1.00 [10,1]1.00 [12,1]1.00 [16,2]1.00 [17,2]1.00 [20,1]1.00\n",
      "Column 1 Cell 1 : 2 segment(s)\n",
      "   Seg #0   ID:0     True 0.0178571 (   1/1   )   55\n",
      "  *Seg #1   ID:31    True 0.1785714 (  10/11  )    4 [5,1]1.00 [12,2]1.00 [15,1]1.00\n",
      "Column 1 Cell 2 : 1 segment(s)\n",
      "   Seg #0   ID:5     True 0.0178571 (   1/10  )   54 [1,1]0.50 [7,2]0.50 [8,1]0.50 [14,1]0.50 [20,2]0.50\n",
      "Column 2 Cell 1 : 3 segment(s)\n",
      "   Seg #0   ID:11    True 0.1785714 (  10/10  )    3 [1,1]1.00 [1,2]0.50 [7,1]1.00 [8,1]1.00 [8,2]0.50 [14,1]0.50 [14,2]1.00 [20,1]1.00\n",
      "   Seg #1   ID:17    True 0.1964286 (  11/11  )    2 [0,1]1.00 [2,1]1.00 [6,1]1.00 [11,1]0.50 [11,2]1.00 [13,2]1.00 [14,1]0.50 [14,2]1.00 [15,1]0.50 [15,2]1.00\n",
      "   Seg #2   ID:37    True 0.0178571 (   1/1   )   23 [1,0]0.50 [7,0]0.50 [8,0]0.50 [14,0]0.50 [20,0]0.50\n",
      "Column 2 Cell 2 : 1 segment(s)\n",
      "   Seg #0   ID:24    True 0.1964286 (  11/11  )    1 [2,1]1.00 [10,1]1.00 [12,1]1.00 [16,2]1.00 [17,2]1.00 [20,1]1.00\n",
      "Column 4 Cell 2 : 1 segment(s)\n",
      "   Seg #0   ID:25    True 0.1964286 (  11/11  )    1 [2,1]1.00 [10,1]1.00 [12,1]1.00 [16,2]1.00 [17,2]1.00 [20,1]1.00\n",
      "Column 5 Cell 1 : 2 segment(s)\n",
      "   Seg #0   ID:26    True 0.1964286 (  11/11  )    1 [2,1]1.00 [10,1]1.00 [12,1]1.00 [16,2]1.00 [17,2]1.00 [20,1]1.00\n",
      "   Seg #1   ID:28    True 0.1964286 (  11/11  )    0 [0,2]1.00 [2,2]1.00 [4,2]1.00 [5,1]1.00 [19,2]1.00\n",
      "Column 6 Cell 1 : 2 segment(s)\n",
      "   Seg #0   ID:12    True 0.1785714 (  10/10  )    3 [1,1]1.00 [1,2]0.50 [7,1]1.00 [8,1]1.00 [8,2]0.50 [14,1]0.50 [14,2]1.00 [20,1]1.00\n",
      "   Seg #1   ID:38    True 0.0178571 (   1/1   )   23 [1,0]0.50 [7,0]0.50 [8,0]0.50 [14,0]0.50 [20,0]0.50\n",
      "Column 7 Cell 1 : 2 segment(s)\n",
      "   Seg #0   ID:6     True 0.0178571 (   1/10  )   54 [1,1]0.50 [7,2]0.50 [8,1]0.50 [14,1]0.50 [20,2]0.50\n",
      "  *Seg #1   ID:32    True 0.1785714 (  10/11  )    4 [5,1]1.00 [12,2]1.00 [15,1]1.00\n",
      "Column 7 Cell 2 : 1 segment(s)\n",
      "   Seg #0   ID:1     True 0.0178571 (   1/1   )   55\n",
      "Column 8 Cell 1 : 2 segment(s)\n",
      "   Seg #0   ID:2     True 0.0178571 (   1/1   )   55\n",
      "  *Seg #1   ID:33    True 0.1785714 (  10/11  )    4 [5,1]1.00 [12,2]1.00 [15,1]1.00\n",
      "Column 8 Cell 2 : 1 segment(s)\n",
      "   Seg #0   ID:7     True 0.0178571 (   1/10  )   54 [1,1]0.50 [7,2]0.50 [8,1]0.50 [14,1]0.50 [20,2]0.50\n",
      "Column 10 Cell 1 : 1 segment(s)\n",
      "   Seg #0   ID:18    True 0.1964286 (  11/11  )    2 [0,1]1.00 [2,1]1.00 [6,1]1.00 [11,1]0.50 [11,2]1.00 [13,2]1.00 [14,1]0.50 [14,2]1.00 [15,1]0.50 [15,2]1.00\n",
      "Column 11 Cell 1 : 1 segment(s)\n",
      "   Seg #0   ID:39    True 0.0178571 (   1/1   )   23 [1,0]0.50 [7,0]0.50 [8,0]0.50 [14,0]0.50 [20,0]0.50\n",
      "Column 11 Cell 2 : 1 segment(s)\n",
      "   Seg #0   ID:13    True 0.1785714 (  10/10  )    3 [1,1]1.00 [1,2]0.50 [7,1]1.00 [8,1]1.00 [8,2]0.50 [14,1]0.50 [14,2]1.00 [20,1]1.00\n",
      "Column 12 Cell 1 : 1 segment(s)\n",
      "   Seg #0   ID:19    True 0.1964286 (  11/11  )    2 [0,1]1.00 [2,1]1.00 [6,1]1.00 [11,1]0.50 [11,2]1.00 [13,2]1.00 [14,1]0.50 [14,2]1.00 [15,1]0.50 [15,2]1.00\n",
      "Column 12 Cell 2 : 1 segment(s)\n",
      "   Seg #0   ID:29    True 0.1964286 (  11/11  )    0 [0,2]1.00 [2,2]1.00 [4,2]1.00 [5,1]1.00 [19,2]1.00\n",
      "Column 13 Cell 2 : 2 segment(s)\n",
      "   Seg #0   ID:14    True 0.1785714 (  10/10  )    3 [1,1]1.00 [1,2]0.50 [7,1]1.00 [8,1]1.00 [8,2]0.50 [14,1]0.50 [14,2]1.00 [20,1]1.00\n",
      "   Seg #1   ID:40    True 0.0178571 (   1/1   )   23 [1,0]0.50 [7,0]0.50 [8,0]0.50 [14,0]0.50 [20,0]0.50\n",
      "Column 14 Cell 1 : 3 segment(s)\n",
      "   Seg #0   ID:3     True 0.0178571 (   1/1   )   55\n",
      "   Seg #1   ID:8     True 0.0178571 (   1/1   )   54 [1,1]0.50 [7,2]0.50 [8,1]0.50 [14,1]0.50 [20,2]0.50\n",
      "   Seg #2   ID:41    True 0.0178571 (   1/1   )   23 [1,0]0.50 [7,0]0.50 [8,0]0.50 [14,0]0.50 [20,0]0.50\n",
      "Column 14 Cell 2 : 2 segment(s)\n",
      "   Seg #0   ID:15    True 0.1785714 (  10/10  )    3 [1,1]1.00 [1,2]0.50 [7,1]1.00 [8,1]1.00 [8,2]0.50 [14,1]0.50 [14,2]1.00 [20,1]1.00\n",
      "  *Seg #1   ID:34    True 0.1785714 (  10/11  )    4 [5,1]1.00 [12,2]1.00 [15,1]1.00\n",
      "Column 15 Cell 1 : 2 segment(s)\n",
      "   Seg #0   ID:30    True 0.1964286 (  11/11  )    0 [0,2]1.00 [2,2]1.00 [4,2]1.00 [5,1]1.00 [19,2]1.00\n",
      "   Seg #1   ID:42    True 0.0178571 (   1/1   )   23 [1,0]0.50 [7,0]0.50 [8,0]0.50 [14,0]0.50 [20,0]0.50\n",
      "Column 15 Cell 2 : 1 segment(s)\n",
      "   Seg #0   ID:16    True 0.1785714 (  10/10  )    3 [1,1]1.00 [1,2]0.50 [7,1]1.00 [8,1]1.00 [8,2]0.50 [14,1]0.50 [14,2]1.00 [20,1]1.00\n",
      "Column 16 Cell 2 : 1 segment(s)\n",
      "   Seg #0   ID:20    True 0.1964286 (  11/11  )    2 [0,1]1.00 [2,1]1.00 [6,1]1.00 [11,1]0.50 [11,2]1.00 [13,2]1.00 [14,1]0.50 [14,2]1.00 [15,1]0.50 [15,2]1.00\n",
      "Column 17 Cell 2 : 1 segment(s)\n",
      "   Seg #0   ID:21    True 0.1964286 (  11/11  )    2 [0,1]1.00 [2,1]1.00 [6,1]1.00 [11,1]0.50 [11,2]1.00 [13,2]1.00 [14,1]0.50 [14,2]1.00 [15,1]0.50 [15,2]1.00\n",
      "Column 19 Cell 2 : 1 segment(s)\n",
      "   Seg #0   ID:27    True 0.1964286 (  11/11  )    1 [2,1]1.00 [10,1]1.00 [12,1]1.00 [16,2]1.00 [17,2]1.00 [20,1]1.00\n",
      "Column 20 Cell 1 : 3 segment(s)\n",
      "   Seg #0   ID:9     True 0.0178571 (   1/10  )   54 [1,1]0.50 [7,2]0.50 [8,1]0.50 [14,1]0.50 [20,2]0.50\n",
      "   Seg #1   ID:22    True 0.1964286 (  11/11  )    2 [0,1]1.00 [2,1]1.00 [6,1]1.00 [11,1]0.50 [11,2]1.00 [13,2]1.00 [14,1]0.50 [14,2]1.00 [15,1]0.50 [15,2]1.00\n",
      "  *Seg #2   ID:35    True 0.1785714 (  10/11  )    4 [5,1]1.00 [12,2]1.00 [15,1]1.00\n",
      "Column 20 Cell 2 : 1 segment(s)\n",
      "   Seg #0   ID:4     True 0.0178571 (   1/1   )   55\n"
     ]
    }
   ],
   "source": [
    "for c in xrange(tm.numberOfCols):\n",
    "    for i in xrange(tm.cellsPerColumn):\n",
    "        if not False or tm.infPredictedState['t'][c, i]:\n",
    "            tm.printCell(c, i, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trackability - Feedforward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'inputSDR': array([0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=uint8),\n",
       "  'inputVal': 73.96732207,\n",
       "  'sp_active': 0},\n",
       " {'inputSDR': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=uint8),\n",
       "  'inputVal': 74.93588199999998,\n",
       "  'sp_active': 2},\n",
       " {'inputSDR': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0], dtype=uint8),\n",
       "  'inputVal': 76.12416182,\n",
       "  'sp_active': 1},\n",
       " {'inputSDR': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0], dtype=uint8),\n",
       "  'inputVal': 78.14070732,\n",
       "  'sp_active': 2},\n",
       " {'inputSDR': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0], dtype=uint8),\n",
       "  'inputVal': 79.32983574,\n",
       "  'sp_active': 3}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "track"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input SDR can be Decoded up to a certain granularity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73.96732207"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "track[0]['inputVal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'[70:80]': ([[73.888888888888886, 73.888888888888886]], '73.89')},\n",
       " ['[70:80]'])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vEnc.decode(track[0]['inputSDR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feed SP with `sp.compute(track[i]['inputSDR'], learn=True, activeArray=output)`,  \n",
    "and then the *Temporal Pooler* `inputSDR[track[i]['sp_active']]` = active columns in TM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trackability - Backwards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate *TM output* by feeding in the active columns of the *SP*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spSDR[track[0]['sp_active']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  1.,  0.,  1.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  1.,  0.,  1.,  0.,  0.,  0.,  1.,  0.,  1.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  1.,  0.,\n",
       "        0.,  0.,  1.,  0.,  0.,  1.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tm.compute(spSDR[track[0]['sp_active']], enableLearn=True, enableInference=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return index for ACTIVE columns in TM: \n",
    "tmActive = []\n",
    "\n",
    "for i in range(tm.infActiveState['t'].shape[0]):\n",
    "    # assign 1 if any 1 (active cell) in the column,\n",
    "    # 0 otherwise\n",
    "    if np.any(tm.infActiveState['t'][i]>0):\n",
    "        tmActive.append(1)\n",
    "    else:\n",
    "        tmActive.append(0)\n",
    "# return index of active Columns        \n",
    "tm_active = np.flatnonzero(np.array(tmActive))\n",
    "del(tmActive) # delete list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  7,  8, 14, 20])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tm_active"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build `spSDR[track[0]['sp_active']]` back:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp_active = np.zeros_like(spSDR[0])\n",
    "sp_active[tm_active] = 1\n",
    "sp_active"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the corresponding column in spSDR:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matching spSDR: [1]\n"
     ]
    }
   ],
   "source": [
    "idx = []\n",
    "for _ in spSDR:\n",
    "    i =+ 1\n",
    "    if np.array_equal(sp_active, spSDR[_]) == True:\n",
    "        idx.append(i)\n",
    "print \"matching spSDR:\", idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overlap:  [0, 1, 2, 1, 0]\n",
      "InputSDR[idx]:  2\n",
      "inputSDR:  [0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# calculate with which inputSDR, the active SP col has the higher overlap: \n",
    "\n",
    "\n",
    "for j in idx:\n",
    "    overlap = []\n",
    "    for i in xrange(len(track)):\n",
    "        overlap.append(sum(track[i]['inputSDR'] * spSDR[j]))\n",
    "        o = last_max_index(overlap)\n",
    "        \n",
    "    print \"overlap: \", str(overlap) +  \"\\nInputSDR[idx]: \", str(o)\n",
    "    print \"inputSDR: \", str(track[o]['inputSDR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function should be useful in case we have ties in the overlap-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_back_SP_to_SDR(lista):\n",
    "    '''\n",
    "    This fnc returns the indeces of the InputSDR/s that match \n",
    "    (have the highest overalpping score) the current SP the most.\n",
    "    \n",
    "    input:  copy of a list `list[:]` with the overlap score bw. \n",
    "            the winning spSDR[i] and the inputSDR[0:]   \n",
    "    output: 'match', a list, indeces of InputSDR in `track`\n",
    "    '''\n",
    "    \n",
    "    a = max(lista)\n",
    "    b = a\n",
    "    match = []\n",
    "    count = 0\n",
    "\n",
    "    while b == a:\n",
    "        i = lista.index(b)\n",
    "        out = lista.pop(i)\n",
    "        i = i+count  # fill the indexes popped out\n",
    "        match.append(i)\n",
    "        count += 1\n",
    "        b = max(lista)    \n",
    "    \n",
    "    return match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2]"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_back_SP_to_SDR(overlap[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputVal[2]: 76.12416182\n",
      "De-Encoder: ({'[70:80]': ([[76.111111111111114, 76.111111111111114]], '76.11')}, ['[70:80]'])\n",
      "-------\n"
     ]
    }
   ],
   "source": [
    "for i in match_back_SP_to_SDR(overlap[:]):\n",
    "    print \"inputVal[\" + str(i) + \"]: \" + str(track[i]['inputVal'])\n",
    "    print \"De-Encoder: \" + str(vEnc.decode(track[i]['inputSDR']))\n",
    "    print \"-------\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mleborgne/_git/nupic/src/nupic/datafiles/extra/hotgym/hotgym.csv\n",
      "\n",
      "gym,address,timestamp,consumption\n",
      "string,string,datetime,float\n",
      "S,,T,\n",
      "Balgowlah Platinum,Shop 67 197-215 Condamine Street Balgowlah 2093,2010-07-02 00:00:00.0,5.3\n",
      "Balgowlah Platinum,Shop 67 197-215 Condamine Street Balgowlah 2093,2010-07-02 00:15:00.0,5.5\n",
      "Balgowlah Platinum,Shop 67 197-215 Condamine Street Balgowlah 2093,2010-07-02 00:30:00.0,5.1\n",
      "Balgowlah Platinum,Shop 67 197-215 Condamine Street Balgowlah 2093,2010-07-02 00:45:00.0,5.3\n",
      "Balgowlah Platinum,Shop 67 197-215 Condamine Street Balgowlah 2093,2010-07-02 01:00:00.0,5.2\n"
     ]
    }
   ],
   "source": [
    "from pkg_resources import resource_filename\n",
    "\n",
    "datasetPath = resource_filename(\"nupic.datafiles\", \"extra/hotgym/hotgym.csv\")\n",
    "print datasetPath\n",
    "\n",
    "with open(datasetPath) as inputFile:\n",
    "    print\n",
    "    for _ in xrange(8):\n",
    "        print inputFile.next().strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data\n",
    "\n",
    "`FileRecordStream` - file reader for the NuPIC file format (CSV with three header rows, understands datetimes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Balgowlah Platinum', 'Shop 67 197-215 Condamine Street Balgowlah 2093', datetime.datetime(2010, 7, 2, 0, 0), 5.3]\n",
      "['Balgowlah Platinum', 'Shop 67 197-215 Condamine Street Balgowlah 2093', datetime.datetime(2010, 7, 2, 0, 15), 5.5]\n",
      "['Balgowlah Platinum', 'Shop 67 197-215 Condamine Street Balgowlah 2093', datetime.datetime(2010, 7, 2, 0, 30), 5.1]\n",
      "['Balgowlah Platinum', 'Shop 67 197-215 Condamine Street Balgowlah 2093', datetime.datetime(2010, 7, 2, 0, 45), 5.3]\n",
      "['Balgowlah Platinum', 'Shop 67 197-215 Condamine Street Balgowlah 2093', datetime.datetime(2010, 7, 2, 1, 0), 5.2]\n"
     ]
    }
   ],
   "source": [
    "from nupic.data.file_record_stream import FileRecordStream\n",
    "\n",
    "def getData():\n",
    "    return FileRecordStream(datasetPath)\n",
    "\n",
    "data = getData()\n",
    "for _ in xrange(5):\n",
    "    print data.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nupic.frameworks.opf.model_factory import ModelFactory\n",
    "model = ModelFactory.create(MODEL_PARAMS)\n",
    "model.enableInference({'predictedField': 'consumption'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  5.3\n",
      "prediction:  5.3\n",
      "input:  5.5\n",
      "prediction:  5.5\n",
      "input:  5.1\n",
      "prediction:  5.36\n",
      "input:  5.3\n",
      "prediction:  5.1\n",
      "input:  5.2\n",
      "prediction:  5.342\n",
      "input:  5.5\n",
      "prediction:  5.2994\n",
      "input:  4.5\n",
      "prediction:  5.35958\n",
      "input:  1.2\n",
      "prediction:  4.92\n",
      "input:  1.1\n",
      "prediction:  1.2\n",
      "input:  1.2\n",
      "prediction:  1.17\n",
      "input:  1.2\n",
      "prediction:  1.179\n",
      "input:  1.2\n",
      "prediction:  1.1853\n",
      "input:  1.2\n",
      "prediction:  1.18971\n",
      "input:  1.2\n",
      "prediction:  1.192797\n",
      "input:  1.1\n",
      "prediction:  1.1949579\n",
      "input:  1.2\n",
      "prediction:  1.16647053\n",
      "input:  1.1\n",
      "prediction:  1.176529371\n",
      "input:  1.2\n",
      "prediction:  1.1535705597\n",
      "input:  1.2\n",
      "prediction:  1.16749939179\n",
      "input:  1.1\n",
      "prediction:  1.17724957425\n",
      "input:  1.2\n",
      "prediction:  1.15407470198\n",
      "input:  6.0\n",
      "prediction:  1.16785229138\n",
      "input:  7.9\n",
      "prediction:  5.551706\n",
      "input:  8.4\n",
      "prediction:  6.2561942\n",
      "input:  10.6\n",
      "prediction:  6.89933594\n",
      "input:  12.4\n",
      "prediction:  10.6\n",
      "input:  12.1\n",
      "prediction:  12.4\n",
      "input:  12.4\n",
      "prediction:  12.31\n",
      "input:  11.4\n",
      "prediction:  12.337\n",
      "input:  11.2\n",
      "prediction:  10.84\n",
      "input:  10.8\n",
      "prediction:  10.948\n",
      "input:  12.0\n",
      "prediction:  10.9036\n",
      "input:  11.8\n",
      "prediction:  11.23252\n",
      "input:  11.9\n",
      "prediction:  11.402764\n",
      "input:  11.4\n",
      "prediction:  11.5519348\n",
      "input:  11.0\n",
      "prediction:  11.50635436\n",
      "input:  9.8\n",
      "prediction:  11.354448052\n",
      "input:  9.8\n",
      "prediction:  10.8881136364\n",
      "input:  10.8\n",
      "prediction:  10.5616795455\n",
      "input:  11.1\n",
      "prediction:  10.6331756818\n",
      "input:  11.1\n",
      "prediction:  10.7732229773\n",
      "input:  11.0\n",
      "prediction:  10.8712560841\n",
      "input:  10.7\n",
      "prediction:  10.9098792589\n",
      "input:  10.6\n",
      "prediction:  10.8469154812\n",
      "input:  10.3\n",
      "prediction:  10.7728408368\n",
      "input:  10.1\n",
      "prediction:  10.6309885858\n",
      "input:  12.9\n",
      "prediction:  10.4716920101\n",
      "input:  10.5\n",
      "prediction:  10.4716920101\n",
      "input:  9.7\n",
      "prediction:  10.480184407\n",
      "input:  9.7\n",
      "prediction:  10.2461290849\n",
      "input:  9.2\n",
      "prediction:  10.0822903594\n",
      "input:  9.2\n",
      "prediction:  9.81760325161\n",
      "input:  9.2\n",
      "prediction:  9.63232227613\n",
      "input:  9.3\n",
      "prediction:  9.50262559329\n",
      "input:  9.1\n",
      "prediction:  9.4418379153\n",
      "input:  9.0\n",
      "prediction:  9.33928654071\n",
      "input:  8.9\n",
      "prediction:  9.2375005785\n",
      "input:  9.0\n",
      "prediction:  9.13625040495\n",
      "input:  8.9\n",
      "prediction:  9.09537528346\n",
      "input:  8.9\n",
      "prediction:  9.03676269843\n",
      "input:  9.0\n",
      "prediction:  8.9957338889\n",
      "input:  9.2\n",
      "prediction:  8.99701372223\n",
      "input:  10.0\n",
      "prediction:  9.05790960556\n",
      "input:  10.7\n",
      "prediction:  9.34053672389\n",
      "input:  8.9\n",
      "prediction:  9.74837570672\n",
      "input:  9.0\n",
      "prediction:  9.49386299471\n",
      "input:  9.0\n",
      "prediction:  9.34570409629\n",
      "input:  9.3\n",
      "prediction:  9.24199286741\n",
      "input:  9.3\n",
      "prediction:  9.25939500718\n",
      "input:  9.1\n",
      "prediction:  9.27157650503\n",
      "input:  9.1\n",
      "prediction:  9.22010355352\n",
      "input:  9.1\n",
      "prediction:  9.18407248746\n",
      "input:  9.2\n",
      "prediction:  9.15885074122\n",
      "input:  9.4\n",
      "prediction:  9.17119551886\n",
      "input:  9.3\n",
      "prediction:  9.2398368632\n",
      "input:  9.3\n",
      "prediction:  9.25788580424\n",
      "input:  9.1\n",
      "prediction:  9.27052006297\n",
      "input:  9.1\n",
      "prediction:  9.21936404408\n",
      "input:  11.0\n",
      "prediction:  9.18355483085\n",
      "input:  9.0\n",
      "prediction:  9.7284883816\n",
      "input:  8.6\n",
      "prediction:  9.50994186712\n",
      "input:  3.0\n",
      "prediction:  9.50994186712\n",
      "input:  1.3\n",
      "prediction:  4.344\n",
      "input:  1.2\n",
      "prediction:  1.20749660397\n",
      "input:  1.3\n",
      "prediction:  1.20524762278\n",
      "input:  1.3\n",
      "prediction:  1.23367333594\n",
      "input:  1.3\n",
      "prediction:  1.25357133516\n",
      "input:  1.2\n",
      "prediction:  1.26749993461\n",
      "input:  1.3\n",
      "prediction:  1.24724995423\n",
      "input:  1.2\n",
      "prediction:  1.26307496796\n",
      "input:  1.3\n",
      "prediction:  1.24415247757\n",
      "input:  1.2\n",
      "prediction:  1.2609067343\n",
      "input:  1.3\n",
      "prediction:  1.24263471401\n",
      "input:  1.2\n",
      "prediction:  1.25984429981\n",
      "input:  1.1\n",
      "prediction:  1.24189100987\n",
      "input:  2.3\n",
      "prediction:  1.19932370691\n",
      "input:  5.5\n",
      "prediction:  3.7308\n",
      "input:  5.5\n",
      "prediction:  6.8366746106\n",
      "input:  5.8\n",
      "prediction:  6.43567222742\n",
      "input:  5.7\n",
      "prediction:  6.24497055919\n"
     ]
    }
   ],
   "source": [
    "data = getData()\n",
    "for _ in xrange(100):\n",
    "    record = dict(zip(data.getFieldNames(), data.next()))\n",
    "    print \"input: \", record[\"consumption\"]\n",
    "    result = model.run(record)\n",
    "    print \"prediction: \", result.inferences[\"multiStepBestPredictions\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-step prediction:  1.19932370691\n"
     ]
    }
   ],
   "source": [
    "print \"5-step prediction: \", result.inferences[\"multiStepBestPredictions\"][5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Params!\n",
    "MODEL_PARAMS = {\n",
    "    # Type of model that the rest of these parameters apply to.\n",
    "    'model': \"HTMPrediction\",\n",
    "\n",
    "    # Version that specifies the format of the config.\n",
    "    'version': 1,\n",
    "\n",
    "    # Intermediate variables used to compute fields in modelParams and also\n",
    "    # referenced from the control section.\n",
    "    'aggregationInfo': {   'days': 0,\n",
    "        'fields': [('consumption', 'sum')],\n",
    "        'hours': 1,\n",
    "        'microseconds': 0,\n",
    "        'milliseconds': 0,\n",
    "        'minutes': 0,\n",
    "        'months': 0,\n",
    "        'seconds': 0,\n",
    "        'weeks': 0,\n",
    "        'years': 0},\n",
    "\n",
    "    'predictAheadTime': None,\n",
    "\n",
    "    # Model parameter dictionary.\n",
    "    'modelParams': {\n",
    "        # The type of inference that this model will perform\n",
    "        'inferenceType': 'TemporalAnomaly',\n",
    "\n",
    "        'sensorParams': {\n",
    "            # Sensor diagnostic output verbosity control;\n",
    "            # if > 0: sensor region will print out on screen what it's sensing\n",
    "            # at each step 0: silent; >=1: some info; >=2: more info;\n",
    "            # >=3: even more info (see compute() in py/regions/RecordSensor.py)\n",
    "            'verbosity' : 0,\n",
    "\n",
    "            # Include the encoders we use\n",
    "            'encoders': {\n",
    "                u'timestamp_timeOfDay': {\n",
    "                    'fieldname': u'timestamp',\n",
    "                    'name': u'timestamp_timeOfDay',\n",
    "                    'timeOfDay': (21, 0.5),\n",
    "                    'type': 'DateEncoder'},\n",
    "                u'timestamp_dayOfWeek': None,\n",
    "                u'timestamp_weekend': None,\n",
    "                u'consumption': {\n",
    "                    'clipInput': True,\n",
    "                    'fieldname': u'consumption',\n",
    "                    'maxval': 100.0,\n",
    "                    'minval': 0.0,\n",
    "                    'n': 50,\n",
    "                    'name': u'c1',\n",
    "                    'type': 'ScalarEncoder',\n",
    "                    'w': 21},},\n",
    "\n",
    "            # A dictionary specifying the period for automatically-generated\n",
    "            # resets from a RecordSensor;\n",
    "            #\n",
    "            # None = disable automatically-generated resets (also disabled if\n",
    "            # all of the specified values evaluate to 0).\n",
    "            # Valid keys is the desired combination of the following:\n",
    "            #   days, hours, minutes, seconds, milliseconds, microseconds, weeks\n",
    "            #\n",
    "            # Example for 1.5 days: sensorAutoReset = dict(days=1,hours=12),\n",
    "            #\n",
    "            # (value generated from SENSOR_AUTO_RESET)\n",
    "            'sensorAutoReset' : None,\n",
    "        },\n",
    "\n",
    "        'spEnable': True,\n",
    "\n",
    "        'spParams': {\n",
    "            # SP diagnostic output verbosity control;\n",
    "            # 0: silent; >=1: some info; >=2: more info;\n",
    "            'spVerbosity' : 0,\n",
    "\n",
    "            # Spatial Pooler implementation selector, see getSPClass\n",
    "            # in py/regions/SPRegion.py for details\n",
    "            # 'py' (default), 'cpp' (speed optimized, new)\n",
    "            'spatialImp' : 'cpp',\n",
    "\n",
    "            'globalInhibition': 1,\n",
    "\n",
    "            # Number of cell columns in the cortical region (same number for\n",
    "            # SP and TM)\n",
    "            # (see also tpNCellsPerCol)\n",
    "            'columnCount': 2048,\n",
    "\n",
    "            'inputWidth': 0,\n",
    "\n",
    "            # SP inhibition control (absolute value);\n",
    "            # Maximum number of active columns in the SP region's output (when\n",
    "            # there are more, the weaker ones are suppressed)\n",
    "            'numActiveColumnsPerInhArea': 40,\n",
    "\n",
    "            'seed': 1956,\n",
    "\n",
    "            # potentialPct\n",
    "            # What percent of the columns's receptive field is available\n",
    "            # for potential synapses. At initialization time, we will\n",
    "            # choose potentialPct * (2*potentialRadius+1)^2\n",
    "            'potentialPct': 0.5,\n",
    "\n",
    "            # The default connected threshold. Any synapse whose\n",
    "            # permanence value is above the connected threshold is\n",
    "            # a \"connected synapse\", meaning it can contribute to the\n",
    "            # cell's firing. Typical value is 0.10. Cells whose activity\n",
    "            # level before inhibition falls below minDutyCycleBeforeInh\n",
    "            # will have their own internal synPermConnectedCell\n",
    "            # threshold set below this default value.\n",
    "            # (This concept applies to both SP and TM and so 'cells'\n",
    "            # is correct here as opposed to 'columns')\n",
    "            'synPermConnected': 0.1,\n",
    "\n",
    "            'synPermActiveInc': 0.1,\n",
    "\n",
    "            'synPermInactiveDec': 0.005,\n",
    "        },\n",
    "\n",
    "        # Controls whether TM is enabled or disabled;\n",
    "        # TM is necessary for making temporal predictions, such as predicting\n",
    "        # the next inputs.  Without TP, the model is only capable of\n",
    "        # reconstructing missing sensor inputs (via SP).\n",
    "        'tmEnable' : True,\n",
    "\n",
    "        'tmParams': {\n",
    "            # TM diagnostic output verbosity control;\n",
    "            # 0: silent; [1..6]: increasing levels of verbosity\n",
    "            # (see verbosity in nupic/trunk/py/nupic/research/TP.py and BacktrackingTMCPP.py)\n",
    "            'verbosity': 0,\n",
    "\n",
    "            # Number of cell columns in the cortical region (same number for\n",
    "            # SP and TM)\n",
    "            # (see also tpNCellsPerCol)\n",
    "            'columnCount': 2048,\n",
    "\n",
    "            # The number of cells (i.e., states), allocated per column.\n",
    "            'cellsPerColumn': 32,\n",
    "\n",
    "            'inputWidth': 2048,\n",
    "\n",
    "            'seed': 1960,\n",
    "\n",
    "            # Temporal Pooler implementation selector (see _getTPClass in\n",
    "            # CLARegion.py).\n",
    "            'temporalImp': 'cpp',\n",
    "\n",
    "            # New Synapse formation count\n",
    "            # NOTE: If None, use spNumActivePerInhArea\n",
    "            #\n",
    "            # TODO: need better explanation\n",
    "            'newSynapseCount': 20,\n",
    "\n",
    "            # Maximum number of synapses per segment\n",
    "            #  > 0 for fixed-size CLA\n",
    "            # -1 for non-fixed-size CLA\n",
    "            #\n",
    "            # TODO: for Ron: once the appropriate value is placed in TP\n",
    "            # constructor, see if we should eliminate this parameter from\n",
    "            # description.py.\n",
    "            'maxSynapsesPerSegment': 32,\n",
    "\n",
    "            # Maximum number of segments per cell\n",
    "            #  > 0 for fixed-size CLA\n",
    "            # -1 for non-fixed-size CLA\n",
    "            #\n",
    "            # TODO: for Ron: once the appropriate value is placed in TP\n",
    "            # constructor, see if we should eliminate this parameter from\n",
    "            # description.py.\n",
    "            'maxSegmentsPerCell': 128,\n",
    "\n",
    "            # Initial Permanence\n",
    "            # TODO: need better explanation\n",
    "            'initialPerm': 0.21,\n",
    "\n",
    "            # Permanence Increment\n",
    "            'permanenceInc': 0.1,\n",
    "\n",
    "            # Permanence Decrement\n",
    "            # If set to None, will automatically default to tpPermanenceInc\n",
    "            # value.\n",
    "            'permanenceDec' : 0.1,\n",
    "\n",
    "            'globalDecay': 0.0,\n",
    "\n",
    "            'maxAge': 0,\n",
    "\n",
    "            # Minimum number of active synapses for a segment to be considered\n",
    "            # during search for the best-matching segments.\n",
    "            # None=use default\n",
    "            # Replaces: tpMinThreshold\n",
    "            'minThreshold': 9,\n",
    "\n",
    "            # Segment activation threshold.\n",
    "            # A segment is active if it has >= tpSegmentActivationThreshold\n",
    "            # connected synapses that are active due to infActiveState\n",
    "            # None=use default\n",
    "            # Replaces: tpActivationThreshold\n",
    "            'activationThreshold': 12,\n",
    "\n",
    "            'outputType': 'normal',\n",
    "\n",
    "            # \"Pay Attention Mode\" length. This tells the TM how many new\n",
    "            # elements to append to the end of a learned sequence at a time.\n",
    "            # Smaller values are better for datasets with short sequences,\n",
    "            # higher values are better for datasets with long sequences.\n",
    "            'pamLength': 1,\n",
    "        },\n",
    "\n",
    "        'clParams': {\n",
    "            'regionName' : 'SDRClassifierRegion',\n",
    "\n",
    "            # Classifier diagnostic output verbosity control;\n",
    "            # 0: silent; [1..6]: increasing levels of verbosity\n",
    "            'verbosity' : 0,\n",
    "\n",
    "            # This controls how fast the classifier learns/forgets. Higher values\n",
    "            # make it adapt faster and forget older patterns faster.\n",
    "            'alpha': 0.005,\n",
    "\n",
    "            # This is set after the call to updateConfigFromSubConfig and is\n",
    "            # computed from the aggregationInfo and predictAheadTime.\n",
    "            'steps': '1',\n",
    "\n",
    "            'implementation': 'cpp',\n",
    "        },\n",
    "\n",
    "        'anomalyParams': {\n",
    "            u'anomalyCacheRecords': None,\n",
    "            u'autoDetectThreshold': None,\n",
    "            u'autoDetectWaitRecords': 2184\n",
    "        },\n",
    "\n",
    "        'trainSPNetOnlyIfRequested': False,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nupic.frameworks.opf.model_factory import ModelFactory\n",
    "model = ModelFactory.create(MODEL_PARAMS)\n",
    "model.enableInference({'predictedField': 'consumption'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  5.3\n",
      "prediction:  5.3\n",
      "input:  5.5\n",
      "prediction:  5.5\n",
      "input:  5.1\n",
      "prediction:  5.36\n",
      "input:  5.3\n",
      "prediction:  5.1\n",
      "input:  5.2\n",
      "prediction:  5.342\n"
     ]
    }
   ],
   "source": [
    "data = getData()\n",
    "for _ in xrange(5):\n",
    "    record = dict(zip(data.getFieldNames(), data.next()))\n",
    "    print \"input: \", record[\"consumption\"]\n",
    "    result = model.run(record)\n",
    "    print \"prediction: \", result.inferences[\"multiStepBestPredictions\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelResult(\tpredictionNumber=4\n",
      "\trawInput={'timestamp': datetime.datetime(2010, 7, 2, 1, 0), 'gym': 'Balgowlah Platinum', 'consumption': 5.2, 'address': 'Shop 67 197-215 Condamine Street Balgowlah 2093'}\n",
      "\tsensorInput=SensorInput(\tdataRow=(5.2, 1.0)\n",
      "\tdataDict={'timestamp': datetime.datetime(2010, 7, 2, 1, 0), 'gym': 'Balgowlah Platinum', 'consumption': 5.2, 'address': 'Shop 67 197-215 Condamine Street Balgowlah 2093'}\n",
      "\tdataEncodings=[array([ 0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  0.,\n",
      "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.], dtype=float32), array([ 0.,  0.,  0., ...,  0.,  0.,  0.], dtype=float32)]\n",
      "\tsequenceReset=0.0\n",
      "\tcategory=-1\n",
      ")\n",
      "\tinferences={'multiStepPredictions': {1: {5.1: 0.0088801263517415546, 5.2: 0.010775254623541418, 5.341999999999999: 0.98034461902471692}}, 'multiStepBucketLikelihoods': {1: {1: 0.0088801263517415546, 2: 0.98034461902471692}}, 'multiStepBestPredictions': {1: 5.341999999999999}, 'anomalyLabel': '[]', 'anomalyScore': 0.40000001}\n",
      "\tmetrics=None\n",
      "\tpredictedFieldIdx=0\n",
      "\tpredictedFieldName=consumption\n",
      "\tclassifierInput=ClassifierInput(\tdataRow=5.2\n",
      "\tbucketIndex=2\n",
      ")\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anomaly score:  0.4\n"
     ]
    }
   ],
   "source": [
    "print \"anomaly score: \", result.inferences[\"anomalyScore\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__See Subutai's talk for more info on anomaly detection!__\n",
    "\n",
    "# Built-in OPF Clients\n",
    "\n",
    "`python examples/opf/bin/OpfRunExperiment.py examples/opf/experiments/multistep/hotgym/`\n",
    "\n",
    "Outputs `examples/opf/experiments/multistep/hotgym/inference/DefaultTask.TemporalMultiStep.predictionLog.csv`\n",
    "\n",
    "`python bin/run_swarm.py examples/opf/experiments/multistep/hotgym/permutations.py`\n",
    "\n",
    "Outputs `examples/opf/experiments/multistep/hotgym/model_0/description.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nupic",
   "language": "python",
   "name": "nupic"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
